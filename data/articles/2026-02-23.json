[
  {
    "title": "The Claude C Compiler: What It Reveals About the Future of Software",
    "link": "https://simonwillison.net/2026/Feb/22/ccc/#atom-everything",
    "content": "\n    \n<p><strong><a href=\"https://www.modular.com/blog/the-claude-c-compiler-what-it-reveals-about-the-future-of-software\">The Claude C Compiler: What It Reveals About the Future of Software</a></strong></p>\nOn February 5th Anthropic's Nicholas Carlini wrote about a project to use <a href=\"https://www.anthropic.com/engineering/building-c-compiler\">parallel Claudes to build a C compiler</a> on top of the brand new Opus 4.6</p>\n<p>Chris Lattner (Swift, LLVM, Clang, Mojo) knows more about C compilers than most. He just published this review of the code.</p>\n<p>Some points that stood out to me:</p>\n<blockquote>\n<ul>\n<li>Good software depends on judgment, communication, and clear abstraction. AI has amplified this.</li>\n<li>AI coding is automation of implementation, so design and stewardship become more important.</li>\n<li>Manual rewrites and translation work are becoming AI-native tasks, automating a large category of engineering effort.</li>\n</ul>\n</blockquote>\n<p>Chris is generally impressed with CCC (the Claude C Compiler):</p>\n<blockquote>\n<p>Taken together, CCC looks less like an experimental research compiler and more like a competent textbook implementation, the sort of system a strong undergraduate team might build early in a project before years of refinement. That alone is remarkable.</p>\n</blockquote>\n<p>It's a long way from being a production-ready compiler though:</p>\n<blockquote>\n<p>Several design choices suggest optimization toward passing tests rather than building general abstractions like a human would. [...] These flaws are informative rather than surprising, suggesting that current AI systems excel at assembling known techniques and optimizing toward measurable success criteria, while struggling with the open-ended generalization required for production-quality systems.</p>\n</blockquote>\n<p>The project also leads to deep open questions about how agentic engineering interacts with licensing and IP for both open source and proprietary code:</p>\n<blockquote>\n<p>If AI systems trained on decades of publicly available code can reproduce familiar structures, patterns, and even specific implementations, where exactly is the boundary between learning and copying?</p>\n</blockquote>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/c\">c</a>, <a href=\"https://simonwillison.net/tags/compilers\">compilers</a>, <a href=\"https://simonwillison.net/tags/open-source\">open-source</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/claude\">claude</a>, <a href=\"https://simonwillison.net/tags/nicholas-carlini\">nicholas-carlini</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a></p>\n\n\n\n",
    "description": "The Claude C Compiler: What It Reveals About the Future of Software On February 5th Anthropic's Nicholas Carlini wrote about a project to use parallel Claudes to build a C compiler on top of the brand new Opus 4.6 Chris Lattner (Swift, LLVM, Clang, Mojo) knows more about C compilers than most. He just published this review of the code. Some points that stood out to me: Good software depends on judgment, communication, and clear abstraction. AI has amplified this. AI coding is automation of imple",
    "is_fulltext": true,
    "source": "Simon Willison's Weblog",
    "pub_date": "2026-02-22T23:58:43+00:00",
    "fetched_at": "2026-02-23T00:38:34.258135",
    "url_hash": "aa4766009a8536145071395d5b6bf0df"
  },
  {
    "title": "How close are we to a vision for 2010?",
    "link": "https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/",
    "content": "<p>Twenty five years ago today, the EU's <a href=\"https://cordis.europa.eu/article/id/14054-ist-advisory-group-istag-takes-strategic-approach\">IST advisory group</a> published a paper about the future of \"Ambient Intelligence\". Way before the world got distracted with cryptoscams and AI slop, we genuinely thought that computers would be so pervasive and well-integrated that the dream of \"<a href=\"https://shkspr.mobi/blog/2002/04/disappearing-computer-2002/\">Ubiquitous Computing</a>\" would become a reality.</p>\n\n<p>The ISTAG published an optimistic paper called \"<a href=\"https://www.researchgate.net/publication/262007900_Scenarios_for_ambient_intelligence_in_2010\">Scenarios for ambient intelligence in 2010</a>\". It's a brilliant look at what the future <em>might</em> have been. Let's go through some of the scenarios and see how close 2026 is to 2000's vision of 2010.</p>\n\n<h2 id=\"scenario-1-maria-road-warrior-close-term-future\"><a href=\"https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/#scenario-1-maria-road-warrior-close-term-future\">Scenario 1: ‘Maria’ – Road Warrior (close-term future)</a></h2>\n\n<p>Our titular heroine steps off a long haul flight into a foreign country.</p>\n\n<blockquote><p>she knows that she can travel much lighter than less than a decade ago, when she had to carry a collection of different so-called personal computing devices (laptop PC, mobile phone, electronic organisers and sometimes beamers and printers). Her computing system for this trip is reduced to one highly personalised communications device, her ‘P–Com’ that she wears on her wrist.</p></blockquote>\n\n<p>Well… OK! Not a bad start. You probably wouldn't want <em>everything</em> controlled by your smart watch - but the mobile is a good substitute. Although wireless video casting works, you'd probably want a trusty USB-C just to make sure.</p>\n\n<blockquote><p>she is able to stroll through immigration without stopping because her P-Comm is dealing with the ID checks as she walks.</p></blockquote>\n\n<p>We're getting closer to digital ID. But outside of a few experiments, there's no international consensus. However, every modern passport has an NFC chip which can be read by most airports. You still need to hold your passport on the reader, but it's usually quicker than queuing for a human.</p>\n\n<p>Maria heads to her rented car:</p>\n\n<blockquote><p>The car opens as she approaches. It starts at the press of a button: she doesn’t need a key. She still has to drive the car but she is supported in her journey downtown to the conference centre-hotel by the traffic guidance system that had been launched by the city government as part of the ‘AmI-Nation’ initiative two years earlier.</p></blockquote>\n\n<p>Lots of cars now have wireless entry and are button controlled. <a href=\"https://www.enterprisecarclub.co.uk/gb/en/about/user-guides.html\">Rental cars often have mobile app unlocking</a>.</p>\n\n<p>The traffic guidance is not provided by local governments. A mixture of international satellites provide positioning information, and a bunch of private companies provide traffic guidance.</p>\n\n<blockquote><p>Downtown traffic has been a legendary nightmare in this city for many\nyears, and draconian steps were taken to limit access to the city centre. But Maria has priority access rights into the central cordon because she has a reservation in the car park of the hotel. Central access however comes at a premium price, in Maria’s case it is embedded in a deal negotiated between her personal agent and the transaction agents of the car-rental and hotel chains</p></blockquote>\n\n<p>Ah! The dream of personal agents. Not even close.</p>\n\n<blockquote><p>In the car Maria’s teenage daughter comes through on the audio system. Amanda has detected from ‘En Casa’ system at home that her mother is in a place that supports direct voice contact.</p></blockquote>\n\n<p>Hurrah for Bluetooth! Every car supports that now. Presence and location sensing is also common. Although the idea of a teenager willingly making a voice call is, sadly, a fantasy.</p>\n\n<blockquote><p>Her room adopts her ‘personality’ as she enters. The room temperature, default lighting and a range of video and music choices are displayed on the video wall.</p></blockquote>\n\n<p>Pffft! Nope. But do people really want this? The music and video are stored on her phone, so there's no need to transmit private data to a hotel.</p>\n\n<blockquote><p>Using voice commands she adjusts the light levels and commands a bath. Then she calls up her daughter on the video wall, while talking she uses a traditional remote control system to browse through a set of webcast local news bulletins from back home that her daughter tells her about. They watch them together.</p></blockquote>\n\n<p>Do you want an always-on Alexa in your hotel room? We have the technology, but we seem to shun in outside of specific scenarios.</p>\n\n<p>We still have traditional remotes for browsing, and how lovely that they predicted the rise of simultaneous viewing!</p>\n\n<blockquote><p>Later on she ‘localises’ her presentation with the help of an agent that is specialised in advising on local preferences (colour schemes, the use of language).</p></blockquote>\n\n<p>I'd say we're there with a mixture of templates and LLMs. Translation and localisation is good enough.</p>\n\n<blockquote><p>She stores the presentation on the secure server at headquarters back in Europe. In the hotel’s seminar room where the sales pitch is take place, she will be able to call down an encrypted version of the presentation and give it a post presentation decrypt life of 1.5 minutes</p></blockquote>\n\n<p>Yup! Most things live in the cloud. Access controls are a thing. Whether people can be bothered to use them is another matter!</p>\n\n<blockquote><p>As she enters the meeting she raises communications access thresholds to block out anything but red-level ‘emergency’ messages</p></blockquote>\n\n<p>Do-Not-Disturb is a feature on every modern phone.</p>\n\n<blockquote><p>Coming out of the meeting she lowers the communication barriers again and picks up a number of amber level communications including one from her cardio-monitor warning her to take some rest now.</p></blockquote>\n\n<p>Ah! The constant chastising FitBit!</p>\n\n<h2 id=\"scenario-2-dimitrios-and-the-digital-me-d-me-near-term-future\"><a href=\"https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/#scenario-2-dimitrios-and-the-digital-me-d-me-near-term-future\">Scenario 2: ‘Dimitrios’ and the Digital Me’ (D-Me) (near-term future)</a></h2>\n\n<p>Dimitrios is the sort of self-facilitating media node you would never get tired of slapping.</p>\n\n<blockquote><p>Dimitrios is wearing, embedded in his clothes (or in his own body), a voice activated ‘gateway’ or digital avatar of himself, familiarly known as ‘D-Me’ or ‘Digital Me’. […] He feels quite confident with his D-Me and relies upon its ‘intelligent‘ reactions.</p></blockquote>\n\n<p>Nope! Oh, sure, your phone can auto-suggest some stock phrases to reply to emails. But we are nowhere close to having a physically embedded system which learns from us and can be trusted to respond.</p>\n\n<p>Dimitrios receives calls which are:</p>\n\n<blockquote><p>answered formally but smoothly in corresponding languages by Dimitrios’ D-Me with a nice reproduction of Dimitrios’ voice and typical accent,</p></blockquote>\n\n<p>Vocal cloning is here. It is <em>almost</em> out of the uncanny valley. But I think most people would prefer to send a quick text or voice-note rather than use an AI.</p>\n\n<blockquote><p>a call from his wife is further analysed by his D-Me. In a first attempt, Dimitrios’ ‘avatar-like’ voice runs a brief conversation with his wife, with the intention of negotiating a delay while explaining his current environment.</p></blockquote>\n\n<p>She's going to leave him.</p>\n\n<blockquote><p>Dimitrios’ D-Me has caught a message from an older person’s D-Me, located in the nearby metro station. This senior has left his home without his medicine and would feel at ease knowing where and how to access similar drugs in an easy way. He has addressed his query in natural speech to his D-Me.</p></blockquote>\n\n<p>This is weird. Yes, we have smart-agents which are just about good enough to recognise speech and understand it. Why is it being sent to Dimitrios?</p>\n\n<blockquote><p>Dimitrios happens to suffer from similar heart problems and uses the same drugs. Dimitrios’ D-Me processes the available data as to offer information to the senior. It ‘decides’ neither to reveal Dimitrios’ identity (privacy level), nor to offer Dimitrios’ direct help (lack of availability), but to list the closest drug shops, the alternative drugs, offer a potential contact with the self-help group. This information is shared with the senior’s D-Me, not with the senior himself as to avoid useless information overload</p></blockquote>\n\n<p>We're nowhere close to this. At most, you might be able to post on social media and hope someone could help. I <em>like</em> the idea of a local social network, and there's a good understanding of privacy. But this seems needlessly convoluted - why wouldn't the senior's D-Me just look up the information online?</p>\n\n<blockquote><p>Meanwhile, his wife’s call is now interpreted by his D-Me as sufficiently pressing to mobilise Dimitrios. It ‘rings’ him using a pre-arranged call tone. Dimitrios takes up the call with one of the available Displayphones of the cafeteria. Since the growing penetration of D-Me, few people still bother to run around with mobile terminals: these functions are sufficiently available in most public and private spaces and your D-Me can always point at the closest…functioning one!</p></blockquote>\n\n<p>A hit and a miss! They predicted the rise of personalised ringtones - which have now all but vanished - but no one wants to use a pay-phone when they have their own mobile!</p>\n\n<blockquote><p>While doing his homework their 9 year-old son is meant to offer some insights on everyday life in Egypt. In a brief 3-way telephone  conference, Dimitrios offers to pass over the query to the D-Me to search for an available direct contact with a child in Egypt. Ten minutes later, his son is videoconferencing at home with a girl of his own age, and recording this real-time translated conversation as part of his homework.</p></blockquote>\n\n<p>ChatRoulette for kids! What could possibly go wrong!</p>\n\n<p>Ignoring that aspect, it's relatively common for kids to videocall each other - especially for language learning. Real-time translation is also possible.</p>\n\n<h2 id=\"scenario-3-carmen-traffic-sustainability-commerce-further-term-future\"><a href=\"https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/#scenario-3-carmen-traffic-sustainability-commerce-further-term-future\">Scenario 3 - Carmen: traffic, sustainability &amp; commerce (further-term future)</a></h2>\n\n<p>Carmen is a modern, 21st century woman. Let's see how technology helps her:</p>\n\n<blockquote><p>She wants to leave for work in half an hour and asks AmI, by means of a voice command, to find a vehicle to share with somebody on her route to work.</p></blockquote>\n\n<p>Voice commands work - although usually only if you know the correct invocation.</p>\n\n<blockquote><p>AmI starts searching the trip database and, after checking the willingness of the driver, finds someone that will pass by in 40 minutes. The in-vehicle biosensor has recognised that this driver is a non-smoker – one of Carmen requirements for trip sharing. From that moment on, Carmen and her driver are in permanent contact if wanted\n(e.g. to allow the driver to alert Carmen if he/she will be late). Both wear their personal area networks (PAN) allowing seamless and intuitive contacts.</p></blockquote>\n\n<p>The aim of \"ride-sharing\" was originally this sort of thing. A driver would give a lift to someone if they happened to be travelling that route. Nowadays that model is over - it's all professional drivers.</p>\n\n<p>Ubiquitous geo-tracking now means you can see if your driver is late, and they can see if you've moved street. We have too many privacy concerts to allow PANs to share much more.</p>\n\n<blockquote><p>She would like also to cook a cake and the e-fridge flashes the recipe. It highlights the ingredients that are missing milk and eggs. She completes the shopping on the e-fridge screen and asks for it to be delivered to the closest distribution point in her neighbourhood.</p></blockquote>\n\n<p>Oh! The Internet-Connected Fridge! Beloved by technologists and spurned by users! While there are a few fridges with build-in web-browsers, most people do their shopping from their phone.</p>\n\n<p>Home delivery is now seamless and cheap. The \"Amazon Locker\" is also a reality.</p>\n\n<blockquote><p>All goods are smart tagged, so that Carmen can check the progress of her virtual shopping expedition, from any enabled device at home, the office or from a kiosk in the street</p></blockquote>\n\n<p>Do you care whether the eggs have been packed yet? I can see that it would be useful to the store to have realtime info on stock levels (and they mostly do for online shopping) but why expose that to the user?</p>\n\n<p>Would you bother using a public terminal?</p>\n\n<blockquote><p>When Carmen gets into the car, the VAN system (Vehicle Area Network) registers her and by doing that she sanctions the payment systems to start counting. A micro-payment system will automatically transfer the amount into the e-purse of the driver when she gets out of the car.</p></blockquote>\n\n<p>I don't think Uber's app uses Bluetooth to detect whether driver and passenger are in proximity. Maybe it should?</p>\n\n<p>Cryptocurrencies still can't do instantaneous micro-transactions. But credit-cards work pretty well.</p>\n\n<blockquote><p>Carmen is alerted by her PAN that a Chardonnay wine that she has previously identified as a preferred choice is on promotion. She adds it to her shopping order</p></blockquote>\n\n<p>Personal Agents always working for the user! Again, a fantasy which has yet to emerge.  The reality is more like a push notification from the shop.</p>\n\n<blockquote><p>On the way home the shared car system senses a bike on a dedicated lane approaching an intersection on their route. The driver is alerted […] so a potential accident is avoided.</p></blockquote>\n\n<p>Tesla's crappy implementation notwithstanding, modern cars are relatively good about detecting bikes, pedestrians, and other vehicles.</p>\n\n<blockquote><p>the traffic density has caused pollution levels to rise above a control threshold. The city-wide engine control systems automatically lower the maximum speeds (for all motorised vehicles) and when the car enters a specific urban ring toll will be deducted via the Automatic Debiting System (ADS)</p></blockquote>\n\n<p>Half-and-half. No one is allowing their car to be remotely controlled, although plenty of roads have dynamic speed limits. Most modern metros have Automatic Number Plate Recognition and can bill drivers who enter congestion zones.</p>\n\n<blockquote><p>Carmen arrives at the local distribution node (actually her neighbourhood corner shop) where she picks up her goods. The shop has already closed but the goods await Carmen in a smart delivery box. By getting them out, the system registers payment</p></blockquote>\n\n<p>This is pretty much how the Amazon Locker works!</p>\n\n<h2 id=\"scenario-4-annette-and-solomon-in-the-ambient-for-social-learning-far-term-future\"><a href=\"https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/#scenario-4-annette-and-solomon-in-the-ambient-for-social-learning-far-term-future\">Scenario 4 – Annette and Solomon in the Ambient for Social Learning (far-term future)</a></h2>\n\n<p>Let's now go to an environmental study group meeting at a learning space.</p>\n\n<blockquote><p>Some are scheduled to work together in real time and space and thus were requested to be present together (the ambient accesses their agendas to do the scheduling).</p></blockquote>\n\n<p>Ah! Sadly not. At best we have shared calenders where people can look up suitable times, or Doodle polls where people can suggest their preferred times. Some integrated systems like Office365 will do a basic attempt to suggest meeting times - but it is a closed and proprietary system.</p>\n\n<p>Here's Annette:</p>\n\n<blockquote><p>Annette is an active and advanced student so the ambient says it might be useful if Annette spends some time today trying to pin down the problem with the model using enhanced interactive simulation and projection facilities. It then asks if Annette would give a brief presentation to the group. The ambient goes briefly through its understanding of Annette’s availability and preferences for the day’s work.</p></blockquote>\n\n<p>A demo of that today would wow people. LLMs can convincingly do <em>some</em> of these tasks, but they're not integrated into anything sufficiently complex.</p>\n\n<p>Here's Solomon, a new participant:</p>\n\n<blockquote><p>The ambient establishes Solomon’s identity; asks Solomon for the name of an ambient that ‘knows’ Solomon; gets permission from Solomon to acquire information about Solomon’s background and experience in Environmental Studies. The ambient then suggests Solomon to join the meeting and to introduce himself to the group.</p></blockquote>\n\n<p>Again, we barely have coherent online identities. We certainly don't have trusted ambient intelligences who can claim to know us. I do like the fact that it asks for permission. Not always a given today!</p>\n\n<blockquote><p>In these private conversations the mental states of the group are synchronised with the ambient, individual and collective work plans are agreed and in most cases checked with the mentor through the ambient.</p></blockquote>\n\n<p>Nope!</p>\n\n<blockquote><p>During the presentation the mentor is feeding observations and questions to the ambient, together with William, an expert who was asked to join the meeting. William, although several thousand miles away, joins to make a comment and answer some questions.</p></blockquote>\n\n<p>Telepresence is a reality today. Video-calling experts in a natural and expected part life here in 2026.</p>\n\n<blockquote><p>During the day the mentor and ambient converse frequently, establishing where the mentor might most usefully spend his time, and in some cases altering the schedule. The ambient and the mentor will spend some time negotiating shared experiences with other ambients – for example mounting a single musical concert with players from two or more distant sites.</p></blockquote>\n\n<p>I feel we're still about 25 years away from this future!</p>\n\n<h2 id=\"key-technological-requirements-for-ambient-intelligence-ami\"><a href=\"https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/#key-technological-requirements-for-ambient-intelligence-ami\">Key technological requirements for Ambient Intelligence (AmI)</a></h2>\n\n<p>The above scenarios are designed to be provocative thought experiments. If that's the future that people want, how would we get there?</p>\n\n<p>The researches suggest five technological requirements:</p>\n\n<ol>\n<li>Very unobtrusive hardware</li>\n<li>A seamless mobile/fixed communications infrastructure</li>\n<li>Dynamic and massively distributed device networks</li>\n<li>Natural feeling human interfaces</li>\n<li>Dependability and security</li>\n</ol>\n\n<p>I think they're bang on the money there.</p>\n\n<p>Hardware is getting unobtrusive. Wearables are limited at the moment to wrist-mounted sensors, some medical devices, and video glasses. The hardware in our environment is even better at being unobtrusive. Presence sensors, cameras, and microphones are embedded all around us.  We're unfortunately limited by short-life batteries.</p>\n\n<p>While the promise of 5G hasn't quite materialised, it is increasing rare to be offline. WiFi is in every building, urban areas are flooded with mobile signals, and satellite comms are becoming cheaper. OK, IPv6 still isn't widespread, but it is mostly seamless when a device moves between radio technologies.</p>\n\n<p>Distributed device networks are still yet to emerge. The current crop of monopolist technology providers want everything to go through their systems.  There's very little standardisation.</p>\n\n<p>Humane interfaces are getting there. Voice-to-text mostly works - but it does rely on training humans sufficiently well. Lots of things are still monolingual.</p>\n\n<p>Security and privacy are constant thorns in the side of progress. Everything would be easier if we didn't need to worry about keeping people safe and secure. Dependability is the crux of any system - every time you experience a failure, you're less likely to return.</p>\n\n<h2 id=\"what-have-we-learned\"><a href=\"https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/#what-have-we-learned\">What Have We Learned</a></h2>\n\n<p><a href=\"https://www.researchgate.net/publication/262007900_Scenarios_for_ambient_intelligence_in_2010\">The whole paper is worth reading</a>, especially the longer versions of each scenario which dive into some of the socio-political issues.</p>\n\n<p>Some of the visions for 2010 are here! We have GPS, ride-sharing, and video-calls with real-time translations. Our groceries and other items can be delivered to smart-lockers, locks are opened with digital keys, and voice cloning mostly works.</p>\n\n<p>We don't have public pay-phones (not even video enabled ones!) and cars aren't centrally controlled. For all the promises of AI, it still isn't even close to providing a seamless experience.</p>\n\n<p>What strikes me most about the possible futures discussed isn't their optimism nor their missteps - it's that most of these things <em>could</em> be possible today if there were sufficient open standards which the public and private sector adopted.</p>\n\n<p>Anyone who has read \"<a href=\"https://shkspr.mobi/blog/2020/02/book-review-the-entrepreneurial-state/\">The Entrepreneurial State</a>\" knows that these things take <em>significant</em> public investment. We've reached a point where the private sector has generated wealth from previous public research, but seems unwilling to invest in any long-term research itself.  That's short-changing our future.</p>\n",
    "description": "Twenty five years ago today, the EU&#039;s IST advisory group published a paper about the future of &#34;Ambient Intelligence&#34;. Way before the world got distracted with cryptoscams and AI slop, we genuinely thought that computers would be so pervasive and well-integrated that the dream of &#34;Ubiquitous Computing&#34; would become a reality. The ISTAG published an optimistic paper called &#34;Scenarios for ambient…",
    "is_fulltext": true,
    "source": "Terence Eden’s Blog",
    "pub_date": "Sun, 22 Feb 2026 12:34:58 +0000",
    "fetched_at": "2026-02-23T00:38:42.285561",
    "url_hash": "ad7e8a18d56ce5fda0f8f073808cc410"
  },
  {
    "title": "The importance of limiting syndication feed requests in some way",
    "link": "https://utcc.utoronto.ca/~cks/space/blog/web/FeedLimitingImportance",
    "content": "<div class=\"wikitext\"><p>People sometimes wonder why I care so much about <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Conditional_requests\">HTTP conditional\nGETs</a>\nand rate limiting for syndication feed fetchers. There are multiple\nreasons, including <a href=\"https://utcc.utoronto.ca/~cks/space/blog/web/WeShouldBlockForSocialReasons\">social reasons to establish norms</a>, but one obvious one is transfer\nvolumes. To illustrate that, I'll look at the statistics for yesterday\nfor feed fetches of the main syndication feed for <a href=\"https://utcc.utoronto.ca/~cks/space/blog/\">Wandering\nThoughts</a>.</p>\n\n<p>Yesterday there were 7492 feed requests that got HTTP 200 responses,\n9419 feed requests that got HTTP 304 Not Modified responses, and\n11941 requests that received <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status/429\">HTTP 429</a>\nresponses. The HTTP 200 responses amounted to about 1.26 GBytes,\nwith the average response size being 176 KBytes. This average\nresponse size is actually a composite; typical compressed syndication\nfeed responses are on the order of 160 KBytes, while uncompressed\nones are on the order of 540 KBytes (but there look to have been\nonly 313 of them, which is fortunate; even still they're 12% of the\ntransfer volume).</p>\n\n<p>If feed readers didn't do any conditional GETs and I didn't have\nany rate limiting (and all of the requests that got HTTP 429s would\nstill have been made), the additional feed requests would have\namounted to about another 3.5 GBytes of responses sent out to people.\nObviously feed readers did do conditional GETS, and 66% of their\nnon rate limited requests were successful conditional GETs.  A HTTP\n200 response ratio of 44% is probably too pessimistic once we include\nrate limited requests, so as an extreme approximation we'll guess\nthat 33% of the rate limited requests would have received HTTP 200\nresponses with a changed feed; that would amount to another 677\nMBytes of response traffic (which is less than I expected). If we\nuse the 44% HTTP 200 ratio, it's still only 903 MBytes more.</p>\n\n<p>(This 44% rate may sound high but my syndication feed changes any\ntime someone leaves a comment on a recent entry, because the\nsyndication feed of entries includes a comment count for every\nentry.)</p>\n\n<p>Another statistic is that 41% of syndication feed requests yesterday\ngot HTTP 429 responses. The most prolific single IP address received\n950 HTTP 429s, <a href=\"https://utcc.utoronto.ca/~cks/space/blog/web/WebRequestTotalsToRequestRates\">which maps to an average request interval of less\nthan two minutes between requests</a>.\nAnother prolific source made 779 requests, which again amounts to\nan interval of just less than two minutes. There are over 20 single\nIPs that received more than 96 HTTP 429 responses (which corresponds\nto an average interval of 15 minutes). There is a lot of syndication\nfeed fetching software out there that is fetching quite frequently.</p>\n\n<p>(Trying to figure out how many HTTP 429 sources did conditional\nrequests is too complex with my current logs, since I don't directly\nrecord that information.)</p>\n\n<p>You can avoid the server performance impact of lots of feed fetching\nby arranging to serve syndication feeds from static files instead\nof a dynamic system (and then you can limit how frequently you\nupdate those files, effectively forcing a maximum number of HTTP\n200 fetches per time interval on anything that does conditional\nGETs). You can't avoid the bandwidth effects, and serving from\nstatic files generally leaves you with only modest tools for rate\nlimiting.</p>\n\n<p>PS: The syndication feeds for <a href=\"https://utcc.utoronto.ca/~cks/space/blog/\">Wandering Thoughts</a> are so big\nbecause I've opted to default to 100 entries in them, but I maintain\nyou should be able to do this sort of thing without having your\nbandwidth explode.</p>\n</div>\n<div> (<a href=\"https://utcc.utoronto.ca/~cks/space/blog/web/FeedLimitingImportance?showcomments#comments\">4 comments</a>.) </div>",
    "description": "",
    "is_fulltext": true,
    "source": "Chris's Wiki :: blog",
    "pub_date": "2026-02-22T01:28:35Z",
    "fetched_at": "2026-02-23T00:38:44.210820",
    "url_hash": "cc31f956b5ba5e64f4a9c697ab6b7dc8"
  },
  {
    "title": "Bitcoin mining difficulty",
    "link": "https://www.johndcook.com/blog/2026/02/22/bitcoin-mining-difficulty/",
    "content": "<p>The previous post looked at the Bitcoin network <a href=\"https://www.johndcook.com/blog/2026/02/22/zettahash/\">hash rate</a>, currently around one zettahash per second, i.e. 10<sup>21</sup> hashes per second. The difficulty of mining a Bitcoin block adjusts over time to keep the rate of block production relatively constant, around one block every 10 minutes. The plot below shows this in action.</p>\n<p><img fetchpriority=\"high\" decoding=\"async\" class=\"aligncenter size-medium\" src=\"https://www.johndcook.com/triple.png\" alt=\"Bitcoin hash rate, difficulty, and ratio of the two\" width=\"1440\" height=\"802\" /></p>\n<p>Notice the difficulty graph is more quantized than the hash rate graph. This is because the difficulty changes every 2,016 blocks, or about every two weeks. The number 2016 was chosen to be the number of blocks that would be produced in two weeks if every block took exactly 10 minutes to create.</p>\n<p>The ratio of the hash rate to difficulty is basically constant with noise. The noticeable dip in mid 2021 was due to China cracking down on Bitcoin mining. This caused the hash rate to drop suddenly, and it took a while for the difficulty level to be adjusted accordingly.</p>\n<h2>Mining difficulty</h2>\n<p>At the current difficulty level, how many hashes would it take to mine a Bitcoin block if there were no competition? How does this compare to the number of hashes the network computes during this time?</p>\n<p>To answer these questions, we have to back up a bit. The current mining difficulty is around 10<sup>14</sup>, but what does that mean?</p>\n<p>The original Bitcoin mining task was to produce a hash [1] with 32 leading zeros. On average, this would take 2<sup>32</sup> attempts. Mining difficulty is defined so that the original mining difficult was 1 and current mining difficulty is proportional to the expected number of hashes needed. So a difficulty of around 10<sup>14</sup> means that the expected number of hashes is around</p>\n<p style=\"padding-left: 40px;\">10<sup>14</sup> × 2<sup>32</sup> = 4.3 × 10<sup>23</sup>.</p>\n<p>At one zetahash per second, the number of hashes computed by the entire network over a 10 minute interval would be</p>\n<p style=\"padding-left: 40px;\">10<sup>21</sup> × 60 × 10 = 6 × 10<sup>23</sup>.</p>\n<p>So the number of hashes computed by the entire network is only about 40% greater than what would be necessary to mine a block without competition.</p>\n<h2>Related posts</h2>\n<ul>\n<li class=\"link\"><a href=\"https://www.johndcook.com/blog/2025/06/20/bitcoin-proof-of-work/\">What exactly is the Bitcoin proof-of-work task?&lt;/a?</a></li>\n<li class=\"link\"><a href=\"https://www.johndcook.com/blog/2019/07/20/hashing-pii-does-not-protect-privacy/\">Hashing names does not adequately protect privacy</a></li>\n<li class=\"link\"><a href=\"https://www.johndcook.com/blog/crypto/\">Blockchains and cryptocurrencies</a></li>\n</ul>\n<p>[1] The hash function used in Bitcoin&#8217;s proof of work is double SHA256, i.e. the Bitcoin hash of <em>x</em> is SHA256( SHA256( <em>x</em> ) ). So a single Bitcoin hash consists of two applications of the SHA256 hash function.</p>The post <a href=\"https://www.johndcook.com/blog/2026/02/22/bitcoin-mining-difficulty/\">Bitcoin mining difficulty</a> first appeared on <a href=\"https://www.johndcook.com/blog\">John D. Cook</a>.",
    "description": "The previous post looked at the Bitcoin network hash rate, currently around one zettahash per second, i.e. 1021 hashes per second. The difficulty of mining a Bitcoin block adjusts over time to keep the rate of block production relatively constant, around one block every 10 minutes. The plot below shows this in action. Notice the [&#8230;] The post Bitcoin mining difficulty first appeared on John D. Cook.",
    "is_fulltext": true,
    "source": "John D. Cook",
    "pub_date": "Sun, 22 Feb 2026 19:17:58 +0000",
    "fetched_at": "2026-02-23T00:38:59.525873",
    "url_hash": "13e10477df9b0e713463e7fc01046773"
  },
  {
    "title": "Nerd Quiz #4",
    "link": "https://susam.net/code/news/nq/4.0.0.html",
    "content": "\n\n<p>\n  Nerd Quiz #4 is the fourth instalment of Nerd Quiz, a single page\n  HTML application that challenges you to measure your inner geek with\n  a brief quiz.  Each question in the quiz comes from everyday moments\n  of reading, writing, thinking, learning and exploring.\n</p>\n<p>\n  This release introduces five new questions drawn from a range of\n  topics, including computing history, graph theory and Unix.\n  Visit <a href=\"../../../nq.html#4\">Nerd Quiz</a> to try the quiz.\n</p>\n<p>\n  A community discussion page is\n  <a href=\"../../../comments/nq.html\">available here</a>.  You are\n  very welcome to share your score or discuss the questions there.\n</p>\n<!-- ### -->\n<p>\n  <a href=\"https://susam.net/code/news/nq/4.0.0.html\">Read on website</a> |\n  <a href=\"https://susam.net/tag/web.html\">#web</a> |\n  <a href=\"https://susam.net/tag/miscellaneous.html\">#miscellaneous</a> |\n  <a href=\"https://susam.net/tag/game.html\">#game</a>\n</p>\n\n",
    "description": "Nerd Quiz #4 is the fourth instalment of Nerd Quiz, a single page HTML application that challenges you to measure your inner geek with a brief quiz. Each question in the quiz comes from everyday moments of reading, writing, thinking, learning and exploring. This release introduces five new questions drawn from a range of topics, including computing history, graph theory and Unix. Visit Nerd Quiz to try the quiz. A community discussion page is available here. You are very welcome to share your sc",
    "is_fulltext": false,
    "source": "Susam Pal",
    "pub_date": "Sun, 22 Feb 2026 00:00:00 +0000",
    "fetched_at": "2026-02-23T00:39:08.628209",
    "url_hash": "6e9df57e0882d4f559df7cf7f732f203"
  },
  {
    "title": "Which web frameworks are most token-efficient for AI agents?",
    "link": "https://martinalderson.com/posts/which-web-frameworks-are-most-token-efficient-for-ai-agents/?utm_source=rss",
    "content": "I benchmarked 19 web frameworks on how efficiently an AI coding agent can build and extend the same app. Minimal frameworks cost up to 2.9x fewer tokens than full-featured ones.",
    "description": "I benchmarked 19 web frameworks on how efficiently an AI coding agent can build and extend the same app. Minimal frameworks cost up to 2.9x fewer tokens than full-featured ones.",
    "is_fulltext": false,
    "source": "Martin Alderson",
    "pub_date": "Mon, 23 Feb 2026 00:00:00 GMT",
    "fetched_at": "2026-02-23T00:39:33.356994",
    "url_hash": "c4f6bca386de092193c33be60466d743"
  }
]