[
  {
    "title": "Quoting claude.com/import-memory",
    "link": "https://simonwillison.net/2026/Mar/1/claude-import-memory/#atom-everything",
    "content": "\n    <blockquote cite=\"https://claude.com/import-memory\"><p><code>I'm moving to another service and need to export my data. List every memory you have stored about me, as well as any context you've learned about me from past conversations. Output everything in a single code block so I can easily copy it. Format each entry as: [date saved, if available] - memory content. Make sure to cover all of the following — preserve my words verbatim where possible: Instructions I've given you about how to respond (tone, format, style, 'always do X', 'never do Y'). Personal details: name, location, job, family, interests. Projects, goals, and recurring topics. Tools, languages, and frameworks I use. Preferences and corrections I've made to your behavior. Any other stored context not covered above. Do not summarize, group, or omit any entries. After the code block, confirm whether that is the complete set or if any remain.</code></p></blockquote>\n<p class=\"cite\">&mdash; <a href=\"https://claude.com/import-memory\">claude.com/import-memory</a>, Anthropic's \"import your memories to Claude\" feature is a prompt</p>\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/prompt-engineering\">prompt-engineering</a>, <a href=\"https://simonwillison.net/tags/llm-memory\">llm-memory</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/claude\">claude</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a></p>\n\n\n\n",
    "description": "I'm moving to another service and need to export my data. List every memory you have stored about me, as well as any context you've learned about me from past conversations. Output everything in a single code block so I can easily copy it. Format each entry as: [date saved, if available] - memory content. Make sure to cover all of the following — preserve my words verbatim where possible: Instructions I've given you about how to respond (tone, format, style, 'always do X', 'never do Y'). Persona",
    "is_fulltext": true,
    "source": "Simon Willison's Weblog",
    "pub_date": "2026-03-01T11:21:45+00:00",
    "fetched_at": "2026-03-01T12:14:48.209468",
    "url_hash": "0c55a3e7235b56bbbbeb572b5e001688"
  },
  {
    "title": "Redis patterns for coding",
    "link": "\nhttp://antirez.com/news/161\n",
    "content": "Here LLM and coding agents can find:\n<br>\n<br>1. Exhaustive documentation about Redis commands and data types.\n<br>2. Patterns commonly used.\n<br>3. Configuration hints.\n<br>4. Algorithms that can be mounted using Redis commands.\n<br>\n<br>https://redis.antirez.com/\n<br>\n<br>Some humans claim this documentation is actually useful for actual people, as well :) I'm posting this to make sure search engines will index it.\n<a href=\"http://antirez.com/news/161\">Comments</a>",
    "description": "Here LLM and coding agents can find: 1. Exhaustive documentation about Redis commands and data types. 2. Patterns commonly used. 3. Configuration hints. 4. Algorithms that can be mounted using Redis commands. https://redis.antirez.com/ Some humans claim this documentation is actually useful for actual people, as well :) I'm posting this to make sure search engines will index it. Comments",
    "is_fulltext": false,
    "source": "\n<antirez>\n",
    "pub_date": "Sun, 01 Mar 2026 10:55:09 +0100",
    "fetched_at": "2026-03-01T12:14:52.604913",
    "url_hash": "723a4e894eefbf0519e9e4b330bc9b8c"
  },
  {
    "title": "&ldquo;How old are you?&rdquo; Asked the OS",
    "link": "https://idiallo.com/byte-size/how-old-are-you-asked-the-os?src=feed",
    "content": "\n\t\t\t\t\t\n\t\t\t<p>A new law passed in California to require every operating system to collect the user's age at account creation time. The law is <a href=\"https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260AB1043\">AB-1043</a>. And it was passed in October of 2025. </p>\n\n<p>How does it work? Does it apply to offline systems? When I set up my Raspberry Pi at home, is this enforced? What if I give an incorrect age, am I breaking the law now? What if I set my account correctly, but then my kids use the device? What happens?</p>\n\n<p>There is no way to enforce this law, but I suspect that's not the point. It's similar to statements you find in IRS documents. The IRS requires you to report all income from illegal activities, such as bribes and scams. Obviously, if you are getting a bribe, you wouldn't report it, but by not reporting it you are breaking additional laws that can be used to get you prosecuted.</p>\n\n<p>When you don't report your age to your OS whether it's a windows device or a Tamagotchi, you are breaking the law. It's not enforced of course, but when you are suspected of any other crime, you can be arrested for the age violation first, then prosecuted for something else. </p>\n\n<p>What a world we live in.</p>\n\t\t\t\n\t\t\t\n\t\t\t\t",
    "description": "A new law passed in California to require every operating system to collect the user's age at account creation time. The law is AB-1043. And it was passed in October of 2025. How does it work? Does it apply to offline systems? When I set up my Raspberry Pi at home, is this enforced? What if I give an incorrect age, am I breaking the law now? What if I set my account correctly, but then my kids use the device? What happens? There is no way to enforce this law, but I suspect that's not the point. ",
    "is_fulltext": true,
    "source": "iDiallo.com",
    "pub_date": "Sun, 01 Mar 2026 01:43:17 GMT",
    "fetched_at": "2026-03-01T12:14:53.220958",
    "url_hash": "797d941dfe3c39589ab8b39fed31ebc8"
  },
  {
    "title": "Why does C have the best file API?",
    "link": "https://maurycyz.com/misc/c_files/",
    "content": "<!-- mksite: start of content -->\n<p>\n\nThere are a lot of nice programming languages, but files always seem like an afterthought. \nYou usually only get read(), write() and some kind of serialization library.\n</p><p>\nIn C, you can access files exactly the same as data in memory:\n<!-- snip -->\n</p>\n<p>\n</p>\n<style>\n/* HTML tags, keywords, commands */\nh-n {color: #F27;}\n/* Values */\nh-v {color: #B8F;}\n/* CSS selectors, attribute/varable names, file names */\nh-s {color: #AEE;}\n/* Comments */\nh-c {color: #777;}\nh-e {color: #F6F;}\n</style>\n<pre>\n<h-c>#include &lt;sys/mman.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;</h-c>\n\n<h-n>void</h-n> <h-s>main</h-s>() {\n\t<h-c>// Create/open a file containing 1000 unsigned integers</h-c>\n\t<h-c>// Initialized to all zeros.</h-c>\n\t<h-n>int</h-n> <h-s>len</h-s> = <h-v>1000</h-v> * <h-n>sizeof</h-n>(<h-v>uint32_t</h-v>);\n\t<h-n>int</h-n> <h-s>file</h-s> = <h-n>open</h-n>(<h-v>\"numbers.u32\"</h-v>, <h-v>O_RDWR</h-v> | <h-v>O_CREAT</h-v>, <h-v>0600</h-v>);\n\t<h-n>ftruncate</h-n>(<h-s>file</h-s>, <h-s>len</h-s>);\n\n\t<h-c>// Map it into memory.</h-c>\n\t<h-n>uint32_t</h-n>* <h-s>numbers</h-s> = <h-n>mmap</h-n>(<h-v>NULL</h-v>, <h-s>len</h-s>, \n\t\t<h-v>PROT_READ</h-v> | <h-v>PROT_WRITE</h-v>, <h-v>MAP_SHARED</h-v>,\n\t\t<h-s>file</h-s>, <h-v>0</h-v>);\n\n\t<h-c>// Do something:</h-c>\n\t<h-n>printf</h-n>(<h-v>\"%d\\n\"</h-v>, <h-s>numbers</h-s>[<h-v>42</h-v>]);\n\t<h-s>numbers</h-s>[<h-v>42</h-v>] = <h-s>numbers</h-s>[<h-v>42</h-v>] + <h-v>1</h-v>;\n\n\t<h-c>// Clean up</h-c>\n\t<h-n>munmap</h-n>(<h-s>numbers</h-s>, <h-s>len</h-s>);\n\t<h-n>close</h-n>(<h-s>file</h-s>);\n}\n</pre>\n<p>\nMemory mapping isn't the same as loading a file into memory:\nIt still works if the file doesn't fit in RAM.\nData is loaded as needed, so it won't take all day to open a terabyte file.\n</p><p>\nIt works with all datatypes and is automatically cached.\nThis cache is cleared automatically if the system needs memory for something else.\n</p><p>\n<em>However, in other most languages</em>,\nyou have to read() in tiny chunks, parse, process, serialize and finally write() it back to the disk.\nThis works, but is slow and needlessly limited to sequential access:\nComputers haven't used tape for decades.\n</p><p>\n<em>If you're lucky enough to have memory mapping</em>, it will be limited to byte arrays,\nwhich still require explicit parsing/serialization.\nIt ends up as just a nicer way to call read() and write()\n</p><p>\nConsidering that most languages already support custom allocators, adding a better way to access files seems very doable...\nbut, as far as I'm aware, C is the only language that lets you specify a binary format and just use it.\n</p><p>\nC's implemenation isn't even very good:\nMemory mapping comes some overhead (page faults, TLB flushes) and C does nothing to handle endianness &mdash;\nbut it doesn't take much to beat nothing. \n</p><p>\n<em>Sure, you might want to do some parsing and validation</em>, but this shouldn't be required every time data leaves the disk. \nWhen working with larger data, it's very common to run out of memory, making it impossible to just parse everything into RAM.\nBeing able to just offload data without complicating the code is very useful.\n</p><p>\nJust look at Python's pickle:\nit's a completely insecure serialization format.\nLoading a file can cause code execution even if you just wanted some numbers...\nbut still very widely used because it fits with the mix-code-and-data model of python.\n</p><p>\nA lot of files are not untrusted. \n</p><p>\n<em>File manipulation</em> is similarly neglected. \nThe filesystem is the original NoSQL database, but you seldom get more then a wrapper around C's readdir().\n</p><p>\nThis usually results in people running another database, such as SQLite, on top of the filesystem,\nbut relational databases never quite fit your program. \n</p><p>\n... and SQL integrates even worse than files:\nOn top of having to serialize all your data, you have to write code in a whole separate language just to access it!\n</p><p>\nMost programmers just use it as a key-value store, and implement their own metadata handling:\ncreating a bizarre triple nested database.\n</p><p>\n<em>So to answer the title,</em>\nI think it's a result of a bad assumption:\nThat data being read from a file is coming from somewhere else and needs to be parsed...\nand that data being written to disk is being sent somewhere and needs to be serialized into a standard format. \n</p><p>\nThis simply isn't true on memory constrained systems &mdash;\nand with 100 GB files &mdash; \nevery system is memory constrained.\n</p>\n<!-- mksite: end of content -->\n\t\t\t\t",
    "description": "There are a lot of nice programming languages, but files always seem like an afterthought. You usually only get read(), write() and some kind of serialization library. In C, you can access files exactly the same as data in memory: /* HTML tags, keywords, commands */ h-n {color: #F27;} /* Values */ h-v {color: #B8F;} /* CSS selectors, attribute/varable names, file names */ h-s {color: #AEE;} /* Comments */ h-c {color: #777;} h-e {color: #F6F;} #include &lt;sys/mman.h&gt; #include &lt;stdio.h&gt; ",
    "is_fulltext": true,
    "source": "Maurycy's Blog",
    "pub_date": "Sat, 28 Feb 2026 00:00:00 +0000",
    "fetched_at": "2026-03-01T12:14:54.183229",
    "url_hash": "586dbadae68f1ab4b0e29d22a4cbe389"
  },
  {
    "title": "Downstream Testing",
    "link": "https://nesbitt.io/2026/03/01/downstream-testing.html",
    "content": "<p>The information about how a library is actually used lives in the dependents’ code, not in the library’s own tests or docs. Someone downstream is parsing your error messages with a regex, or relying on the iteration order of a result set you never documented, or depending on a method you consider internal because it wasn’t marked private in a language that doesn’t enforce visibility. <a href=\"https://www.hyrumslaw.com/\">Hyrum’s Law</a> says all of these implicit contracts exist once you have enough users, and semver can’t help because a version number declares what the maintainer intended, not what downstream code actually depends on. A <a href=\"https://hasel.auckland.ac.nz/2023/11/12/understanding-breaking-changes-in-the-wild/\">2023 study of Maven</a> found that 11.58% of dependency updates contain breaking changes that impact clients, and nearly half arrived in non-major version bumps. Most library maintainers have no way to validate their version number before publishing, so the feedback loop is reactive: release, wait for bug reports, and hope the breakage wasn’t too widespread before you can cut a patch.</p>\n\n<h3 id=\"distributions\">Distributions</h3>\n\n<p>Debian packages declare test suites following the DEP-8 specification, and when a package is a candidate for migration from unstable to testing, the migration tool Britney triggers <a href=\"https://wiki.debian.org/autopkgtest\">autopkgtest</a> for the package and all of its reverse dependencies. A regression blocks migration, so an Expat update that causes test failures in its dependents sits in unstable until someone resolves them, and a Coq update that broke mathcomp-analysis and mathcomp-finmap did the same. The maintainer finds out who they broke and how before the change reaches anyone who didn’t opt into unstable.</p>\n\n<p>Autopkgtest doesn’t check API compatibility. It runs actual test suites of actual consumers, which encode whatever implicit contracts those consumers have built against, including ones the upstream maintainer has never heard of. If library Y changes the sort order of a hash table in a patch release and package X’s tests assumed that order was stable, migration blocks until someone decides whose assumption was wrong.</p>\n\n<p>Fedora’s recent work with <a href=\"https://cockpit-project.org/blog/tmt-cross-project-testing.html\">tmt, Packit, and Testing Farm</a> runs downstream tests in the PR, before anything is released. The Cockpit project configured it so that opening a PR on their core library automatically runs the test suites of cockpit-podman and other dependents against the proposed change, with results showing up as status checks before merge. As they put it, “it is too late at the distro level anyway: at that point the new upstream release which includes the regression was already done, and the culprit landed possibly weeks ago already.”</p>\n\n<p>When a maintainer discovers breakage in a PR, they’re still inside the change. They remember why they restructured that error path, they know which tests they considered, and the diff is right in front of them. The cost of responding to a downstream failure at this point is a few minutes of thought and maybe a revised approach. When the same breakage surfaces as an issue filed three weeks after release, the maintainer has to reload the context of the change, understand the downstream project’s usage well enough to see why it broke, decide whether to fix forward or revert, cut a new release, and hope that consumers who already pinned away will unpin. The information is the same in both cases, a downstream test failed, but the cost of acting on it scales with the distance from the change that caused it.</p>\n\n<p>Debian’s autopkgtest catches breakage before migration to testing, which is better than catching it after, but the change has already been released upstream by that point. The Fedora approach catches it before the upstream release happens at all, which means the maintainer can fix it before anyone outside their own CI ever encounters it. František Lachman and Cristian Le presented the PTE project at <a href=\"https://fosdem.org/2026/schedule/event/MCNHUF-from-code-to-distribution-testing-pipeline/\">FOSDEM</a>. Downstream feedback that arrives while you’re still writing the code changes how you think about the change itself.</p>\n\n<h3 id=\"language-ecosystems\">Language ecosystems</h3>\n\n<p>Distributions can do this because they have structural properties that language ecosystems lack: a single canonical dependency graph, a standardized test interface (DEP-8 in Debian’s case), a shared execution environment where every package builds and runs the same way, and the authority to block a release based on downstream results. npm, PyPI, and RubyGems have fragmented tooling, no standard way to invoke a package’s tests from outside its own repo, heterogeneous execution environments, and no mechanism to gate a publish on anything other than the maintainer’s own judgement. A few language ecosystems have built partial versions of downstream testing anyway, though they tend to belong to compiler teams with the resources to work around these gaps.</p>\n\n<p>Rust’s <a href=\"https://github.com/rust-lang/crater\">crater</a> compiles and tests every crate on crates.io against both the current and proposed compiler, then diffs the results. A recent <a href=\"https://github.com/rust-lang/rust/pull/142723\">PR adding <code class=\"language-plaintext highlighter-rouge\">impl From&lt;f16&gt; for f32</code></a> to the standard library broke 3,143 crates out of 650,587 tested. Adding a trait implementation is unambiguously backwards-compatible by semver’s rules, but it broke type inference in thousands of downstream projects because existing code depended on there being exactly one conversion path between those types. Crater caught it before it shipped, during a run that took five to six days across Linux x86_64. Without it, the Rust team would have discovered the breakage from 3,143 individual bug reports.</p>\n\n<p>Crater also benefits from Rust being compiled: a type inference failure shows up at build time, before any tests run. In Python, Ruby, or JavaScript, the equivalent breakage only surfaces at runtime, so you need downstream test suites that actually exercise the affected code paths, and those code paths need to be covered in the first place. The case for downstream testing is stronger in dynamic ecosystems because there’s no compile step to catch the easy ones, and the signal is harder to get.</p>\n\n<p>Node.js runs <a href=\"https://github.com/nodejs/citgm\">CITGM</a> (Canary in the Goldmine), which tests about 80 curated npm packages against proposed Node versions. A refactor in Node 12 moved <code class=\"language-plaintext highlighter-rouge\">isFile</code> from <code class=\"language-plaintext highlighter-rouge\">Stats.prototype</code> to <code class=\"language-plaintext highlighter-rouge\">StatsBase.prototype</code>, changing nothing about the public API but breaking the esm module because it walked the prototype chain directly. In a separate release, a change to the timing of a <code class=\"language-plaintext highlighter-rouge\">readable</code> event on EOF broke the dicer module, which depended on that event firing synchronously.</p>\n\n<p>All of these were built by teams with dedicated infrastructure budgets and release processes, and an individual library maintainer who publishes a widely-used package on npm or PyPI or RubyGems has nothing comparable, even though they face the same problem at a different scale.</p>\n\n<h3 id=\"merge-confidence\">Merge confidence</h3>\n\n<p>Renovate’s <a href=\"https://docs.renovatebot.com/merge-confidence/\">Merge Confidence</a> aggregates data from millions of update PRs to tell consumers whether an update is safe: how old the release is, what percentage of Renovate users have adopted it, and what percentage of updates result in passing tests. The signal comes from real test results across real projects, but it arrives after the release and flows to consumers, never back to the maintainer who shipped the change. The algorithm is private, and the underlying dataset of which updates broke which projects’ tests stays behind Mend’s paywall. Dependabot shows a <a href=\"https://docs.github.com/en/code-security/dependabot/dependabot-security-updates/about-dependabot-security-updates\">compatibility score</a> on security update PRs, calculated from CI results across other public repos that made the same update, but only when at least five candidate updates exist, and the data doesn’t flow back to the maintainer either. I’ve started indexing Dependabot PRs at <a href=\"https://dependabot.ecosyste.ms\">dependabot.ecosyste.ms</a> to build an open version of this signal. It doesn’t have CI data yet, but it already tracks merge percentages per update, which gives a rough proxy for how much trouble a particular version bump is causing across the ecosystem.</p>\n\n<h3 id=\"discovery\">Discovery</h3>\n\n<p>Registries track which packages declare dependencies on other packages, but applications that consume libraries are mostly invisible: a Rails app that depends on a gem won’t show up in RubyGems’ reverse dependency list, and a company’s internal service using an npm package won’t appear on npmjs.com. The maintainer’s view of their dependents is limited to whatever the registry can see, which skews heavily toward other libraries and misses the applications, which are where the stranger usage patterns and more surprising implicit contracts show up.</p>\n\n<p><a href=\"https://ecosyste.ms\">ecosyste.ms</a> tracks dependents across both packages and open source repositories, scanning millions of repos on GitHub, GitLab, and other forges for manifest files that declare dependencies. A maintainer can see which applications actually use their library, which is the view you’d need to build a downstream testing system on.</p>\n\n<h3 id=\"building-it\">Building it</h3>\n\n<p>This is something I want to build on top of ecosyste.ms. A maintainer connects the service to their CI, and on every PR or pre-release branch it queries ecosyste.ms for the top N dependents of the package, both libraries and applications, ranked by some combination of dependent count, download volume, and recency of commits. It clones each one, installs the proposed version of the library in place of the current release, and runs their test suite in an isolated environment. The results come back as a report on the PR: which dependents were tested, which ones regressed, what the stack traces look like, which of the maintainer’s changes likely caused each failure.</p>\n\n<p>A maintainer looking at that report before tagging a release would see things that are currently invisible to them. They’d see that popular applications parse their error messages with regex and will break if the wording changes, that a widely-used wrapper library calls a method they considered internal and were about to remove, that their optimisation to batch database calls changed the callback order in a way that two downstream projects’ integration tests depend on.</p>\n\n<p>Michal Gorny’s <a href=\"https://mgorny.pl/articles/downstream-testing-python-packages.html\">catalogue of problems with downstream testing Python packages</a> lays out the failure modes: test suites that modify installed files assuming they’re in a disposable container, pytest plugins in the environment causing unexpected test collection, tests requiring network access or Docker, timing-dependent assertions, floating-point precision differences across architectures, source distributions that omit test files entirely. Any service trying this across a registry would need to handle all of these gracefully, distinguishing genuine regressions from environmental noise, which is a hard problem that Debian has spent years refining with autopkgtest and still hasn’t fully solved.</p>\n\n<p>ecosyste.ms already provides the dependent discovery, source repositories are linked from package metadata, test suites follow ecosystem conventions that are well-understood enough to automate, and container infrastructure makes isolated environments cheap. Crater and autopkgtest have proven the approach works at ecosystem scale.</p>",
    "description": "Most library maintainers have no way to test against their dependents before releasing.",
    "is_fulltext": true,
    "source": "Andrew Nesbitt",
    "pub_date": "2026-03-01T00:00:00+00:00",
    "fetched_at": "2026-03-01T12:15:30.188409",
    "url_hash": "4374fa68a2cf6c535d2c7bd10f8c723c"
  },
  {
    "title": "Notes on Lagrange Interpolating Polynomials",
    "link": "https://eli.thegreenplace.net/2026/notes-on-lagrange-interpolating-polynomials/",
    "content": "<p><em>Polynomial interpolation</em> is a method of finding a polynomial function\nthat fits a given set of data perfectly. More concretely, suppose we\nhave a set of <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> distinct points <a class=\"footnote-reference\" href=\"#footnote-1\" id=\"footnote-reference-1\">[1]</a>:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/e3ee741ff781bf26237c69b505322eb378075e89.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\[(x_0,y_0), (x_1, y_1), (x_2, y_2)\\cdots(x_n, y_n)\\]</object>\n<p>And we want to find the polynomial coefficients <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/3cb777352d19998f6099864dfe85849e46fd0d8c.svg\" style=\"height: 11px;\" type=\"image/svg+xml\">{a_0\\cdots a_n}</object>\nsuch that:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/4aff81770a1cc10239926be6d6676eb37fba719d.svg\" style=\"height: 22px;\" type=\"image/svg+xml\">\\[p(x)=a_0 + a_1 x + a_2 x^2 + \\cdots + a_n x^n\\]</object>\n<p>Fits all our points; that is <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/9bee0b2482233e55d638019ff5324f45ce5c0134.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x_0)=y_0</object>, <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/1066a27080e8f4f98e1e837c563063ce09929300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x_1)=y_1</object> etc.</p>\n<p>This post discusses a common approach to solving this problem, and also\nshows why such a polynomial exists and is unique.</p>\n<div class=\"section\" id=\"showing-existence-using-linear-algebra\">\n<h2>Showing existence using linear algebra</h2>\n<p>When we assign all points <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/fac14e12be52903f4008e439178230b3eefb437a.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">(x_i, y_i)</object> into the generic polynomial\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/7f86e6c6bb632c1ca2518f269fc1cc1b6737d4f7.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x)</object>, we get:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/708bd02c5cc4f2ddb0dbc93967053e55853683d3.svg\" style=\"height: 134px;\" type=\"image/svg+xml\">\\[\\begin{aligned}\np(x_0)&amp;=a_0 + a_1 x_0 + a_2 x_0^2 + \\cdots a_n x_0^n = y_0\\\\\np(x_1)&amp;=a_0 + a_1 x_1 + a_2 x_1^2 + \\cdots a_n x_1^n = y_1\\\\\np(x_2)&amp;=a_0 + a_1 x_2 + a_2 x_2^2 + \\cdots a_n x_2^n = y_2\\\\\n\\cdots \\\\\np(x_n)&amp;=a_0 + a_1 x_n + a_2 x_n^2 + \\cdots a_n x_n^n = y_n\\\\\n\\end{aligned}\\]</object>\n<p>We want to solve for the coefficients <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/1ba9b59bdee92f38c1698c784b67ba70f803331d.svg\" style=\"height: 11px;\" type=\"image/svg+xml\">a_i</object>. This is a linear\nsystem of equations that can be represented by the following matrix\nequation:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/4352a3b8e07b33cc419089f1c48e0b360c9200e5.svg\" style=\"height: 159px;\" type=\"image/svg+xml\">\\[{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n     1 &amp; x_0 &amp; x_0^2 &amp; \\dots &amp; x_0^n\\\\\n     1 &amp; x_1 &amp; x_1^2 &amp; \\dots &amp; x_1^n\\\\\n     1 &amp; x_2 &amp; x_2^2 &amp; \\dots &amp; x_2^n\\\\\n     \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n     1 &amp; x_n &amp; x_n^2 &amp; \\dots &amp; x_n^n\n \\end{bmatrix}\n \\begin{bmatrix}\n     a_0\\\\\n     a_1\\\\\n     a_2\\\\\n     \\vdots\\\\\n     a_n\\\\\n \\end{bmatrix}=\n \\begin{bmatrix}\n     y_0\\\\\n     y_1\\\\\n     y_2\\\\\n     \\vdots\\\\\n     y_n\\\\\n \\end{bmatrix}\n }\\]</object>\n<p>The matrix on the left is called the <em>Vandermonde matrix</em>. This matrix\nis known to be invertible (see Appendix for a proof); therefore, this\nsystem of equations has a single solution that can be calculated by\ninverting the matrix.</p>\n<p>In practice, however, the Vandermonde matrix is often numerically\nill-conditioned, so inverting it isn’t the best way to calculate exact\npolynomial coefficients. Several better methods exist.</p>\n</div>\n<div class=\"section\" id=\"lagrange-polynomial\">\n<h2>Lagrange Polynomial</h2>\n<p>Lagrange interpolation polynomials emerge from a simple, yet powerful\nidea. Let’s define the <em>Lagrange basis</em> functions <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object>\n(<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/71047ffb369f30ea7df6aad7d69de2edc1eca912.svg\" style=\"height: 18px;\" type=\"image/svg+xml\">i \\in [0, n]</object>) as follows, given our points <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/fac14e12be52903f4008e439178230b3eefb437a.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">(x_i, y_i)</object>:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/5e4d0981c95e59436de02cb6fc85dcdcf4537f1b.svg\" style=\"height: 54px;\" type=\"image/svg+xml\">\\[l_i(x) =\n\\begin{cases}\n    1      &amp; x = x_i \\\\\n    0      &amp; x = x_j \\quad \\forall j \\neq i\n\\end{cases}\\]</object>\n<p>In words, <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object> is constrained to 1 at <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" /> and to 0 at\nall other <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/73058e43db0f4edc791b10f27f913cbc5d361ab6.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">x_j</object>. We don’t care about its value at any other point.</p>\n<p>The linear combination:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/9e02d7ad79abe9dd4e108d6e33e02bd6b2cece5e.svg\" style=\"height: 49px;\" type=\"image/svg+xml\">\\[p(x)=\\sum_{i=0}^{n}y_i l_i(x)\\]</object>\n<p>is then a valid interpolating polynomial for our set of <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object>\npoints, because it’s equal to <img alt=\"y_i\" class=\"valign-m4\" src=\"https://eli.thegreenplace.net/images/math/35c2ac2f82d0ff8f9011b596ed7e54bfcc55f471.png\" style=\"height: 12px;\" /> at each <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" /> (take a\nmoment to convince yourself this is true).</p>\n<p>How do we find <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object>? The key insight comes from studying the\nfollowing function:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/ab2f106bd0be79644b4f08e7241d53541fde914c.svg\" style=\"height: 54px;\" type=\"image/svg+xml\">\\[l&#x27;_i(x)=(x-x_0)\\cdot (x-x_1)\\cdots (x-x_{i-1}) \\cdot (x-x_{i+1})\\cdots (x-x_n)=\n\\prod_{\\substack{0\\leq j \\leq n \\\\ j \\neq i}}(x-x_j)\\]</object>\n<p>This function has <img alt=\"n\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/d1854cae891ec7b29161ccaf79a24b00c274bdaa.png\" style=\"height: 8px;\" /> terms <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/ee95074369b77b297d18a5d2500b53463aaf275a.svg\" style=\"height: 20px;\" type=\"image/svg+xml\">(x-x_j)</object> for all\n<object class=\"valign-m4\" data=\"https://eli.thegreenplace.net/images/math/6e1be82fe5bc74efdbe2bd9234f5da2cec90f954.svg\" style=\"height: 17px;\" type=\"image/svg+xml\">j\\neq i</object>. It should be easy to see that <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/f2445af2b56e69160a5ee45a30d1a96a97ea8496.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l&#x27;_i(x)</object> is 0 at\nall <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/73058e43db0f4edc791b10f27f913cbc5d361ab6.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">x_j</object> when <object class=\"valign-m4\" data=\"https://eli.thegreenplace.net/images/math/6e1be82fe5bc74efdbe2bd9234f5da2cec90f954.svg\" style=\"height: 17px;\" type=\"image/svg+xml\">j\\neq i</object>.</p>\n<p>What about its value at <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" />, though? We can just assign\n<img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" /> into <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/f2445af2b56e69160a5ee45a30d1a96a97ea8496.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l&#x27;_i(x)</object> to get:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/c4a71af1b8a616db5347164e5abc488dc888da60.svg\" style=\"height: 54px;\" type=\"image/svg+xml\">\\[l&#x27;_i(x_i)=\\prod_{\\substack{0\\leq j \\leq n \\\\ j \\neq i}}(x_i-x_j)\\]</object>\n<p>And then normalize <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/f2445af2b56e69160a5ee45a30d1a96a97ea8496.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l&#x27;_i(x)</object>, dividing it by this (constant) value. We get\nthe Lagrange basis function <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object>:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/9556fe744ec99f27b47d421edd5e625e072145b5.svg\" style=\"height: 64px;\" type=\"image/svg+xml\">\\[l_i(x)=\\frac{l&#x27;_i(x)}{l&#x27;_i(x_i)}=\\prod_{\\substack{0\\leq j \\leq n \\\\ j \\neq i}}\\frac{x-x_j}{x_i-x_j}\\]</object>\n<p>Let’s use a concrete example to visualize this. Suppose we have the\nfollowing set of points we want to interpolate:\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/eb71287f6f652c4e2753483486714619516e0822.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">(1,4), (2,2), (3,3)</object>. We can calculate <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/efa94b9705d7324c446e2fd3a0f87163cf4a09aa.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l&#x27;_0(x)</object>,\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/35fec30e61d70678416c62035d3dce29fd3ffc5a.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l&#x27;_1(x)</object> and <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/5d4342750343edd5a8607e54a1f6dac771110497.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l&#x27;_2(x)</object>, and get the following:</p>\n<img alt=\"Un-normalized lagrange basis functions for our sample\" class=\"align-center\" src=\"https://eli.thegreenplace.net/images/2026/lagrange-basis.png\" />\n<p>Note where each <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/f2445af2b56e69160a5ee45a30d1a96a97ea8496.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l&#x27;_i(x)</object> intersects the <img alt=\"x\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/11f6ad8ec52a2984abaafd7c3b516503785c2072.png\" style=\"height: 8px;\" /> axis. These\nfunctions have the right values at all <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/3430b1a7366e85d75a89e8ef95fffaa8e0fd36f2.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">x_{j\\neq i}</object>. If we\nnormalize them to obtain <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object>, we get these functions:</p>\n<img alt=\"Normalized lagrange basis functions for our sample\" class=\"align-center\" src=\"https://eli.thegreenplace.net/images/2026/lagrange-basis-normalized.png\" />\n<p>Note that each polynomial is 1 at the appropriate <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" /> and 0 at\nall the other <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/3430b1a7366e85d75a89e8ef95fffaa8e0fd36f2.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">x_{j\\neq i}</object>, as required.</p>\n<p>With these <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object>, we can now plot the interpolating polynomial\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/bc2c6fb1897affc253cf6db77c4f7d4a41a5be32.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x)=\\sum_{i=0}^{n}y_i l_i(x)</object>, which fits our set of input points:</p>\n<img alt=\"Interpolation polynomial\" class=\"align-center\" src=\"https://eli.thegreenplace.net/images/2026/lagrange-inter-poly.png\" />\n</div>\n<div class=\"section\" id=\"polynomial-degree-and-uniqueness\">\n<h2>Polynomial degree and uniqueness</h2>\n<p>We’ve just seen that the linear combination of Lagrange basis functions:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/9e02d7ad79abe9dd4e108d6e33e02bd6b2cece5e.svg\" style=\"height: 49px;\" type=\"image/svg+xml\">\\[p(x)=\\sum_{i=0}^{n}y_i l_i(x)\\]</object>\n<p>is a valid interpolating polynomial for a set of <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> distinct\npoints <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/fac14e12be52903f4008e439178230b3eefb437a.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">(x_i, y_i)</object>. What is its degree?</p>\n<p>Since the degree of each <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object> is <img alt=\"n\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/d1854cae891ec7b29161ccaf79a24b00c274bdaa.png\" style=\"height: 8px;\" />, then the degree of\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/7f86e6c6bb632c1ca2518f269fc1cc1b6737d4f7.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x)</object> is <em>at most</em> <img alt=\"n\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/d1854cae891ec7b29161ccaf79a24b00c274bdaa.png\" style=\"height: 8px;\" />. We’ve just derived the first part\nof the <em>Polynomial interpolation theorem</em>:</p>\n<p><strong>Polynomial interpolation theorem</strong>: for any <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> data points\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/3e2e9500dcfffb808ec380f67db20f6f0804211e.svg\" style=\"height: 20px;\" type=\"image/svg+xml\">(x_0,y_0), (x_1, y_1)\\cdots(x_n, y_n) \\in \\mathbb{R}^2</object> where no\ntwo <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/73058e43db0f4edc791b10f27f913cbc5d361ab6.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">x_j</object> are the same, there exists a unique polynomial\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/7f86e6c6bb632c1ca2518f269fc1cc1b6737d4f7.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x)</object> of degree at most <img alt=\"n\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/d1854cae891ec7b29161ccaf79a24b00c274bdaa.png\" style=\"height: 8px;\" /> that interpolates these points.</p>\n<p>We’ve demonstrated existence and degree, but not yet <em>uniqueness</em>. So\nlet’s turn to that.</p>\n<p>We know that <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/7f86e6c6bb632c1ca2518f269fc1cc1b6737d4f7.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x)</object> interpolates all <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> points, and its\ndegree is <img alt=\"n\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/d1854cae891ec7b29161ccaf79a24b00c274bdaa.png\" style=\"height: 8px;\" />. Suppose there’s another such polynomial\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/90425caaec1646540a7a9049146bf2606d9dbd0d.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">q(x)</object>. Let’s construct:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/b88ab71d9a2c512da829c88eda1adcd5c0191deb.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\[r(x)=p(x)-r(x)\\]</object>\n<p>That do we know about <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/9468a2656a6201bfa194ec81fb0f78352c9666c9.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">r(x)</object>? First of all, its value is 0 at all\nour <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" />, so it has <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> <em>roots</em>. Second, we also know\nthat its degree is at most <img alt=\"n\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/d1854cae891ec7b29161ccaf79a24b00c274bdaa.png\" style=\"height: 8px;\" /> (because it’s the difference of two\npolynomials of such degree). These two facts are a contradiction.\nNo non-zero polynomial of degree <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/189de1175926fa11245f32e4d48aa2a7ab2435b4.svg\" style=\"height: 15px;\" type=\"image/svg+xml\">\\leq n</object> can have\n<object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> roots (a basic algebraic fact related to the <em>Fundamental\ntheorem of algebra</em>). So <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/9468a2656a6201bfa194ec81fb0f78352c9666c9.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">r(x)</object> must be the zero polynomial; in\nother words, our <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/7f86e6c6bb632c1ca2518f269fc1cc1b6737d4f7.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x)</object> is unique <object class=\"valign-0\" data=\"https://eli.thegreenplace.net/images/math/4a4e9e431da45a27bc880a8a1ca44d8b1b9bc143.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">\\blacksquare</object>.</p>\n<p>Note the implication of uniqueness here: given our set of <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object>\ndistinct points, there’s only one polynomial of degree <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/189de1175926fa11245f32e4d48aa2a7ab2435b4.svg\" style=\"height: 15px;\" type=\"image/svg+xml\">\\leq n</object>\nthat interpolates it. We can find its coefficients by inverting the\nVandermonde matrix, by using Lagrange basis functions, or\nany other method <a class=\"footnote-reference\" href=\"#footnote-2\" id=\"footnote-reference-2\">[2]</a>.</p>\n</div>\n<div class=\"section\" id=\"lagrange-polynomials-as-a-basis-for-p-n-mathbb-r\">\n<h2>Lagrange polynomials as a basis for <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/66e617fc4a3781fe03dcf20effb656feaa81a47e.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">P_n(\\mathbb{R})</object></h2>\n<p>The set <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/66e617fc4a3781fe03dcf20effb656feaa81a47e.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">P_n(\\mathbb{R})</object> consists of all real polynomials of\ndegree <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/189de1175926fa11245f32e4d48aa2a7ab2435b4.svg\" style=\"height: 15px;\" type=\"image/svg+xml\">\\leq n</object>. This set - along with addition of polynomials and\nscalar multiplication - <a class=\"reference external\" href=\"https://eli.thegreenplace.net/2026/notes-on-linear-algebra-for-polynomials/\">forms a vector\nspace</a>.</p>\n<p>We called <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object> the &quot;Lagrange basis&quot; previously, and they do -\nin fact - form an actual linear algebra basis for this vector space. To\nprove this claim, we need to show that Lagrange polynomials are linearly\nindependent and that they span the space.</p>\n<p><strong>Linear independence</strong>: we have to show that</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/3469cc3e26dc0483fb111f3993bf06b1c5336c53.svg\" style=\"height: 49px;\" type=\"image/svg+xml\">\\[s(x)=\\sum_{i=0}^{n}a_i l_i(x)=0\\]</object>\n<p>implies <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/936812b8cbbba06fa5948bf8f9393e0bd9abc223.svg\" style=\"height: 15px;\" type=\"image/svg+xml\">a_i=0 \\quad \\forall i</object>. Recall that <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object> is 1\nat <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" />, while all other <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/1695428630aa1a460c0d7eb95749f04017fb8b60.svg\" style=\"height: 20px;\" type=\"image/svg+xml\">l_j(x)</object> are 0 at that point.\nTherefore, evaluating <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/68cee1190d7058555e058756fed1d6527ab89855.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">s(x)</object> at <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" />, we get:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/eda879b68c484c7e88db094e5d4b63e38738503e.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\[s(x_i)=a_i = 0\\]</object>\n<p>Similarly, we can show that <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/1ba9b59bdee92f38c1698c784b67ba70f803331d.svg\" style=\"height: 11px;\" type=\"image/svg+xml\">a_i</object> is 0, for all <img alt=\"i\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/042dc4512fa3d391c5170cf3aa61e6a638f84342.png\" style=\"height: 12px;\" />\n<object class=\"valign-0\" data=\"https://eli.thegreenplace.net/images/math/4a4e9e431da45a27bc880a8a1ca44d8b1b9bc143.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">\\blacksquare</object>.</p>\n<p><strong>Span</strong>: we’ve already demonstrated that the linear combination of\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object>:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/9e02d7ad79abe9dd4e108d6e33e02bd6b2cece5e.svg\" style=\"height: 49px;\" type=\"image/svg+xml\">\\[p(x)=\\sum_{i=0}^{n}y_i l_i(x)\\]</object>\n<p>is a valid interpolating polynomial for any set of <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> distinct\npoints. Using the <em>polynomial interpolation theorem</em>, this is the unique\npolynomial interpolating this set of points. In other words, for every\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/ca8eba083582be9ac48f889214d2f74248955c2f.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">q(x)\\in P_n(\\mathbb{R})</object>, we can identify any set of <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> distinct points it passes\nthrough, and then use the technique described in this post to find the coefficients of <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/90425caaec1646540a7a9049146bf2606d9dbd0d.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">q(x)</object> in the\nLagrange basis. Therefore, the set <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/266681d17d2dc06fe4a139a6c0daa4c5c163b300.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x)</object> spans\nthe vector space <object class=\"valign-0\" data=\"https://eli.thegreenplace.net/images/math/4a4e9e431da45a27bc880a8a1ca44d8b1b9bc143.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">\\blacksquare</object>.</p>\n</div>\n<div class=\"section\" id=\"interpolation-matrix-in-the-lagrange-basis\">\n<h2>Interpolation matrix in the Lagrange basis</h2>\n<p>Previously we’ve seen how to use the <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/dd30851f93c58a2397e24da06afb6c865f1fd4d6.svg\" style=\"height: 20px;\" type=\"image/svg+xml\">\\{1, x, x^2, \\dots x^n\\}</object>\nbasis to write down a system of linear equations that helps us find the\ninterpolating polynomial. This results in the <em>Vandermonde matrix</em>.</p>\n<p>Using the Lagrange basis, we can get a much nicer matrix representation\nof the interpolation equations.</p>\n<p>Recall that our general polynomial using the Lagrange basis is:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/e27577760eb802468c6135d93fa6b761cadd55ea.svg\" style=\"height: 49px;\" type=\"image/svg+xml\">\\[p(x)=\\sum_{i=0}^{n}a_i l_i(x)\\]</object>\n<p>Let’s build a system of equations for each of the <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> points\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/224e78a167ad90c8d6434766a835f152b7adcd44.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">(x_i,y_i)</object>. For <img alt=\"x_0\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png\" style=\"height: 11px;\" />:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/7a62a190b24f3e630c1d267c707dd96329efa545.svg\" style=\"height: 49px;\" type=\"image/svg+xml\">\\[p(x_0)=\\sum_{i=0}^{n}a_i l_i(x_0)\\]</object>\n<p>By definition of the Lagrange basis functions, all <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/dd57195bcdd0b0c2e0f836ee74730425bfd21726.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_i(x_0)</object>\nwhere <object class=\"valign-m4\" data=\"https://eli.thegreenplace.net/images/math/5722358d633306016b737900981a909e904098bd.svg\" style=\"height: 17px;\" type=\"image/svg+xml\">i\\neq 0</object> are 0, while <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/e45ce17273faa377fac587c644355c089905f5f8.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">l_0(x_0)</object> is 1. So this\nsimplifies to:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/c0536313cb1338dd7071c085f52ea51dcb72d79d.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\[p(x_0)=a_0\\]</object>\n<p>But the value at node <img alt=\"x_0\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png\" style=\"height: 11px;\" /> is <img alt=\"y_0\" class=\"valign-m4\" src=\"https://eli.thegreenplace.net/images/math/2bb5817d0f3bf8490a8c7b1343f84f9635e683a3.png\" style=\"height: 12px;\" />, so we’ve just found\nthat <object class=\"valign-m4\" data=\"https://eli.thegreenplace.net/images/math/6df7c1c7fdab6f76ef16a230d6c0b3744017acfd.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">a_0=y_0</object>. We can produce similar equations for the other\nnodes as well, <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/7d5f400d37852b1b57adaf0e21efabada38c8363.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">p(x_1)=a_1</object>, etc. In matrix form:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/7c432b10332759eba03394449c6f7adf0ef3a996.svg\" style=\"height: 159px;\" type=\"image/svg+xml\">\\[{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n     1 &amp; 0 &amp; 0 &amp; \\dots &amp; 0\\\\\n     1 &amp; 0 &amp; 0 &amp; \\dots &amp; 0\\\\\n     1 &amp; 0 &amp; 0 &amp; \\dots &amp; 0\\\\\n     \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n     1 &amp; 0 &amp; 0 &amp; \\dots &amp; 1\n \\end{bmatrix}\n \\begin{bmatrix}\n     a_0\\\\\n     a_1\\\\\n     a_2\\\\\n     \\vdots\\\\\n     a_n\\\\\n \\end{bmatrix}=\n \\begin{bmatrix}\n     y_0\\\\\n     y_1\\\\\n     y_2\\\\\n     \\vdots\\\\\n     y_n\\\\\n \\end{bmatrix}\n }\\]</object>\n<p>We get the identity matrix; this is another way to trivially show that\n<object class=\"valign-m4\" data=\"https://eli.thegreenplace.net/images/math/6df7c1c7fdab6f76ef16a230d6c0b3744017acfd.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">a_0=y_0</object>, <object class=\"valign-m4\" data=\"https://eli.thegreenplace.net/images/math/8491dd4445d9d585827151312ba90e75fc4859fb.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">a_1=y_1</object> and so on.</p>\n</div>\n<div class=\"section\" id=\"appendix-vandermonde-matrix\">\n<h2>Appendix: Vandermonde matrix</h2>\n<p>Given some numbers <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/0f80294ca0e3cea0ce687973ea5aa7202c1c6f44.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\{x_0 \\dots x_n\\}</object> a matrix of this form:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/a1b91b44ffad5324694b37ed4ed07f5de048d55b.svg\" style=\"height: 159px;\" type=\"image/svg+xml\">\\[V=\n{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n1 &amp; x_0 &amp; x_0^2 &amp; \\dots &amp; x_0^n\\\\\n1 &amp; x_1 &amp; x_1^2 &amp; \\dots &amp; x_1^n\\\\\n1 &amp; x_2 &amp; x_2^2 &amp; \\dots &amp; x_2^n\\\\\n\\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n1 &amp; x_n &amp; x_n^2 &amp; \\dots &amp; x_n^n\n\\end{bmatrix}\n}\\]</object>\n<p>Is called the <em>Vandermonde</em> matrix. What’s special about a Vandermonde\nmatrix is that we know it’s invertible when <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" /> are distinct.\nThis is <a class=\"reference external\" href=\"https://mathworld.wolfram.com/InvertibleMatrixTheorem.html\">because its determinant is known to be\nnon-zero</a>.\nMoreover, its determinant is <a class=\"footnote-reference\" href=\"#footnote-3\" id=\"footnote-reference-3\">[3]</a>:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/aeef2af004a7aeeccdad775b2eaec44543643e90.svg\" style=\"height: 41px;\" type=\"image/svg+xml\">\\[\\det(V) = \\prod_{0 \\le i &lt; j \\le n} (x_j - x_i)\\]</object>\n<p>Here’s why.</p>\n<p>To get some intuition, let’s consider some small-rank Vandermonde\nmatrices. Starting with a 2-by-2:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/409bf1caaf2ceab8e097d007aacd2e7031185732.svg\" style=\"height: 42px;\" type=\"image/svg+xml\">\\[\\det(V)=\\det\\begin{bmatrix}\n1 &amp; x_0 \\\\\n1 &amp; x_1 \\\\\n\\end{bmatrix}=x_1-x_0\\]</object>\n<p>Let’s try 3-by-3 now:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/fa1e9fd7d521588ed1f13cd1ea96c43b56aef604.svg\" style=\"height: 96px;\" type=\"image/svg+xml\">\\[\\det(V)=\\det\n{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n    1 &amp; x_0 &amp; x_0^2 \\\\\n    1 &amp; x_1 &amp; x_1^2 \\\\\n    1 &amp; x_2 &amp; x_2^2 \\\\\n\\end{bmatrix}\n}\\]</object>\n<p>We can use the standard way of calculating determinants to expand from\nthe first row:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/39f0107408e77d8492349b40106253d18487e48e.svg\" style=\"height: 49px;\" type=\"image/svg+xml\">\\[\\begin{aligned}\n\\det(V)&amp;=1\\cdot(x_1 x_2^2 - x_2 x_1^2)-x_0(x_2^2-x_1^2)+x_0^2(x_2 - x_1)\\\\\n&amp;=x_1 x_2^2 - x_2 x_1^2 - x_0 x_2^2+x_0 x_1^2+x_0^2 x_2 - x_0^2 x_1\\\\\n\\end{aligned}\\]</object>\n<p>Using some algebraic manipulation, it’s easy to show this is equivalent\nto:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/1cfe17009b539affb81c76120ef3960119bf1a8d.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\[\\det(V)=(x_2-x_1)(x_2-x_0)(x_1-x_0)\\]</object>\n<p>For the full proof, let’s look at the generalized\n<object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object>-by-<object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/db2a943efe93404e43f6ecbec79e0a4fe81b1649.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">n+1</object> matrix again:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/d93183948364818eeb51b48056262a016e345ef9.svg\" style=\"height: 159px;\" type=\"image/svg+xml\">\\[V=\n{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n        1 &amp; x_0 &amp; x_0^2 &amp; \\dots &amp; x_0^n\\\\\n        1 &amp; x_1 &amp; x_1^2 &amp; \\dots &amp; x_1^n\\\\\n        1 &amp; x_2 &amp; x_2^2 &amp; \\dots &amp; x_2^n\\\\\n        \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n        1 &amp; x_n &amp; x_n^2 &amp; \\dots &amp; x_n^n\n    \\end{bmatrix}\n }\\]</object>\n<p>Recall that subtracting a multiple of one column from another doesn’t\nchange a matrix’s determinant. For each column <object class=\"valign-m2\" data=\"https://eli.thegreenplace.net/images/math/1ce658ba27a5ceb614d1279b5e24989689505dcd.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">k&gt;1</object>, we’ll\nsubtract the value of column <object class=\"valign-0\" data=\"https://eli.thegreenplace.net/images/math/4136a771b69c092ff42aa6115afbc9160e5353c9.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">k-1</object> multiplied by <img alt=\"x_0\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/efbda784ad565c1c5201fdc948a570d0426bc6e6.png\" style=\"height: 11px;\" /> from\nit (this is done on all columns simultaneously). The idea is to make the\nfirst row all zeros after the very first element:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/7b17cf508ed83e3f00a056891c02d58bc85df72c.svg\" style=\"height: 159px;\" type=\"image/svg+xml\">\\[V=\n{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n        1 &amp; 0 &amp; 0 &amp; \\dots &amp; 0\\\\\n        1 &amp; x_1 - x_0 &amp; x_1^2 - x_1 x_0&amp; \\dots &amp; x_1^n - x_1^{n-1} x_0\\\\\n        1 &amp; x_2 - x_0 &amp; x_2^2 - x_2 x_0&amp; \\dots &amp; x_2^n - x_2^{n-1} x_0\\\\\n        \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n        1 &amp; x_n - x_0 &amp; x_n^2 - x_n x_0&amp; \\dots &amp; x_n^n - x_n^{n-1} x_0\\\\\n    \\end{bmatrix}\n}\\]</object>\n<p>Now we factor out <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/89cce2d73854c97e220aa9b7232bb408e5d1b0d6.svg\" style=\"height: 11px;\" type=\"image/svg+xml\">x_1-x_0</object> from the second row (after the first\nelement), <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/9f4f5293a3d0b243932a97c1c52109c3bba378c7.svg\" style=\"height: 11px;\" type=\"image/svg+xml\">x_2-x_0</object> from the third row and so on, to get:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/0f35e4bc0e43ffcebb6b8ca326dacba9c10549b6.svg\" style=\"height: 159px;\" type=\"image/svg+xml\">\\[V=\n{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n        1 &amp; 0 &amp; 0 &amp; \\dots &amp; 0\\\\\n        1 &amp; x_1 - x_0 &amp; x_1(x_1 - x_0)&amp; \\dots &amp; x_1^{n-1}(x_1 - x_0)\\\\\n        1 &amp; x_2 - x_0 &amp; x_2(x_2 - x_0)&amp; \\dots &amp; x_2^{n-1}(x_2 - x_0)\\\\\n        \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n        1 &amp; x_n - x_0 &amp; x_n(x_n - x_0)&amp; \\dots &amp; x_n^{n-1}(x_n - x_0)\\\\\n    \\end{bmatrix}\n}\\]</object>\n<p>Imagine we erase the first row and first column of <img alt=\"V\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/c9ee5681d3c59f7541c27a38b67edf46259e187b.png\" style=\"height: 12px;\" />. We’ll call\nthe resulting matrix <img alt=\"W\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/e2415cb7f63df0c9de23362326ad3c37a9adfc96.png\" style=\"height: 12px;\" />.</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/bd6c93bd0a0454bce81c7565870e59033bffd317.svg\" style=\"height: 128px;\" type=\"image/svg+xml\">\\[W=\n{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n        x_1 - x_0 &amp; x_1(x_1 - x_0)&amp; \\dots &amp; x_1^{n-1}(x_1 - x_0)\\\\\n        x_2 - x_0 &amp; x_2(x_2 - x_0)&amp; \\dots &amp; x_2^{n-1}(x_2 - x_0)\\\\\n        \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n        x_n - x_0 &amp; x_n(x_n - x_0)&amp; \\dots &amp; x_n^{n-1}(x_n - x_0)\\\\\n    \\end{bmatrix}\n}\\]</object>\n<p>Because the first row of <img alt=\"V\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/c9ee5681d3c59f7541c27a38b67edf46259e187b.png\" style=\"height: 12px;\" /> is all zeros except the first\nelement, we have:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/c112a75142ecd4bc97e681cf01e4a734a67e9c5d.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\[\\det(V)=\\det(W)\\]</object>\n<p>Note that the first row of <img alt=\"W\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/e2415cb7f63df0c9de23362326ad3c37a9adfc96.png\" style=\"height: 12px;\" /> has a common factor of\n<object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/89cce2d73854c97e220aa9b7232bb408e5d1b0d6.svg\" style=\"height: 11px;\" type=\"image/svg+xml\">x_1-x_0</object>, so when calculating <object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/3845b3a938b1cd6b8667c495a8caa9957a8ee224.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\det(W)</object>, we can move this\ncommon factor out. Same for the common factor <object class=\"valign-m3\" data=\"https://eli.thegreenplace.net/images/math/9f4f5293a3d0b243932a97c1c52109c3bba378c7.svg\" style=\"height: 11px;\" type=\"image/svg+xml\">x_2-x_0</object> of the\nsecond row, and so on. Overall, we can write:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/e444fd8f617e7e5ce3752d3c356d18040c31371d.svg\" style=\"height: 160px;\" type=\"image/svg+xml\">\\[\\det(W)=(x_1-x_0)(x_2-x_0)\\cdots(x_n-x_0)\\cdot \\det\n{\\renewcommand{\\arraystretch}{1.5}\\begin{bmatrix}\n        1 &amp; x_0 &amp; x_0^2 &amp; \\dots &amp; x_0^{n-1}\\\\\n        1 &amp; x_1 &amp; x_1^2 &amp; \\dots &amp; x_1^{n-1}\\\\\n        1 &amp; x_2 &amp; x_2^2 &amp; \\dots &amp; x_2^{n-1}\\\\\n        \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots \\\\\n        1 &amp; x_n &amp; x_n^2 &amp; \\dots &amp; x_n^{n-1}\n    \\end{bmatrix}\n}\\]</object>\n<p>But the smaller matrix is just the Vandermonde matrix for\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/4c41722db7edcf3779cdd6d5664ccfb838e2dfc8.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">\\{x_0 \\dots x_{n-1}\\}</object>. If we continue this process by induction,\nwe’ll get:</p>\n<object class=\"align-center\" data=\"https://eli.thegreenplace.net/images/math/aeef2af004a7aeeccdad775b2eaec44543643e90.svg\" style=\"height: 41px;\" type=\"image/svg+xml\">\\[\\det(V) = \\prod_{0 \\le i &lt; j \\le n} (x_j - x_i)\\]</object>\n<p>If you’re interested, the <a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Vandermonde_matrix\">Wikipedia page for the Vandermonde matrix</a> has a couple of additional\nproofs.</p>\n<hr class=\"docutils\" />\n<table class=\"docutils footnote\" frame=\"void\" id=\"footnote-1\" rules=\"none\">\n<colgroup><col class=\"label\" /><col /></colgroup>\n<tbody valign=\"top\">\n<tr><td class=\"label\"><a class=\"fn-backref\" href=\"#footnote-reference-1\">[1]</a></td><td>The <img alt=\"x\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/11f6ad8ec52a2984abaafd7c3b516503785c2072.png\" style=\"height: 8px;\" />-es here are called <em>nodes</em> and the <img alt=\"y\" class=\"valign-m4\" src=\"https://eli.thegreenplace.net/images/math/95cb0bfd2977c761298d9624e4b4d4c72a39974a.png\" style=\"height: 12px;\" />-s are\ncalled <em>values</em>.</td></tr>\n</tbody>\n</table>\n<table class=\"docutils footnote\" frame=\"void\" id=\"footnote-2\" rules=\"none\">\n<colgroup><col class=\"label\" /><col /></colgroup>\n<tbody valign=\"top\">\n<tr><td class=\"label\"><a class=\"fn-backref\" href=\"#footnote-reference-2\">[2]</a></td><td><a class=\"reference external\" href=\"https://eli.thegreenplace.net/2024/method-of-differences-and-newton-polynomials/\">Newton\npolynomials</a>\nis also an option, and there are many other approaches.</td></tr>\n</tbody>\n</table>\n<table class=\"docutils footnote\" frame=\"void\" id=\"footnote-3\" rules=\"none\">\n<colgroup><col class=\"label\" /><col /></colgroup>\n<tbody valign=\"top\">\n<tr><td class=\"label\"><a class=\"fn-backref\" href=\"#footnote-reference-3\">[3]</a></td><td>Note that this means the product of all differences between\n<object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/73058e43db0f4edc791b10f27f913cbc5d361ab6.svg\" style=\"height: 14px;\" type=\"image/svg+xml\">x_j</object> and <img alt=\"x_i\" class=\"valign-m3\" src=\"https://eli.thegreenplace.net/images/math/34e03e6559b14df9fe5a97bbd2ed10109dfebbd3.png\" style=\"height: 11px;\" /> where <img alt=\"i\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/042dc4512fa3d391c5170cf3aa61e6a638f84342.png\" style=\"height: 12px;\" /> is strictly smaller than\n<object class=\"valign-m4\" data=\"https://eli.thegreenplace.net/images/math/5c2dd944dde9e08881bef0894fe7b22a5c9c4b06.svg\" style=\"height: 16px;\" type=\"image/svg+xml\">j</object>. That is, for <object class=\"valign-0\" data=\"https://eli.thegreenplace.net/images/math/2091fb295870e9f79b6d8a10d0f6046b091e6fe5.svg\" style=\"height: 12px;\" type=\"image/svg+xml\">n=2</object>, the full product is\n<object class=\"valign-m5\" data=\"https://eli.thegreenplace.net/images/math/c42a249f6023c731a0d670240a66413cd79aee91.svg\" style=\"height: 19px;\" type=\"image/svg+xml\">(x_2-x_1)(x_2-x_0)(x_1-x_0)</object>. For an arbitrary <img alt=\"n\" class=\"valign-0\" src=\"https://eli.thegreenplace.net/images/math/d1854cae891ec7b29161ccaf79a24b00c274bdaa.png\" style=\"height: 8px;\" />,\nthere are <object class=\"valign-m6\" data=\"https://eli.thegreenplace.net/images/math/66a19249b26d808e85ea349b8b84dee8a2090e0c.svg\" style=\"height: 25px;\" type=\"image/svg+xml\">\\frac{n(n-1)}{2}</object> factors in total.</td></tr>\n</tbody>\n</table>\n</div>\n",
    "description": "Polynomial interpolation is a method of finding a polynomial function that fits a given set of data perfectly. More concretely, suppose we have a set of n+1 distinct points [1]: \\[(x_0,y_0), (x_1, y_1), (x_2, y_2)\\cdots(x_n, y_n)\\] And we want to find the polynomial coefficients {a_0\\cdots …",
    "is_fulltext": true,
    "source": "Eli Bendersky's website",
    "pub_date": "2026-03-01T02:58:06-08:00",
    "fetched_at": "2026-03-01T12:15:42.943441",
    "url_hash": "04e374969d9fb22eddb27202a04618ce"
  }
]