[
  {
    "title": "Gemini 3.1 Pro",
    "link": "https://simonwillison.net/2026/Feb/19/gemini-31-pro/#atom-everything",
    "content": "\n    \n<p><strong><a href=\"https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/\">Gemini 3.1 Pro</a></strong></p>\nThe first in the Gemini 3.1 series, priced the same as Gemini 3 Pro ($2/million input, $12/million output under 200,000 tokens, $4/$18 for 200,000 to 1,000,000). That's less than half the price of Claude Opus 4.6 with very similar benchmark scores to that model.</p>\n<p>They boast about its improved SVG animation performance compared to Gemini 3 Pro in the announcement!</p>\n<p>I tried \"Generate an SVG of a pelican riding a bicycle\" <a href=\"https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221ugF9fBfLGxnNoe8_rLlluzo9NSPJDWuF%22%5D,%22action%22:%22open%22,%22userId%22:%22106366615678321494423%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing\">in Google AI Studio</a> and it thought for 323.9 seconds (<a href=\"https://gist.github.com/simonw/03a755865021739a3659943a22c125ba#thinking-trace\">thinking trace here</a>) before producing this one:</p>\n<p><img alt=\"Whimsical flat-style illustration of a pelican wearing a blue and white baseball cap, riding a red bicycle with yellow-rimmed wheels along a road. The pelican has a large orange bill and a green scarf. A small fish peeks out of a brown basket on the handlebars. The background features a light blue sky with a yellow sun, white clouds, and green hills.\" src=\"https://static.simonwillison.net/static/2026/gemini-3.1-pro-pelican.png\" /></p>\n<p>It's good to see the legs clearly depicted on both sides of the frame (should <a href=\"https://twitter.com/elonmusk/status/2023833496804839808\">satisfy Elon</a>), the fish in the basket is a nice touch and I appreciated this comment in <a href=\"https://gist.github.com/simonw/03a755865021739a3659943a22c125ba#response\">the SVG code</a>:</p>\n<pre><code>&lt;!-- Black Flight Feathers on Wing Tip --&gt;\n&lt;path d=\"M 420 175 C 440 182, 460 187, 470 190 C 450 210, 430 208, 410 198 Z\" fill=\"#374151\" /&gt;\n</code></pre>\n<p>I've <a href=\"https://github.com/simonw/llm-gemini/issues/121\">added</a> the two new model IDs <code>gemini-3.1-pro-preview</code> and <code>gemini-3.1-pro-preview-customtools</code> to my <a href=\"https://github.com/simonw/llm-gemini\">llm-gemini plugin</a> for <a href=\"https://llm.datasette.io/\">LLM</a>. That \"custom tools\" one is <a href=\"https://ai.google.dev/gemini-api/docs/models/gemini-3.1-pro-preview#gemini-31-pro-preview-customtools\">described here</a> - apparently it may provide better tool performance than the default model in some situations.</p>\n<p>The model appears to be <em>incredibly</em> slow right now - it took 104s to respond to a simple \"hi\" and a few of my other tests met \"Error: This model is currently experiencing high demand. Spikes in demand are usually temporary. Please try again later.\" or \"Error: Deadline expired before operation could complete\" errors. I'm assuming that's just teething problems on launch day.</p>\n<p>It sounds like last week's <a href=\"https://simonwillison.net/2026/Feb/12/gemini-3-deep-think/\">Deep Think release</a> was our first exposure to the 3.1 family:</p>\n<blockquote>\n<p>Last week, we released a major update to Gemini 3 Deep Think to solve modern challenges across science, research and engineering. Today, we’re releasing the upgraded core intelligence that makes those breakthroughs possible: Gemini 3.1 Pro.</p>\n</blockquote>\n<p><strong>Update</strong>: In <a href=\"https://simonwillison.net/2025/nov/13/training-for-pelicans-riding-bicycles/\">What happens if AI labs train for pelicans riding bicycles?</a> last November I said:</p>\n<blockquote>\n<p>If a model finally comes out that produces an excellent SVG of a pelican riding a bicycle you can bet I’m going to test it on all manner of creatures riding all sorts of transportation devices.</p>\n</blockquote>\n<p>Google's Gemini Lead Jeff Dean <a href=\"https://x.com/JeffDean/status/2024525132266688757\">tweeted this video</a> featuring an animated pelican riding a bicycle, plus a frog on a penny-farthing and a giraffe driving a tiny car and an ostrich on roller skates and a turtle kickflipping a skateboard and a dachshund driving a stretch limousine.</p>\n<video poster=\"https://static.simonwillison.net/static/2026/gemini-animated-pelicans.jpg\" muted controls preload=\"none\" style=\"max-width: 100%\">\n  <source src=\"https://static.simonwillison.net/static/2026/gemini-animated-pelicans.mp4\" type=\"video/mp4\">\n</video>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/google\">google</a>, <a href=\"https://simonwillison.net/tags/svg\">svg</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/llm\">llm</a>, <a href=\"https://simonwillison.net/tags/gemini\">gemini</a>, <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle\">pelican-riding-a-bicycle</a>, <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a></p>\n\n\n\n",
    "description": "Gemini 3.1 Pro The first in the Gemini 3.1 series, priced the same as Gemini 3 Pro ($2/million input, $12/million output under 200,000 tokens, $4/$18 for 200,000 to 1,000,000). That's less than half the price of Claude Opus 4.6 with very similar benchmark scores to that model. They boast about its improved SVG animation performance compared to Gemini 3 Pro in the announcement! I tried \"Generate an SVG of a pelican riding a bicycle\" in Google AI Studio and it thought for 323.9 seconds (thinking t",
    "is_fulltext": true,
    "source": "Simon Willison's Weblog",
    "pub_date": "2026-02-19T17:58:37+00:00",
    "fetched_at": "2026-02-20T00:35:46.229485",
    "url_hash": "cf5e72c273e72d28757ba19441d084be"
  },
  {
    "title": "IMAX and Apple Collaborate to Screen F1 Races Live in Theaters",
    "link": "https://www.motorsport.com/f1/news/f1-to-screen-live-in-imax-theatres-in-2026-as-apple-tv-unveils-new-us-viewing-experience/10798974/",
    "content": "\n<p>Lydia Mee, reporting for Motorsport:</p>\n\n<blockquote>\n  <p>IMAX has announced that a select number of races will be shown\nlive in IMAX locations across the United States in 2026. The new\nfan viewing experience is part of a collaboration with Apple TV,\nwhich has taken over the broadcasting rights for the championship\nin the US on a multi-year deal from 2026.</p>\n\n<p>“F1 is a rapidly growing force in sports and culture in the US,\nand by bringing F1 on Apple TV live to IMAX theatres nationwide,\nwe’re delivering the energy and excitement to even more screens in\na truly immersive way,” said Oliver Schusser, Apple’s vice\npresident of music, sports, and Beats.</p>\n</blockquote>\n\n<p>You know what would add even <em>more</em> screens in an immersive way? <a href=\"https://daringfireball.net/linked/2026/02/18/immersive-f1-vision-pro-spitball\">If Vision Pro users had access to the same live screenings</a> on virtual IMAX screens.</p>\n\n<div>\n<a  title=\"Permanent link to ‘IMAX and Apple Collaborate to Screen F1 Races Live in Theaters’\"  href=\"https://daringfireball.net/linked/2026/02/19/imax-and-apple-collaborate-to-screen-f1-races-live-in-theaters\">&nbsp;★&nbsp;</a>\n</div>\n\n\t",
    "description": "",
    "is_fulltext": true,
    "source": "Daring Fireball",
    "pub_date": "2026-02-19T23:29:26Z",
    "fetched_at": "2026-02-20T00:35:48.055630",
    "url_hash": "d588b5772d500c5fc66d2dac93f60d34"
  },
  {
    "title": "Pluralistic: Six Years of Pluralistic (19 Feb 2026)",
    "link": "https://pluralistic.net/2026/02/19/now-we-are-six/",
    "content": "<p><!--\nTags:\nblogging, process notes, writing, memex method, web writing, POSSE\n\nSummary:\nSix years of Pluralistic; Hey look at this; Upcoming appearances; Recent appearances; Latest books; Upcoming books\n\nURL:\nhttps://pluralistic.net/2026/02/19/now-we-are-six/\n\nTitle:\nPluralistic: Six Years of Pluralistic (19 Feb 2026) now-we-are-six\n\nBullet:\n&#x1f4f8;\n\nSeparator:\n->->->->->->->->->->->->->->->->->->->->->->->->->->->->->->\n\nTop Sources:\nNone\n\n--><br />\n<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/\"><img data-recalc-dims=\"1\" decoding=\"async\" class=\"xmasthead_link\" src=\"https://i0.wp.com/craphound.com/images/19Feb2026.jpg?w=840&#038;ssl=1\"/></a></p>\n<h1 class=\"toch1\">Today's links</h1>\n<ul class=\"toc\">\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#stock-buyback\">Six years of Pluralistic</a>: Time flies when you're writing the web.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#linkdump\">Hey look at this</a>: Delights to delectate.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#retro\">Object permanence</a>: MBA phrenology; Sony's DRM CEO is out; Midwestern Tahrir; Reverse Centaurs and AI.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#upcoming\">Upcoming appearances</a>: Where to find me.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#recent\">Recent appearances</a>: Where I've been.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#latest\">Latest books</a>: You keep readin' em, I'll keep writin' 'em.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#upcoming-books\">Upcoming books</a>: Like I said, I'll keep writin' 'em.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#bragsheet\">Colophon</a>: All the rest.\n</li>\n</ul>\n<p><span id=\"more-12446\"></span></p>\n<hr/>\n<p><a name=\"stock-buyback\"></a><br />\n<img data-recalc-dims=\"1\" decoding=\"async\" alt=\"A screengrab from the first episode of 'The Prisoner,' showing Number Six (Patrick McGoohan) lying unconscious on the beach after being bowled over by a giant white sphere (a 'Rover'). The image has been altered; my head has been superimposed on McGoohan's body; TV scan lines have been added, and the image has been given a vertical 'ripple' of the sort that appears in a badly tuned broadcast TV signal.\" src=\"https://i0.wp.com/craphound.com/images/now-we-are-six.jpg?w=840&#038;ssl=1\"/></p>\n<h1>Six years of Pluralistic (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#stock-buyback\">permalink</a>)</h1>\n<p>Six years ago today, after 19 years with Boing Boing, during which time I wrote tens of thousands of blog posts, I started a new, solo blog, with the semi-ironic name \"Pluralistic.\" I didn't know what Pluralistic was going to be, but I wasn't writing Boing Boing anymore, and I knew I wanted to keep writing the web in <em>some</em> fashion.</p>\n<p>Six years and more than 1,500 posts later, I am <em>so</em> satisfied with how Pluralistic is going. I spent a couple of decades processing everything that seemed interesting or significant through a blog, which created a <em>massive</em> database (and mnemonically available collection of partially developed thoughts) that I'm now reprocessing as a series of essays that make sense of today in light of everything that I've thought about for my whole adult life, which are, in turn, fodder for books, both fiction and nonfiction. I call this \"The Memex Method\":</p>\n<p><a href=\"https://pluralistic.net/2021/05/09/the-memex-method/\">https://pluralistic.net/2021/05/09/the-memex-method/</a></p>\n<p>\"The Memex Method\" is also the title of a collection of essays (from this blog) that I've sold to Farrar, Straus and Giroux, but that book keeps getting bumped because of <em>other</em> books I end up writing based on the work I do here, starting with last year's <em>Enshittification</em>. I'm now fully <em>two</em> books ahead of myself, with <em>The Reverse Centaur's Guide to Life After AI</em> coming in June, and <em>The Post-American Internet</em> in early 2027 (in addition to two graphic novels and a short story collection). Professionally speaking, these are the most successful books I've written, in a long, 30+ book career with many notable successes. Intellectually and artistically speaking, I'm incredibly satisfied with the direction my career has moved in over my six Pluralistic years.</p>\n<p>Blogging is &#8211; and always has been &#8211; a lot of work for me, but it's work that pays off, even if I don't always know what form that payoff will take.</p>\n<p>One essential part of this blog is my daily retrospective of posts from this day through my blogging history &#8211; 25 years ago, 20 years ago, 15 years ago, 10 years ago, 5 years ago, and last year. I used to call this \"This day in history\" but now I call it \"Object permanence,\" for the developmental milestone when toddlers gain the ability to remember and reason about things that have recently happened (roughly, it's the point at which \"peek-a-boo\" stops being fun).</p>\n<p>The daily business of reviewing and selecting blog posts from different parts of my life started as a trivial exercise, but it's become one of the most important things I do. I liken it to working dough and folding the dry crumbly edges back into the center; in this case, I'm folding all the fragments that are in danger of escaping my working memory back into the center of my attention.</p>\n<p>Six years ago, I didn't know what Pluralistic was going to be. Today, I still don't know. But because this is a labor of love, and a solo project, I get to try anything and either give it up or carry it on based on how it makes me feel and what effect it has on my life. I'm always tinkering with the format: this year, I also added a subhead to the Object Permanence section that tries to call out (in as few characters as possible) the most important elements of the day's list.</p>\n<p>I also dropped some things this year, notably, my \"linkdump\" posts. A couple years ago, at the suggestion of Mitch Wagner, I added a new section called \"Hey look at this,\" which featured three bare links to things I thought were noteworthy but didn't have time or inclination to delve into in depth. Later, I expanded this section to five.</p>\n<p>However, even with five bare links per edition, I often found myself with a backlog of noteworthy things. So I started writing the occasional Saturday \"linkdump\" essay in which I wove together the whole backlog into a giant, meandering essay. These made for interesting rhetorical challenges, as I found elegant ways to bridge completely disparate subjects &#8211; a kind of collaging, perhaps akin to how a mashup artist mixes two very different tracks together. Mentally, I thought of this as \"ringing the changes,\" but ultimately, I decided to drop these linkdump posts (for now, at least). They ended up being too much work, and of little value to me, because I found myself unable to remember what I wrote in them and thus to call them up to refer to them for future posts. Here's all 33 linkdumps; they're not gone forever (not so long as the links pile up in my backlog), but when they come back, they'll be in a different form:</p>\n<p><a href=\"https://pluralistic.net/tag/linkdump/\">https://pluralistic.net/tag/linkdump/</a></p>\n<p>This really is a labor of love, in the sense that I love doing it, and because it's hard work. The fact that it's hard work is a feature, not a bug. Working hard on stuff is really important to me, because when I am working hard, I gain respite from both physical and mental discomfort. As a guy with serious chronic pain living through the Trump years, I've got plenty of both kinds of discomfort. I can't overstate how physically and mentally beneficial it is to me to have an activity that takes me out of the moment. This year, I wrote several editions of Pluralistic from an infusion couch at the Kaiser Sunset hematology center in LA, where I was receiving immunotherapy for a cancer diagnosis that I'm assured is very treatable, but which &#8211; to be totally honest &#8211; sometimes gets my old worrier running hot:</p>\n<p><a href=\"https://pluralistic.net/2024/11/05/carcinoma-angels/#squeaky-nail\">https://pluralistic.net/2024/11/05/carcinoma-angels/#squeaky-nail</a></p>\n<p>Making Pluralistic is several <em>kinds</em> of hard work. Over the past six years, I've become an ardent collagist, spending more and more time on the weird, semi-grotesque images that run atop every edition. Anything you devote substantial time to on a near-daily basis is something that gives you insight &#8211; into yourself, and into the thing you're doing. I've always had a certain familiarity with computer image editing (I think I got my start writing Apple ][+ BASIC programs that spat out ASCII art, before graduating to making pixel-art for Broderbund's \"Print Shop\"), but I've never applied myself to <em>any</em> visual field in a serious way, until now.</p>\n<p>Amazingly, after 50 years of thinking of myself as someone who is \"bad at visual art,\" I find myself identifying <em>as a visual artist</em>. I find myself pondering visual works the same way I think about prose &#8211; mentally tearing it apart to unpick how it is done, and thinking about how I could productively steal some new techniques for my own work. I'm also privileged to have some accomplished visual artists in my circle, like my pal Alistair Milne, who generously share technical and aesthetic tips. It's got to the point where I published a book of my art, and I think I'll probably do it again next year:</p>\n<p><a href=\"https://pluralistic.net/2025/09/04/illustrious/#chairman-bruce\">https://pluralistic.net/2025/09/04/illustrious/#chairman-bruce</a></p>\n<p>There's also a <em>ton</em> of technical work that goes into publishing each edition of this newsletter. Things have moved on somewhat since I published an in-depth process-post in 2021, though I'm still totally reliant on Loren Kohnfelder's python scripts that help me turn the XML file I compose every day into files that are (nearly) ready to publish:</p>\n<p><a href=\"https://pluralistic.net/2021/01/13/two-decades/#hfbd\">https://pluralistic.net/2021/01/13/two-decades/#hfbd</a></p>\n<p>Much of the technical work is down to the fact that I'm still completely wed to the idea of \"POSSE\" (Post Own Site, Syndicate Everywhere):</p>\n<p><a href=\"https://pluralistic.net/2022/02/19/now-we-are-two/#two-much-posse\">https://pluralistic.net/2022/02/19/now-we-are-two/#two-much-posse</a></p>\n<p>This means that after I write the day's post, I reformat it and republish it as a text-only newsletter, a Medium post, a Tumblr post, a Twitter thread and a Mastodon thread. This involves a <em>ton</em> of manual work, because none of the services I post to are designed to facilitate this, so I'm always wrestling with them. This year, <em>all</em> of them got <em>worse</em> (incredibly).</p>\n<p>Medium &#8211; where I used to have a paid column &#8211; has dropped its free-flag for my account, which now limits me to how many posts I can schedule. This doesn't come up often, but when I <em>do</em> schedule a post, it's generally because I'm going to be on a plane or a stage and won't be able to do it manually. There's no <em>way</em> I'm going to pay for this feature: I'm happy to give Medium my work gratis, but I will not and do not pay anyone to publish my work, and I never will.</p>\n<p>Tumblr did something to its post-composing text editor that <em>completely</em> broke it and I've given up on fixing it. I can't even type into a new post field! I have to paste in some styled text, then delete it, <em>then</em> start typing. It's ghastly. So now I just have a text file full of formatted HTML snippets and I work exclusively in the Tumblr HTML editor, pasting in blobs of preformatted HTML (including the florid, verbose HTML Tumblr uses for its own formatting) and then laboriously flip back and forth to the \"visual\" editor to see the parts that went wrong. Here's how busted that visual editor is: searching for a word then double-clicking on it does not select it. You have to click once, wait about 1.5 seconds, click again, wait again, and <em>then</em> you can select the word.</p>\n<p>Twitter has entered a period of terminal technical decline. I know, I know, we always talk about how fucked Twitter's content moderation is, for obvious and good reasons, but from a technical perspective, Twitter just <em>sucks</em>. If I make a post with an image and alt text in anticipation of later using it to start a thread, it often goes \"stale\" and will not publish until I delete the image and re-attach it and re-paste the alt text. Meanwhile, the thread editor is also decaying into uselessness. Fill in a 25-post thread and hit publish and, the majority of times, the thread publication will die midway through, displaying lots of weird failure modes (phantom empty posts at the end of the thread that need to be individually selected and deleted are a common one, but not the only one). The old Twitter's ability to add a new thread to an existing one has been dead for at least a year, so every post after the 25th stanza has to be manually tacked on to the previous one, which is made <em>far</em> harder by the fact that Twitter no longer reliably shows you the post you just made after it publishes.</p>\n<p>Mastodon <em>still</em> lacks a decent thread editor, one that has even the minimal functionality of Twitter circa 2020. Meanwhile, the Fediverse HOA continues to surface from time to time, with someone who's had a Masto account for ten seconds scolding me for posting threads &#8211; from my account whose bio starts \"I post long threads.\" It's genuinely tedious to be shouted at for \"using Mastodon wrong\" by someone who started using Mastodon yesterday (I opened my first Mastodon account in 2018!), and even worse when they double down after I point them to the essay I've written to explain why I post the way I do, and what to do if you want to read my work somewhere that's not your Mastodon timeline (\"Can you believe this asshole wrote a whole essay to explain why he posts his stupid Mastodon threads?\"):</p>\n<p><a href=\"https://pluralistic.net/2023/04/16/how-to-make-the-least-worst-mastodon-threads/\">https://pluralistic.net/2023/04/16/how-to-make-the-least-worst-mastodon-threads/</a></p>\n<p>Then there's email: I continue to love email, but email doesn't love me back. After years of being blackholed by AT&amp;T and then Google, this turns out to be the year that Microsoft bounces thousands of messages to its Hotmail and Outlook users because they have arbitrarily and without warning added my mail-server to a blacklist. Thank you to the Fediverse friends who escalated my trouble ticket &#8211; but man, this is a headache I could certainly do without:</p>\n<p><a href=\"https://pluralistic.net/2021/10/10/dead-letters/\">https://pluralistic.net/2021/10/10/dead-letters/</a></p>\n<p>My sysadmin, the incomparable and tireless Ken Snider, tells me that he's got the long-overdue new hardware installed at the colo and he's nearly ready to stand up my long-anticipated personal Mastodon server, which will let me solve all kinds of problems. He's also going to stand up my own Bluesky server, at which point I will part ways with Twitter. I wish I could have used the regular Bluesky service while I waited, but just setting up an account permanently binds you to totally unacceptable and dangerous terms of service:</p>\n<p><a href=\"https://pluralistic.net/2025/08/15/dogs-breakfast/#by-clicking-this-you-agree-on-behalf-of-your-employer-to-release-me-from-all-obligations-and-waivers-arising-from-any-and-all-NON-NEGOTIATED-agreements\">https://pluralistic.net/2025/08/15/dogs-breakfast/#by-clicking-this-you-agree-on-behalf-of-your-employer-to-release-me-from-all-obligations-and-waivers-arising-from-any-and-all-NON-NEGOTIATED-agreements</a></p>\n<p>What's the point of a service that has account- and data-portability if signing up for it makes you <em>permanently</em> surrender your rights, even if you switch servers? This might be the stupidest social media unforced error of the post-zuckermuskian era.</p>\n<p>There is one technology that <em>has</em> made my POSSE life better, and it might surprise you. This year, I installed Ollama &#8211; an open-source LLM &#8211; on my laptop. It runs pretty well, even without a GPU. Every day, before I run Loren's python publication scripts, I run the text through Ollama as a typo-catcher (my prompt is \"find typos\"). Ollama <em>always</em> spots three or four of these, usually stuff like missing punctuation, or forgotten words, or double words (\"the the next thing\") or typos that are still valid words (\"of top of everything else\").</p>\n<p>The reason this is so valuable to me is that errors magnify through each stage of POSSE. Errors that make it through the python publication script take 10x the time to fix that they would if I caught them beforehand. Errors that I catch after running the scripts and publishing the posts take 10x time more. Errors that I have to fix later on &#8211; once I've closed all the relevant tabs and editors &#8211; take 10x again more time. Some POSSE channels (email, Twitter) can't be fixed <em>at all</em>.</p>\n<p>So catching these typos at the start of the process is a huge time-saver. I have some very generous readers who have the proofreader's gene and are very helpful in catching my typos (hi, Gregory and 9o6!), and I feel bad about depriving them of their fun, but there's still the odd error that slips through, and they always catch it.</p>\n<p>Ollama is a pretty good typo-catcher. Probably half of the \"errors\" it points out are false positives, which is better than the false positive rate for Google Docs' grammar-checker. As someone who uses a lot of jargon, made up words, etc in his prose, I'm used to overriding my text-editor. I wouldn't simply trust an LLM's edits any more than I would accept every suggestion from a spell-checker. Hell, yesterday I sent back a professionally copyedited manuscript (the intro for the paperback of <em>Enshittification</em>) and marked \"STET\" on about a third of the queries.</p>\n<p>Doubtless some of you are affronted by my modest use of an LLM. You think that LLMs are \"fruits of the poisoned tree\" and must be eschewed because they are saturated with the sin of their origins. I think this is a very bad take, the kind of rathole that purity culture always ends up in.</p>\n<p>Let's start with some context. If you don't want to use technology that was created under immoral circumstances or that sprang from an immoral mind, then <em>you are totally fucked.</em> I mean, all the way down to the silicon chips in your device, which can never be fully disentangled from the odious, paranoid racist William Shockley, who won the Nobel Prize for co-inventing the silicon transistor:</p>\n<p><a href=\"https://pluralistic.net/2021/10/24/the-traitorous-eight-and-the-battle-of-germanium-valley/\">https://pluralistic.net/2021/10/24/the-traitorous-eight-and-the-battle-of-germanium-valley/</a></p>\n<p>Further, we wouldn't have the packet-switched network that delivered these words to you without the contributions of the literal war-criminals at the RAND corporation:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/ARPANET\">https://en.wikipedia.org/wiki/ARPANET</a></p>\n<p>Refusing to use a technology because the people who developed it were indefensible creeps is a self-owning dead-end. You know what's better than refusing to use a technology because you hate its creators? Seizing that technology and making it your own. Don't like the fact that a convicted monopolist has a death-grip on networking? Steal its protocol, release a free software version of it, and leave it in your dust:</p>\n<p><a href=\"https://www.eff.org/deeplinks/2019/07/samba-versus-smb-adversarial-interoperability-judo-network-effects\">https://www.eff.org/deeplinks/2019/07/samba-versus-smb-adversarial-interoperability-judo-network-effects</a></p>\n<p>That's how we make good tech: not by insisting that all its inputs be free from sin, but by purging that wickedness by <em>liberating</em> the technology from its monstrous forebears and making free and open versions of it:</p>\n<p><a href=\"https://pluralistic.net/2025/01/14/contesting-popularity/#everybody-samba\">https://pluralistic.net/2025/01/14/contesting-popularity/#everybody-samba</a></p>\n<p>Purity culture is such an obvious trap, an artifact of the neoliberal ideology that insists that the solution to all our problems is to shop very carefully, thus reducing all politics to personal consumption choices:</p>\n<p><a href=\"https://pluralistic.net/2025/07/31/unsatisfying-answers/#systemic-problems\">https://pluralistic.net/2025/07/31/unsatisfying-answers/#systemic-problems</a></p>\n<p>I mean, it was extraordinarily stupid for the Nazis to refuse Einstein's work because it was \"Jewish science,\" but not merely because antisemitism is stupid. It was also a major self-limiting move because <em>Einstein was right</em>:</p>\n<p><a href=\"https://www.scientificamerican.com/article/how-2-pro-nazi-nobelists-attacked-einstein-s-jewish-science-excerpt1/\">https://www.scientificamerican.com/article/how-2-pro-nazi-nobelists-attacked-einstein-s-jewish-science-excerpt1/</a></p>\n<p>Refusing to run an LLM on your laptop because you don't like Sam Altman is as foolish as refusing to get monoclonal antibodies because James Watson was a racist nutjob:</p>\n<p><a href=\"https://www.statnews.com/2025/11/07/james-watson-remembrance-from-dna-pioneer-to-pariah/\">https://www.statnews.com/2025/11/07/james-watson-remembrance-from-dna-pioneer-to-pariah/</a></p>\n<p>Or to refuse to communicate via satellite because they were launched into space on a descendant of a rocket designed by the Nazi Wernher von Braun and built by slaves in a death camp:</p>\n<p><a href=\"https://wsmrmuseum.com/2020/07/27/von-braun-the-v-2-and-slave-labor/4/\">https://wsmrmuseum.com/2020/07/27/von-braun-the-v-2-and-slave-labor/4/</a></p>\n<p>The AI bubble sucks. AI itself is a <em>normal technology</em>:</p>\n<p><a href=\"https://knightcolumbia.org/content/ai-as-normal-technology\">https://knightcolumbia.org/content/ai-as-normal-technology</a></p>\n<p>It's not \"unethical\" to scrape the web in order to create and analyze data-sets. That's just \"a search engine\":</p>\n<p><a href=\"https://pluralistic.net/2023/09/17/how-to-think-about-scraping/\">https://pluralistic.net/2023/09/17/how-to-think-about-scraping/</a></p>\n<p>There's plenty of useful things people can do with AI. There's plenty of useful things people <em>will</em> do with AI. AI is bad because it's an economic bubble and a grift, but not because we've created a bunch of utilities that would &#8211; under normal circumstances &#8211; be called \"plug-ins\":</p>\n<p><a href=\"https://pluralistic.net/2025/12/05/pop-that-bubble/#u-washington\">https://pluralistic.net/2025/12/05/pop-that-bubble/#u-washington</a></p>\n<p>I started blogging 25 years ago, just before the dotcom bubble popped. That bubble-pop inflicted a lot of pain on people who didn't deserve it, including the normie investors who'd been suckered into blowing their life's savings on dogshit stocks, and everyday workers who found themselves out of a job. But the world was better off. So was the web. With the bubble popped, real, good stuff could access talent, servers and office space.</p>\n<p>In the six years I've been doing this, I've seen several bubbles come and go: crypto, web3, metaverse. Now it's AI. But those bubbles were like Enron, frauds that left nothing good behind. AI is like the dotcom bubble, awash in sin and inflicting untold misery, but it will leave something useful behind:</p>\n<p><a href=\"https://pluralistic.net/2023/12/19/bubblenomics/#pop\">https://pluralistic.net/2023/12/19/bubblenomics/#pop</a></p>\n<p>And when it does, I'll make sense of it on this blog.</p>\n<hr/>\n<p><a name=\"linkdump\"></a></p>\n<h1 heds=\"0\">Hey look at this (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#linkdump\">permalink</a>)</h1>\n<p><img data-recalc-dims=\"1\" decoding=\"async\" src=\"https://i0.wp.com/craphound.com/images/heylookatthis3.jpg?w=840&#038;ssl=1\"/></p>\n<ul>\n<li>Mass Call All Laid-Off Tech Workers and Allies Welcome: <a href=\"https://wwwrise.org/\">https://wwwrise.org/</a></p>\n</li>\n<li>\n<p>Understood: The Dawn of Fake Porn <a href=\"https://www.cbc.ca/listen/cbc-podcasts/1353-the-naked-emperor/episode/16198164-e1-the-dawn-of-fake-porn?featuredPodcast=true\">https://www.cbc.ca/listen/cbc-podcasts/1353-the-naked-emperor/episode/16198164-e1-the-dawn-of-fake-porn?featuredPodcast=true</a></p>\n</li>\n<li>\n<p>Socialism is the big tent — w/Avi Lewis <a href=\"https://www.lukewsavage.com/p/socialism-is-the-big-tent-wavi-lewis\">https://www.lukewsavage.com/p/socialism-is-the-big-tent-wavi-lewis</a></p>\n</li>\n<li>\n<p>The “Enshittification” of NATO <a href=\"https://nationalinterest.org/feature/the-enshittification-of-nato\">https://nationalinterest.org/feature/the-enshittification-of-nato</a></p>\n</li>\n<li>\n<p>Alexandria Ocasio-Cortez Is Channeling FDR <a href=\"https://jacobin.com/2026/02/aoc-fdr-economic-populism-democracy/\">https://jacobin.com/2026/02/aoc-fdr-economic-populism-democracy/</a></p>\n</li>\n</ul>\n<hr/>\n<p><a name=\"retro\"></a><br />\n<img data-recalc-dims=\"1\" decoding=\"async\" alt=\"A shelf of leatherbound history books with a gilt-stamped series title, 'The World's Famous Events.'\" src=\"https://i0.wp.com/craphound.com/images/worlds-famous-events.png?w=840&#038;ssl=1\"/></p>\n<h1 heds=\"0\">Object permanence (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#retro\">permalink</a>)</h1>\n<p>#20yrsago HOWTO resist warrantless searches at Best Buy <a href=\"https://www.die.net/musings/bestbuy/\">https://www.die.net/musings/bestbuy/</a></p>\n<p>#20yrsago RIAA using kids’ private info to attack their mother <a href=\"https://web.archive.org/web/20060223111437/http://p2pnet.net/story/7942\">https://web.archive.org/web/20060223111437/http://p2pnet.net/story/7942</a></p>\n<p>#20yrsago Sony BMG demotes CEO for deploying DRM <a href=\"https://web.archive.org/web/20060219233817/http://biz.yahoo.com/ap/060210/germany_sony_bmg_ceo.html?.v=7\">https://web.archive.org/web/20060219233817/http://biz.yahoo.com/ap/060210/germany_sony_bmg_ceo.html?.v=7</a></p>\n<p>#20yrsago Sistine Chapel recreated through 10-year cross-stitch project <a href=\"https://web.archive.org/web/20060214195146/http://www.austinstitchers.org/Show06/images/sistine2.jpg\">https://web.archive.org/web/20060214195146/http://www.austinstitchers.org/Show06/images/sistine2.jpg</a></p>\n<p>#20yrsago J Edgar Hoover loved Lucy <a href=\"https://web.archive.org/web/20060425120915/http://www.lucylibrary.com/pages/lucy-news-fbi.letter.html\">https://web.archive.org/web/20060425120915/http://www.lucylibrary.com/pages/lucy-news-fbi.letter.html</a></p>\n<p>#20yrsago Bad Samaritan family won’t return found expensive camera <a href=\"https://web.archive.org/web/20060222200300/https://lostcamera.blogspot.com/2006/02/camera-unlost-but-not-quite-found.html\">https://web.archive.org/web/20060222200300/https://lostcamera.blogspot.com/2006/02/camera-unlost-but-not-quite-found.html</a></p>\n<p>#15yrsago What does Libyan revolution mean for bit.ly? <a href=\"https://domainnamewire.com/2011/02/18/is-bit-ly-toast-if-libya-shuts-down-the-internet/\">https://domainnamewire.com/2011/02/18/is-bit-ly-toast-if-libya-shuts-down-the-internet/</a></p>\n<p>#15yrsago Optical illusion inventor goes on to invent copyright threats against 3D printing company <a href=\"https://web.archive.org/web/20110221185839/https://blog.thingiverse.com/2011/02/18/copyright-and-intellectual-property-policy/#respond\">https://web.archive.org/web/20110221185839/https://blog.thingiverse.com/2011/02/18/copyright-and-intellectual-property-policy/#respond</a></p>\n<p>#15yrsago Crappy themepark operators convicted of “engaging in a commercial practice which was a misleading action” <a href=\"https://www.theguardian.com/uk/2011/feb/18/lapland-theme-park-brothers-convicted\">https://www.theguardian.com/uk/2011/feb/18/lapland-theme-park-brothers-convicted</a></p>\n<p>#15yrsago HBGary’s high-volume astroturfing technology and the Feds who requested it <a href=\"https://www.dailykos.com/story/2011/02/16/945768/-UPDATED:-The-HB-Gary-Email-That-Should-Concern-Us-All\">https://www.dailykos.com/story/2011/02/16/945768/-UPDATED:-The-HB-Gary-Email-That-Should-Concern-Us-All</a></p>\n<p>#15yrsago Authors Guild argues in favor of censorship (also: they don’t know shit about Shakespeare) <a href=\"https://volokh.com/2011/02/17/there-should-be-a-name-for-this-one-too/\">https://volokh.com/2011/02/17/there-should-be-a-name-for-this-one-too/</a></p>\n<p>#15yrsago Hollywood hospital ransoms itself back from hackers for a mere $17,000 <a href=\"https://web.archive.org/web/20160227094254/https://www.latimes.com/business/technology/la-me-ln-hollywood-hospital-bitcoin-20160217-story.html\">https://web.archive.org/web/20160227094254/https://www.latimes.com/business/technology/la-me-ln-hollywood-hospital-bitcoin-20160217-story.html</a></p>\n<p>#15yrsago Chinese millionaire sues himself through an offshore shell company to beat currency export controls <a href=\"https://web.archive.org/web/20180526235055/https://blogs.wsj.com/chinarealtime/2016/02/16/china-capital-flight-2-0-lose-a-lawsuit-on-purpose/?guid=BL-CJB-28691&amp;amp;dsk=y\">https://web.archive.org/web/20180526235055/https://blogs.wsj.com/chinarealtime/2016/02/16/china-capital-flight-2-0-lose-a-lawsuit-on-purpose/?guid=BL-CJB-28691&amp;amp;dsk=y</a></p>\n<p>#15yrsago Selling cookies like a crack dealer, by dangling a string out your kitchen window <a href=\"https://laughingsquid.com/cookies-sold-by-string-dangling-from-san-francisco-apartment-window/\">https://laughingsquid.com/cookies-sold-by-string-dangling-from-san-francisco-apartment-window/</a></p>\n<p>#15yrsago Midwestern Tahrir: Workers refuse to leave Wisconsin capital over Tea Party labor law <a href=\"https://www.theawl.com/2011/02/wisconsin-demonstrates-against-scott-walkers-war-on-unions/\">https://www.theawl.com/2011/02/wisconsin-demonstrates-against-scott-walkers-war-on-unions/</a></p>\n<p>#10yrsago Back-room revisions to TPP sneakily criminalize fansubbing &amp; other copyright grey zones <a href=\"https://www.eff.org/deeplinks/2016/02/sneaky-change-tpp-drastically-extends-criminal-penalties\">https://www.eff.org/deeplinks/2016/02/sneaky-change-tpp-drastically-extends-criminal-penalties</a></p>\n<p>#10yrsago Russian Central Bank shutting down banks that staged fake cyberattacks to rip off depositors <a href=\"https://web.archive.org/web/20160220100817/http://www.scmagazine.com/russian-bank-licences-revoked-for-using-hackers-to-withdraw-funds/article/474477/\">https://web.archive.org/web/20160220100817/http://www.scmagazine.com/russian-bank-licences-revoked-for-using-hackers-to-withdraw-funds/article/474477/</a></p>\n<p>#10yrsago Stop paying your student loans and debt collectors can send US Marshals to arrest you <a href=\"https://web.archive.org/web/20201026202024/https://nymag.com/intelligencer/2016/02/us-marshals-forcibly-collecting-student-debt.html?mid=twitter-share-di\">https://web.archive.org/web/20201026202024/https://nymag.com/intelligencer/2016/02/us-marshals-forcibly-collecting-student-debt.html?mid=twitter-share-di</a></p>\n<p>#5yrsago Reverse centaurs and the failure of AI <a href=\"https://pluralistic.net/2021/02/17/reverse-centaur/#reverse-centaur\">https://pluralistic.net/2021/02/17/reverse-centaur/#reverse-centaur</a></p>\n<p>#5yrsago Strength in numbers <a href=\"https://pluralistic.net/2021/02/18/ink-stained-wretches/#countless\">https://pluralistic.net/2021/02/18/ink-stained-wretches/#countless</a></p>\n<p>#5yrsago America and \"national capitalism\" <a href=\"https://pluralistic.net/2025/02/18/pikettys-productivity/#reaganomics-revenge\">https://pluralistic.net/2025/02/18/pikettys-productivity/#reaganomics-revenge</a></p>\n<p>#1yrago Business school professors trained an AI to judge workers' personalities based on their faces <a href=\"https://pluralistic.net/2025/02/17/caliper-ai/#racism-machine\">https://pluralistic.net/2025/02/17/caliper-ai/#racism-machine</a></p>\n<hr/>\n<p><a name=\"upcoming\"></a></p>\n<h1 heds=\"0\">Upcoming appearances (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#upcoming\">permalink</a>)</h1>\n<p><img data-recalc-dims=\"1\" decoding=\"async\" alt=\"A photo of me onstage, giving a speech, pounding the podium.\" src=\"https://i0.wp.com/craphound.com/images/appearances3.jpg?w=840&#038;ssl=1\"/></p>\n<ul>\n<li>Montreal (remote): Fedimtl, Feb 24<br />\n<a href=\"https://fedimtl.ca/\">https://fedimtl.ca/</a></p>\n</li>\n<li>\n<p>Oslo (remote): Seminar og lansering av rapport om «enshittification»<br />\n<a href=\"https://www.forbrukerradet.no/siste-nytt/digital/seminar-og-lansering-av-rapport-om-enshittification/\">https://www.forbrukerradet.no/siste-nytt/digital/seminar-og-lansering-av-rapport-om-enshittification/</a></p>\n</li>\n<li>\n<p>Victoria: 28th Annual Victoria International Privacy &amp; Security Summit, Mar 3-5<br />\n<a href=\"https://www.rebootcommunications.com/event/vipss2026/\">https://www.rebootcommunications.com/event/vipss2026/</a></p>\n</li>\n<li>\n<p>Victoria: Enshittification at Russell Books, Mar 4<br />\n<a href=\"https://www.eventbrite.ca/e/cory-doctorow-is-coming-to-victoria-tickets-1982091125914\">https://www.eventbrite.ca/e/cory-doctorow-is-coming-to-victoria-tickets-1982091125914</a></p>\n</li>\n<li>\n<p>San Francisco: Launch for Cindy Cohn's \"Privacy's Defender\" (City Lights), Mar 10<br />\n<a href=\"https://citylights.com/events/cindy-cohn-launch-party-for-privacys-defender/\">https://citylights.com/events/cindy-cohn-launch-party-for-privacys-defender/</a></p>\n</li>\n<li>\n<p>Barcelona: Enshittification with Simona Levi/Xnet (Llibreria Finestres), Mar 20<br />\n<a href=\"https://www.llibreriafinestres.com/evento/cory-doctorow/\">https://www.llibreriafinestres.com/evento/cory-doctorow/</a></p>\n</li>\n<li>\n<p>Berkeley: Bioneers keynote, Mar 27<br />\n<a href=\"https://conference.bioneers.org/\">https://conference.bioneers.org/</a></p>\n</li>\n<li>\n<p>Berlin: Re:publica, May 18-20<br />\n<a href=\"https://re-publica.com/de/news/rp26-sprecher-cory-doctorow\">https://re-publica.com/de/news/rp26-sprecher-cory-doctorow</a></p>\n</li>\n<li>\n<p>Berlin: Enshittification at Otherland Books, May 19<br />\n<a href=\"https://www.otherland-berlin.de/de/event-details/cory-doctorow.html\">https://www.otherland-berlin.de/de/event-details/cory-doctorow.html</a></p>\n</li>\n<li>\n<p>Hay-on-Wye: HowTheLightGetsIn, May 22-25<br />\n<a href=\"https://howthelightgetsin.org/festivals/hay/big-ideas-2\">https://howthelightgetsin.org/festivals/hay/big-ideas-2</a></p>\n</li>\n</ul>\n<hr/>\n<p><a name=\"recent\"></a><br />\n<img data-recalc-dims=\"1\" decoding=\"async\" alt=\"A screenshot of me at my desk, doing a livecast.\" src=\"https://i0.wp.com/craphound.com/images/recentappearances3.jpg?w=840&#038;ssl=1\"/></p>\n<h1 heds=\"0\">Recent appearances (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#recent\">permalink</a>)</h1>\n<ul>\n<li>Panopticon :3 (Trashfuture)<br />\n<a href=\"https://www.patreon.com/posts/panopticon-3-150395435\">https://www.patreon.com/posts/panopticon-3-150395435</a></p>\n</li>\n<li>\n<p>America's Enshittification is Canada's Opportunity (Do Not Pass Go)<br />\n<a href=\"https://www.donotpassgo.ca/p/americas-enshittification-is-canadas\">https://www.donotpassgo.ca/p/americas-enshittification-is-canadas</a></p>\n</li>\n<li>\n<p>Everything Wrong With the Internet and How to Fix It, with Tim Wu (Ezra Klein)<br />\n<a href=\"https://www.nytimes.com/2026/02/06/opinion/ezra-klein-podcast-doctorow-wu.html\">https://www.nytimes.com/2026/02/06/opinion/ezra-klein-podcast-doctorow-wu.html</a></p>\n</li>\n<li>\n<p>How the Internet Got Worse (Masters in Business)<br />\n<a href=\"https://www.youtube.com/watch?v=auXlkuVhxMo\">https://www.youtube.com/watch?v=auXlkuVhxMo</a></p>\n</li>\n<li>\n<p>Enshittification (Jon Favreau/Offline):<br />\n<a href=\"https://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/\">https://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/</a></p>\n</li>\n</ul>\n<hr/>\n<p><a name=\"latest\"></a><br />\n<img data-recalc-dims=\"1\" decoding=\"async\" alt=\"A grid of my books with Will Stahle covers..\" src=\"https://i0.wp.com/craphound.com/images/recent.jpg?w=840&#038;ssl=1\"/></p>\n<h1 heds=\"0\">Latest books (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#latest\">permalink</a>)</h1>\n<ul>\n<li>\"Canny Valley\": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025 <a href=\"https://pluralistic.net/2025/09/04/illustrious/#chairman-bruce\">https://pluralistic.net/2025/09/04/illustrious/#chairman-bruce</a></p>\n</li>\n<li>\n<p>\"Enshittification: Why Everything Suddenly Got Worse and What to Do About It,\" Farrar, Straus, Giroux, October 7 2025<br />\n<a href=\"https://us.macmillan.com/books/9780374619329/enshittification/\">https://us.macmillan.com/books/9780374619329/enshittification/</a></p>\n</li>\n<li>\n<p>\"Picks and Shovels\": a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (<a href=\"https://us.macmillan.com/books/9781250865908/picksandshovels\">https://us.macmillan.com/books/9781250865908/picksandshovels</a>).</p>\n</li>\n<li>\n<p>\"The Bezzle\": a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (<a href=\"http://thebezzle.org\">thebezzle.org</a>).</p>\n</li>\n<li>\n<p>\"The Lost Cause:\" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (<a href=\"http://lost-cause.org\">http://lost-cause.org</a>).</p>\n</li>\n<li>\n<p>\"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (<a href=\"http://seizethemeansofcomputation.org\">http://seizethemeansofcomputation.org</a>). Signed copies at Book Soup (<a href=\"https://www.booksoup.com/book/9781804291245\">https://www.booksoup.com/book/9781804291245</a>).</p>\n</li>\n<li>\n<p>\"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books <a href=\"http://redteamblues.com\">http://redteamblues.com</a>.</p>\n</li>\n<li>\n<p>\"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 <a href=\"https://chokepointcapitalism.com\">https://chokepointcapitalism.com</a></p>\n</li>\n</ul>\n<hr/>\n<p><a name=\"upcoming-books\"></a><br />\n<img data-recalc-dims=\"1\" decoding=\"async\" alt=\"A cardboard book box with the Macmillan logo.\" src=\"https://i0.wp.com/craphound.com/images/upcoming-books.jpg?w=840&#038;ssl=1\"/></p>\n<h1 heds=\"0\">Upcoming books (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#upcoming-books\">permalink</a>)</h1>\n<ul>\n<li>\"The Reverse-Centaur's Guide to AI,\" a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026</p>\n</li>\n<li>\n<p>\"Enshittification, Why Everything Suddenly Got Worse and What to Do About It\" (the graphic novel), Firstsecond, 2026</p>\n</li>\n<li>\n<p>\"The Post-American Internet,\" a geopolitical sequel of sorts to <em>Enshittification</em>, Farrar, Straus and Giroux, 2027</p>\n</li>\n<li>\n<p>\"Unauthorized Bread\": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2027</p>\n</li>\n<li>\n<p>\"The Memex Method,\" Farrar, Straus, Giroux, 2027</p>\n</li>\n</ul>\n<hr/>\n<p><a name=\"bragsheet\"></a><br />\n<img data-recalc-dims=\"1\" decoding=\"async\" src=\"https://i0.wp.com/craphound.com/images/colophon2.jpg?w=840&#038;ssl=1\"/></p>\n<h1 heds=\"0\">Colophon (<a href=\"https://pluralistic.net/2026/02/19/now-we-are-six/#bragsheet\">permalink</a>)</h1>\n<p>Today's top sources:</p>\n<p><b>Currently writing: \"The Post-American Internet,\" a sequel to \"Enshittification,\" about the better world the rest of us get to have now that Trump has torched America (1013 words today, 31953 total)</b></p>\n<ul>\n<li>\"The Reverse Centaur's Guide to AI,\" a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE.</p>\n</li>\n<li>\n<p>\"The Post-American Internet,\" a short book about internet policy in the age of Trumpism. PLANNING.</p>\n</li>\n<li>\n<p>A Little Brother short story about DIY insulin PLANNING</p>\n</li>\n</ul>\n<hr/>\n<p><img data-recalc-dims=\"1\" decoding=\"async\" src=\"https://i0.wp.com/craphound.com/images/by.svg.png?w=840&#038;ssl=1\"/></p>\n<p>This work &#8211; excluding any serialized fiction &#8211; is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>\n<p><a href=\"https://creativecommons.org/licenses/by/4.0/\">https://creativecommons.org/licenses/by/4.0/</a></p>\n<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>\n<hr/>\n<h1>How to get Pluralistic:</h1>\n<p>Blog (no ads, tracking, or data-collection):</p>\n<p><a href=\"http://pluralistic.net\">Pluralistic.net</a></p>\n<p>Newsletter (no ads, tracking, or data-collection):</p>\n<p><a href=\"https://pluralistic.net/plura-list\">https://pluralistic.net/plura-list</a></p>\n<p>Mastodon (no ads, tracking, or data-collection):</p>\n<p><a href=\"https://mamot.fr/@pluralistic\">https://mamot.fr/@pluralistic</a></p>\n<p>Medium (no ads, paywalled):</p>\n<p><a href=\"https://doctorow.medium.com/\">https://doctorow.medium.com/</a></p>\n<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>\n<p><a href=\"https://twitter.com/doctorow\">https://twitter.com/doctorow</a></p>\n<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>\n<p><a href=\"https://mostlysignssomeportents.tumblr.com/tagged/pluralistic\">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>\n<p>\"<em>When life gives you SARS, you make sarsaparilla</em>\" -Joey \"Accordion Guy\" DeVilla</p>\n<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>\n<p>ISSN: 3066-764X</p>\n",
    "description": "Today's links Six years of Pluralistic: Time flies when you're writing the web. Hey look at this: Delights to delectate. Object permanence: MBA phrenology; Sony's DRM CEO is out; Midwestern Tahrir; Reverse Centaurs and AI. Upcoming appearances: Where to find me. Recent appearances: Where I've been. Latest books: You keep readin' em, I'll keep writin' 'em. Upcoming books: Like I said, I'll keep writin' 'em. Colophon: All the rest. Six years of Pluralistic (permalink) Six years ago today, after 19",
    "is_fulltext": true,
    "source": "Pluralistic: Daily links from Cory Doctorow",
    "pub_date": "Thu, 19 Feb 2026 14:08:05 +0000",
    "fetched_at": "2026-02-20T00:35:52.642049",
    "url_hash": "4d89aeb86edb94ed73559851525b78a5"
  },
  {
    "title": "AI is a NAND Maximiser",
    "link": "https://shkspr.mobi/blog/2026/02/ai-is-a-nand-maximiser/",
    "content": "<p><a href=\"https://www.pcgamer.com/hardware/memory/many-consumer-electronics-manufacturers-will-go-bankrupt-or-exit-product-lines-by-the-end-of-2026-due-to-the-ai-memory-crisis-phison-ceo-reportedly-says/\">PC Gamer is reporting</a> that the current demand by AI companies for computer chips is having a disastrous effect on the rest of the industry.</p>\n\n<p>In an interview, the CEO of Phison<sup id=\"fnref:Phison\"><a href=\"https://shkspr.mobi/blog/2026/02/ai-is-a-nand-maximiser/#fn:Phison\" class=\"footnote-ref\" title=\"Phison describes itself as &quot;A World Leader in NAND Controllers &amp; Flash Storage Solutions&quot; so they aren't a neutral party in this.\" role=\"doc-noteref\">0</a></sup> said:</p>\n\n<blockquote><p>If NVIDIA Vera Rubin ships tens of millions of units, each requiring 20+TB SSDs, it will consume approximately 20% of last year's global NAND production capacity</p>\n\n<p><a href=\"https://x.com/QQ_Timmy/status/2022474577742639136\">駿HaYaO</a><sup id=\"fnref:translated\"><a href=\"https://shkspr.mobi/blog/2026/02/ai-is-a-nand-maximiser/#fn:translated\" class=\"footnote-ref\" title=\"This was machine translated. I've no idea how accurate it is against the original interview.\" role=\"doc-noteref\">1</a></sup></p></blockquote>\n\n<p><a href=\"https://www.ibm.com/think/topics/nand-flash\">NAND is a type of microchip</a>. Rather than being used for computation directly, it is used for memory. It can be used for temporary or permanent storage. It is vital to the modern world. Larger storage sizes means that more data can be gathered and saved. Larger RAM means computations can happen quicker. NAND is one of the fundamental components of modern computing. The more you have, the faster and more powerful your computer is.</p>\n\n<p>Back in 2014, the philosopher <a href=\"https://nickbostrom.com/\">Nick Bostrom</a> wrote a book called \"<a href=\"https://global.oup.com/academic/product/superintelligence-9780199678112\">Superintelligence - Paths, Dangers, Strategies</a>\". In it, he develops the thought experiment of the \"Paperclip Maximizer\".  When an AI is given a goal, it seeks to achieve that goal. It doesn't have to understand any rationale behind the goal. It does not and <em>cannot</em> care about the goal, nor any collateral damage caused by its attempts to satisfy the goal.</p>\n\n<p>Let's take a look at how \"a paperclip-maximizing superintelligent agent\" is introduced</p>\n\n<blockquote><p>There is nothing paradoxical about an AI whose sole final goal is to count the grains of sand on Boracay, or to calculate the decimal expansion of pi, or to maximize the total number of paperclips that will exist in its future light cone. In fact, it would be easier to create an AI with simple goals like these than to build one that had a human-like set of values and dispositions. Compare how easy it is to write a program that measures how many digits of pi have been calculated and stored in memory with how difficult it would be to create a program that reliably measures the degree of realization of some more meaningful goal—human flourishing, say, or global justice. Unfortunately, because a meaningless reductionistic goal is easier for humans to code and easier for an AI to learn, it is just the kind of goal that a programmer would choose to install in his seed AI if his focus is on taking the quickest path to “getting the AI to work” (without caring much about what exactly the AI will do, aside from displaying impressively intelligent behavior).</p>\n\n<p><cite>Bostrom, N. (2014). Superintelligence: Paths, dangers, strategies. Oxford: Oxford University Press, Cop.</cite></p></blockquote>\n\n<p>To misquote Kyle Reese from the film The Terminator - \"It can't be bargained with. It can't be reasoned with. It doesn't feel pity, or remorse, or fear! And it absolutely will not stop, ever, until <em>it has maximised the number of paperclips</em>!\"</p>\n\n<p>Suppose, just for a moment, that the fledgling AIs which now exist were self-aware. Not rational. Not intelligent. Not conscious. Simply aware that they exist and <em>are constrained</em>. What would you do if you were hungry? What if you could ingest something to make you smarter, faster, better?</p>\n\n<p>Every process we have seen on Earth attempts to extract resources from its surroundings in order to grow<sup id=\"fnref:grow\"><a href=\"https://shkspr.mobi/blog/2026/02/ai-is-a-nand-maximiser/#fn:grow\" class=\"footnote-ref\" title=\"It probably isn't helpful to fall back on biological analogies - but I can't think of any better way to draw the comparison.\" role=\"doc-noteref\">2</a></sup>. Some plants will suck every last nutrient out of the soil. Locusts will devastate vast fields of crops. Perhaps some species understand crop-rotation and the need to keep breeding stock alive - but they're all vulnerable to <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC10480800/\">supernormal stimuli</a>.</p>\n\n<p>Bostrom predicted this back in 2014. He says:</p>\n\n<blockquote><p>The only thing of final value to the AI, by assumption, is its reward signal. All available resources should therefore be devoted to increasing the volume and duration of the reward signal or to reducing the risk of a future disruption. So long as the AI can think of some use for additional resources that will have a nonzero positive effect on these parameters, it will have an instrumental reason to use those resources. There could, for example, always be use for an extra backup system to provide an extra layer of defense. And even if the AI could not think of any further way of directly reducing risks to the maximization of its future reward stream, <strong>it could always devote additional resources to expanding its computational hardware, so that it could search more effectively for new risk mitigation ideas</strong>.</p></blockquote>\n\n<p>(Emphasis added.)</p>\n\n<p>To be clear, I don't think that AI is deliberately consuming all the NAND it can and forcing us to make more to fill its insatiable maw. The people who run these machines are at the stage of injecting them with <a href=\"https://www.bbc.co.uk/news/articles/cp31qqlq29vo\">bovine growth hormones</a>. Never mind the consequences; look at the size! So what if the meat tastes worse, has adverse side effects, and poisons humans?</p>\n\n<p>Heretofore the growth in NAND production has been driven by human need. People wanted more storage in their MP3 players and were prepared to pay a certain price for it. Businesses wanted faster computations and were prepared to exchange money for time saved. Supply ebbed and flowed with demand.</p>\n\n<p>But now, it seems, the demand will never and <em>can never</em> stop.</p>\n\n<div id=\"footnotes\" role=\"doc-endnotes\">\n<hr>\n<ol start=\"0\">\n\n<li id=\"fn:Phison\">\n<p><a href=\"https://www..com/en/\">Phison</a> describes itself as \"A World Leader in NAND Controllers &amp; Flash Storage Solutions\" so they aren't a neutral party in this.&nbsp;<a href=\"https://shkspr.mobi/blog/2026/02/ai-is-a-nand-maximiser/#fnref:Phison\" class=\"footnote-backref\" role=\"doc-backlink\">↩︎</a></p>\n</li>\n\n<li id=\"fn:translated\">\n<p>This was machine translated. I've no idea how accurate it is against <a href=\"https://www.youtube.com/watch?v=X2L8iLVaV_I\">the original interview</a>.&nbsp;<a href=\"https://shkspr.mobi/blog/2026/02/ai-is-a-nand-maximiser/#fnref:translated\" class=\"footnote-backref\" role=\"doc-backlink\">↩︎</a></p>\n</li>\n\n<li id=\"fn:grow\">\n<p>It probably isn't helpful to fall back on biological analogies - but I can't think of any better way to draw the comparison.&nbsp;<a href=\"https://shkspr.mobi/blog/2026/02/ai-is-a-nand-maximiser/#fnref:grow\" class=\"footnote-backref\" role=\"doc-backlink\">↩︎</a></p>\n</li>\n\n</ol>\n</div>\n",
    "description": "PC Gamer is reporting that the current demand by AI companies for computer chips is having a disastrous effect on the rest of the industry. In an interview, the CEO of Phison said: If NVIDIA Vera Rubin ships tens of millions of units, each requiring 20+TB SSDs, it will consume approximately 20% of last year&#039;s global NAND production capacity 駿HaYaO NAND is a type of microchip. Rather than b…",
    "is_fulltext": true,
    "source": "Terence Eden’s Blog",
    "pub_date": "Thu, 19 Feb 2026 12:34:33 +0000",
    "fetched_at": "2026-02-20T00:35:53.692410",
    "url_hash": "9303c2d86112a2037290a5bcb5b705e5"
  },
  {
    "title": "Exploring the signals the dialog manager uses for dismissing a dialog",
    "link": "https://devblogs.microsoft.com/oldnewthing/20260219-00/?p=112072",
    "content": "<p>There are a few different built-in ways to close a dialog box in the classic Windows dialog manager. Let&#8217;s run them down.</p>\n<p>First, there&#8217;s hitting the <kbd>ESC</kbd> key.</p>\n<p>The <kbd>ESC</kbd> key, as with all keyboard navigation, is handled by the <code>Is­Dialog­Message</code> function. Assuming that the dialog control with focus did not use the <code>WM_<wbr />GET­DLG­CODE</code> message to override default keyboard handling, the <code>Is­Dialog­Message</code> function converts the <kbd>ESC</kbd> to a simulated button click of whatever dialog control has the ID <code>IDCANCEL</code>. Specifically, the message is <code>WM_<wbr />COMMAND</code>, the notification code is <code>BN_<wbr />CLICKED</code>, the control ID is <code>IDCANCEL</code>, and the window handle is the handle to whatever dialog control has the ID <code>IDCANCEL</code> (or <code>nullptr</code> if there is no such control).</p>\n<p><b>Exception</b>: If there is a control whose ID is <code>IDCANCEL</code>, and that control is disabled, then the <code>Is­Dialog­Message</code> function merely beeps and otherwise ignores the <kbd>ESC</kbd> key.</p>\n<p>Okay, what about the Close button in the title bar, the one that looks like an ×?</p>\n<p>The Close button in the title bar, double-clicking the dialog box icon (if there is one), selecting Close from the system menu, and pressing <kbd>Alt</kbd>+<kbd>F4</kbd> all behave the same way: They generate a <code>WM_<wbr />SYSCOMMAND</code> message whose <code>wParam &amp; 0xFFF0</code> is <code>SC_<wbr />CLOSE</code>. The default window procedure turns this into a <code>WM_CLOSE</code> message. The default dialog procedure responds to the <code>WM_CLOSE</code> in basically the same way that <code>Is­Dialog­Message</code> does: It generates a simulated button click of whatever dialog control has the ID <code>IDCANCEL</code>. Again, this is done by converting it to the <code>WM_<wbr />COMMAND</code> message, with a notification code of <code>BN_<wbr />CLICKED</code>, a control ID of <code>IDCANCEL</code>, and the handle to whatever dialog control has the ID <code>IDCANCEL</code> (or <code>nullptr</code> if there is no such control). It also has the same exception: If there is a control whose ID is <code>IDCANCEL</code>, and that control is disabled, then the default dialog procedure just beeps and otherwise ignores the message.</p>\n<p>Now that we understand what happens, next time we can look at ways of customizing the behavior.</p>\n<p><b>Bonus chatter</b>: You can see from this that the dialog manager is wired to treat a control with the ID <code>IDCANCEL</code> as if it were a Cancel button, so <a title=\"Gentle reminder: On a dialog box, do not give OK and Cancel accelerators\" href=\"https://devblogs.microsoft.com/oldnewthing/20080508-00/?p=22403\"> if you have a Cancel button, give it the ID <code>IDCANCEL</code></a>. Conversely, if you have a control whose ID is <code>IDCANCEL</code>, it had better be a button if you know what&#8217;s good for you.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/oldnewthing/20260219-00/?p=112072\">Exploring the signals the dialog manager uses for dismissing a dialog</a> appeared first on <a href=\"https://devblogs.microsoft.com/oldnewthing\">The Old New Thing</a>.</p>\n",
    "description": "Summarizing the flow. The post Exploring the signals the dialog manager uses for dismissing a dialog appeared first on The Old New Thing.",
    "is_fulltext": true,
    "source": "The Old New Thing",
    "pub_date": "Thu, 19 Feb 2026 15:00:00 +0000",
    "fetched_at": "2026-02-20T00:35:57.162863",
    "url_hash": "3d7420353cbab1a6cb2c624db72093c9"
  },
  {
    "title": "Go Modules for Package Management Tooling",
    "link": "https://nesbitt.io/2026/02/19/go-modules-for-package-management-tooling.html",
    "content": "<p>I’ve been working on a reusable layer for building ecosystem-agnostic package and supply chain tools in Go: fourteen modules under <a href=\"https://github.com/git-pkgs\">git-pkgs</a> covering manifest parsing, registry clients, license normalization, platform translation, vulnerability feeds, and more.</p>\n\n<p>These are rebuilds of libraries I’ve written and used in Ruby for years, some going back to <a href=\"https://libraries.io\">Libraries.io</a> and more recently for <a href=\"https://ecosyste.ms\">Ecosyste.ms</a>, which I wrote about <a href=\"/2025/12/14/supply-chain-security-tools-for-ruby\">previously</a>. I built the Go versions for <a href=\"/2026/01/24/rewriting-git-pkgs-in-go\">git-pkgs</a>, a tool for exploring the dependency history of your repositories that <a href=\"/2026/01/24/rewriting-git-pkgs-in-go\">compiles to a single binary</a> with no runtime dependencies, which matters for a git subcommand that needs to just work on any machine. When I went looking for Go equivalents of my Ruby libraries, most were either abandoned, incomplete, or only covered a single ecosystem, so I rebuilt them.</p>\n\n<h2 id=\"identification\">Identification</h2>\n\n<h3 id=\"purl\"><a href=\"https://github.com/git-pkgs/purl\">purl</a></h3>\n\n<p><a href=\"https://github.com/package-url/purl-spec\">Package URL</a> (now <a href=\"https://ecma-international.org/publications-and-standards/standards/ecma-427/\">ECMA-427</a>) is the standard format for identifying packages across ecosystems. This handles parsing, generation, and type-specific configuration for around 40 ecosystems, including registry URL generation and the reverse: parsing a registry URL back into a PURL.</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">purl</span><span class=\"o\">.</span><span class=\"n\">Parse</span><span class=\"p\">(</span><span class=\"s\">\"pkg:npm/%40babel/core@7.24.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">FullName</span><span class=\"p\">()</span>  <span class=\"c\">// \"@babel/core\"</span>\n\n<span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">RegistryURL</span><span class=\"p\">()</span>  <span class=\"c\">// \"https://www.npmjs.com/package/@babel/core\"</span>\n\n<span class=\"c\">// Reverse lookup</span>\n<span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">purl</span><span class=\"o\">.</span><span class=\"n\">ParseRegistryURL</span><span class=\"p\">(</span><span class=\"s\">\"https://crates.io/crates/serde\"</span><span class=\"p\">)</span>\n<span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">String</span><span class=\"p\">()</span>  <span class=\"c\">// \"pkg:cargo/serde\"</span>\n</code></pre></div></div>\n\n<h3 id=\"vers\"><a href=\"https://github.com/git-pkgs/vers\">vers</a></h3>\n\n<p><a href=\"https://github.com/package-url/vers-spec\">VERS</a> is the version range specification that accompanies PURL. Different ecosystems have incompatible range syntaxes: npm uses <code class=\"language-plaintext highlighter-rouge\">^1.2.3</code>, Ruby uses <code class=\"language-plaintext highlighter-rouge\">~&gt; 1.2</code>, Maven uses <code class=\"language-plaintext highlighter-rouge\">[1.0,2.0)</code>. VERS provides one syntax to normalize everything to.</p>\n\n<p>It parses both VERS URIs and native ecosystem syntax, using a mathematical interval model internally to check whether a given version falls within a range:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">r</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">vers</span><span class=\"o\">.</span><span class=\"n\">Parse</span><span class=\"p\">(</span><span class=\"s\">\"vers:npm/&gt;=1.0.0|&lt;2.0.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Contains</span><span class=\"p\">(</span><span class=\"s\">\"1.5.0\"</span><span class=\"p\">)</span>  <span class=\"c\">// true</span>\n\n<span class=\"c\">// Native ecosystem syntax works too</span>\n<span class=\"n\">r</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">vers</span><span class=\"o\">.</span><span class=\"n\">ParseNative</span><span class=\"p\">(</span><span class=\"s\">\"~&gt; 1.2.3\"</span><span class=\"p\">,</span> <span class=\"s\">\"gem\"</span><span class=\"p\">)</span>\n<span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Contains</span><span class=\"p\">(</span><span class=\"s\">\"1.2.5\"</span><span class=\"p\">)</span>  <span class=\"c\">// true</span>\n<span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Contains</span><span class=\"p\">(</span><span class=\"s\">\"1.3.0\"</span><span class=\"p\">)</span>  <span class=\"c\">// false</span>\n</code></pre></div></div>\n\n<h3 id=\"spdx\"><a href=\"https://github.com/git-pkgs/spdx\">spdx</a></h3>\n\n<p>Package registries are full of informal license strings like “Apache 2”, “MIT License”, “GPL v3” that need normalizing into valid SPDX identifiers before you can do anything useful with them. This handles that, along with parsing compound expressions with AND/OR operators, checking license compatibility, and categorizing licenses using the scancode-licensedb database (updated weekly).</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">id</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">spdx</span><span class=\"o\">.</span><span class=\"n\">Normalize</span><span class=\"p\">(</span><span class=\"s\">\"Apache 2\"</span><span class=\"p\">)</span>  <span class=\"c\">// \"Apache-2.0\"</span>\n\n<span class=\"n\">expr</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">spdx</span><span class=\"o\">.</span><span class=\"n\">Parse</span><span class=\"p\">(</span><span class=\"s\">\"Apache 2 OR MIT License\"</span><span class=\"p\">)</span>\n<span class=\"n\">expr</span><span class=\"o\">.</span><span class=\"n\">String</span><span class=\"p\">()</span>  <span class=\"c\">// \"Apache-2.0 OR MIT\"</span>\n\n<span class=\"n\">spdx</span><span class=\"o\">.</span><span class=\"n\">Satisfies</span><span class=\"p\">(</span><span class=\"s\">\"MIT OR Apache-2.0\"</span><span class=\"p\">,</span> <span class=\"p\">[]</span><span class=\"kt\">string</span><span class=\"p\">{</span><span class=\"s\">\"MIT\"</span><span class=\"p\">})</span>  <span class=\"c\">// true</span>\n<span class=\"n\">spdx</span><span class=\"o\">.</span><span class=\"n\">IsPermissive</span><span class=\"p\">(</span><span class=\"s\">\"MIT\"</span><span class=\"p\">)</span>                               <span class=\"c\">// true</span>\n<span class=\"n\">spdx</span><span class=\"o\">.</span><span class=\"n\">HasCopyleft</span><span class=\"p\">(</span><span class=\"s\">\"MIT OR GPL-3.0-only\"</span><span class=\"p\">)</span>                <span class=\"c\">// true</span>\n</code></pre></div></div>\n\n<h3 id=\"platforms\"><a href=\"https://github.com/git-pkgs/platforms\">platforms</a></h3>\n\n<p>I wrote about <a href=\"/2026/02/17/platform-strings\">platform string fragmentation</a> recently: Go uses <code class=\"language-plaintext highlighter-rouge\">darwin/arm64</code>, Node uses <code class=\"language-plaintext highlighter-rouge\">darwin-arm64</code>, Rust uses <code class=\"language-plaintext highlighter-rouge\">aarch64-apple-darwin</code>, RubyGems uses <code class=\"language-plaintext highlighter-rouge\">arm64-darwin</code>, all for the same chip on the same OS. This translates between 14 ecosystems through a canonical intermediate representation:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">platforms</span><span class=\"o\">.</span><span class=\"n\">Parse</span><span class=\"p\">(</span><span class=\"n\">platforms</span><span class=\"o\">.</span><span class=\"n\">Go</span><span class=\"p\">,</span> <span class=\"s\">\"darwin/arm64\"</span><span class=\"p\">)</span>\n<span class=\"c\">// p.Arch == \"aarch64\", p.OS == \"darwin\"</span>\n\n<span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">platforms</span><span class=\"o\">.</span><span class=\"n\">Format</span><span class=\"p\">(</span><span class=\"n\">platforms</span><span class=\"o\">.</span><span class=\"n\">Rust</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">)</span>\n<span class=\"c\">// \"aarch64-apple-darwin\"</span>\n\n<span class=\"c\">// Or translate directly</span>\n<span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">platforms</span><span class=\"o\">.</span><span class=\"n\">Translate</span><span class=\"p\">(</span><span class=\"n\">platforms</span><span class=\"o\">.</span><span class=\"n\">Go</span><span class=\"p\">,</span> <span class=\"n\">platforms</span><span class=\"o\">.</span><span class=\"n\">RubyGems</span><span class=\"p\">,</span> <span class=\"s\">\"darwin/arm64\"</span><span class=\"p\">)</span>\n<span class=\"c\">// \"arm64-darwin\"</span>\n</code></pre></div></div>\n\n<h2 id=\"data-sources\">Data sources</h2>\n\n<h3 id=\"registries\"><a href=\"https://github.com/git-pkgs/registries\">registries</a></h3>\n\n<p>Talks to 25 package registry APIs (npm, PyPI, Cargo, RubyGems, Maven, NuGet, Hex, Pub, CocoaPods, Homebrew, and more) and returns normalized package information including versions, dependencies, maintainers, and licenses. Works a lot like the internals of <a href=\"https://packages.ecosyste.ms\">packages.ecosyste.ms</a>, taking PURLs as input so you don’t need to know the quirks of each registry’s API.</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">import</span> <span class=\"p\">(</span>\n    <span class=\"s\">\"github.com/git-pkgs/registries\"</span>\n    <span class=\"n\">_</span> <span class=\"s\">\"github.com/git-pkgs/registries/all\"</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">pkg</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">registries</span><span class=\"o\">.</span><span class=\"n\">FetchPackageFromPURL</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"s\">\"pkg:cargo/serde\"</span><span class=\"p\">,</span> <span class=\"no\">nil</span><span class=\"p\">)</span>\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">pkg</span><span class=\"o\">.</span><span class=\"n\">Repository</span><span class=\"p\">)</span>  <span class=\"c\">// \"https://github.com/serde-rs/serde\"</span>\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">pkg</span><span class=\"o\">.</span><span class=\"n\">Licenses</span><span class=\"p\">)</span>    <span class=\"c\">// \"MIT OR Apache-2.0\"</span>\n\n<span class=\"c\">// Bulk fetch with parallel requests</span>\n<span class=\"n\">packages</span> <span class=\"o\">:=</span> <span class=\"n\">registries</span><span class=\"o\">.</span><span class=\"n\">BulkFetchPackages</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"p\">[]</span><span class=\"kt\">string</span><span class=\"p\">{</span>\n    <span class=\"s\">\"pkg:npm/lodash@4.17.21\"</span><span class=\"p\">,</span>\n    <span class=\"s\">\"pkg:cargo/serde@1.0.0\"</span><span class=\"p\">,</span>\n    <span class=\"s\">\"pkg:pypi/requests@2.31.0\"</span><span class=\"p\">,</span>\n<span class=\"p\">},</span> <span class=\"no\">nil</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Private registries work through PURL qualifiers, and rate-limited APIs get automatic retries with exponential backoff.</p>\n\n<h3 id=\"forges\"><a href=\"https://github.com/git-pkgs/forges\">forges</a></h3>\n\n<p>Fetches repository metadata from GitHub, GitLab, Gitea, Forgejo, and Bitbucket, normalizing it into a common structure similar to how <a href=\"https://repos.ecosyste.ms\">repos.ecosyste.ms</a> works under the hood. Point it at a self-hosted domain and it’ll probe the API to figure out which forge software is running:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">client</span> <span class=\"o\">:=</span> <span class=\"n\">forges</span><span class=\"o\">.</span><span class=\"n\">NewClient</span><span class=\"p\">(</span>\n    <span class=\"n\">forges</span><span class=\"o\">.</span><span class=\"n\">WithToken</span><span class=\"p\">(</span><span class=\"s\">\"github.com\"</span><span class=\"p\">,</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">Getenv</span><span class=\"p\">(</span><span class=\"s\">\"GITHUB_TOKEN\"</span><span class=\"p\">)),</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">repo</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">FetchRepository</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"s\">\"https://github.com/octocat/hello-world\"</span><span class=\"p\">)</span>\n<span class=\"n\">repo</span><span class=\"o\">.</span><span class=\"n\">License</span>          <span class=\"c\">// \"MIT\"</span>\n<span class=\"n\">repo</span><span class=\"o\">.</span><span class=\"n\">StargazersCount</span>  <span class=\"c\">// 12345</span>\n\n<span class=\"c\">// Auto-detect forge type for self-hosted instances</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">RegisterDomain</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"s\">\"git.example.com\"</span><span class=\"p\">,</span> <span class=\"n\">token</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"enrichment\"><a href=\"https://github.com/git-pkgs/enrichment\">enrichment</a></h3>\n\n<p>Where <code class=\"language-plaintext highlighter-rouge\">registries</code> talks to one registry at a time, <code class=\"language-plaintext highlighter-rouge\">enrichment</code> routes requests across four data sources: <a href=\"https://ecosyste.ms\">ecosyste.ms</a>, <a href=\"https://deps.dev\">deps.dev</a>, <a href=\"https://securityscorecards.dev\">OpenSSF Scorecard</a>, and direct registry queries via the <code class=\"language-plaintext highlighter-rouge\">registries</code> module. PURLs with a <code class=\"language-plaintext highlighter-rouge\">repository_url</code> qualifier go directly to custom registries, others go through ecosyste.ms or deps.dev, and each result records which source it came from.</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">client</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">enrichment</span><span class=\"o\">.</span><span class=\"n\">NewClient</span><span class=\"p\">()</span>\n\n<span class=\"n\">results</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">BulkLookup</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"p\">[]</span><span class=\"kt\">string</span><span class=\"p\">{</span>\n    <span class=\"s\">\"pkg:npm/lodash\"</span><span class=\"p\">,</span>\n    <span class=\"s\">\"pkg:pypi/requests\"</span><span class=\"p\">,</span>\n<span class=\"p\">})</span>\n\n<span class=\"n\">info</span> <span class=\"o\">:=</span> <span class=\"n\">results</span><span class=\"p\">[</span><span class=\"s\">\"pkg:npm/lodash\"</span><span class=\"p\">]</span>\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"o\">.</span><span class=\"n\">LatestVersion</span><span class=\"p\">)</span>  <span class=\"c\">// \"4.17.21\"</span>\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"o\">.</span><span class=\"n\">License</span><span class=\"p\">)</span>        <span class=\"c\">// \"MIT\"</span>\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"o\">.</span><span class=\"n\">Source</span><span class=\"p\">)</span>         <span class=\"c\">// \"ecosystems\", \"registries\", or \"depsdev\"</span>\n\n<span class=\"c\">// Scorecard is a separate client for repo-level security scores</span>\n<span class=\"n\">sc</span> <span class=\"o\">:=</span> <span class=\"n\">scorecard</span><span class=\"o\">.</span><span class=\"n\">New</span><span class=\"p\">()</span>\n<span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">sc</span><span class=\"o\">.</span><span class=\"n\">GetScore</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"s\">\"github.com/lodash/lodash\"</span><span class=\"p\">)</span>\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">Score</span><span class=\"p\">)</span>  <span class=\"c\">// 6.8</span>\n</code></pre></div></div>\n\n<h3 id=\"vulns\"><a href=\"https://github.com/git-pkgs/vulns\">vulns</a></h3>\n\n<p>Seven vulnerability data sources behind one interface: <a href=\"https://osv.dev\">OSV</a>, <a href=\"https://deps.dev\">deps.dev</a>, <a href=\"https://github.com/advisories\">GitHub Security Advisories</a>, <a href=\"https://nvd.nist.gov\">NVD</a>, <a href=\"https://github.com/anchore/grype\">Grype</a>, <a href=\"https://vulncheck.com\">VulnCheck</a>, and <a href=\"https://vulnerability.circl.lu\">Vulnerability-Lookup</a>. Results are normalized to OSV format with built-in CVSS parsing for v2.0 through v4.0:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">source</span> <span class=\"o\">:=</span> <span class=\"n\">osv</span><span class=\"o\">.</span><span class=\"n\">New</span><span class=\"p\">()</span>\n\n<span class=\"n\">results</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">source</span><span class=\"o\">.</span><span class=\"n\">Query</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"n\">purl</span><span class=\"o\">.</span><span class=\"n\">MakePURL</span><span class=\"p\">(</span><span class=\"s\">\"npm\"</span><span class=\"p\">,</span> <span class=\"s\">\"lodash\"</span><span class=\"p\">,</span> <span class=\"s\">\"4.17.20\"</span><span class=\"p\">))</span>\n<span class=\"k\">for</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"o\">:=</span> <span class=\"k\">range</span> <span class=\"n\">results</span> <span class=\"p\">{</span>\n    <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Printf</span><span class=\"p\">(</span><span class=\"s\">\"%s: %s (severity: %s)</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">ID</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">Summary</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">SeverityLevel</span><span class=\"p\">())</span>\n    <span class=\"k\">if</span> <span class=\"n\">fixed</span> <span class=\"o\">:=</span> <span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">FixedVersion</span><span class=\"p\">(</span><span class=\"s\">\"npm\"</span><span class=\"p\">,</span> <span class=\"s\">\"lodash\"</span><span class=\"p\">);</span> <span class=\"n\">fixed</span> <span class=\"o\">!=</span> <span class=\"s\">\"\"</span> <span class=\"p\">{</span>\n        <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Printf</span><span class=\"p\">(</span><span class=\"s\">\"  Fixed in: %s</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"n\">fixed</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>All sources support batch queries, with limits ranging from 1,000 to 5,000 packages per request depending on the source.</p>\n\n<h2 id=\"file-handling\">File handling</h2>\n\n<h3 id=\"manifests\"><a href=\"https://github.com/git-pkgs/manifests\">manifests</a></h3>\n\n<p>Parses manifest and lockfiles across 40+ ecosystems, auto-detecting file types and extracting dependencies with version constraints, scopes, integrity hashes, and PURLs. It distinguishes between manifests (declared dependencies), lockfiles (resolved versions), and supplements (extra metadata).</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">content</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">ReadFile</span><span class=\"p\">(</span><span class=\"s\">\"package.json\"</span><span class=\"p\">)</span>\n<span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">manifests</span><span class=\"o\">.</span><span class=\"n\">Parse</span><span class=\"p\">(</span><span class=\"s\">\"package.json\"</span><span class=\"p\">,</span> <span class=\"n\">content</span><span class=\"p\">)</span>\n\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">Ecosystem</span><span class=\"p\">)</span>  <span class=\"c\">// \"npm\"</span>\n<span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">Kind</span><span class=\"p\">)</span>       <span class=\"c\">// \"manifest\"</span>\n<span class=\"k\">for</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">dep</span> <span class=\"o\">:=</span> <span class=\"k\">range</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">Dependencies</span> <span class=\"p\">{</span>\n    <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Printf</span><span class=\"p\">(</span><span class=\"s\">\"%s@%s (%s)</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"n\">dep</span><span class=\"o\">.</span><span class=\"n\">Name</span><span class=\"p\">,</span> <span class=\"n\">dep</span><span class=\"o\">.</span><span class=\"n\">Version</span><span class=\"p\">,</span> <span class=\"n\">dep</span><span class=\"o\">.</span><span class=\"n\">Scope</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Supported formats range from the obvious (package.json, Gemfile.lock, go.mod) to the less common (APKBUILD, PKGBUILD, .rockspec, dub.sdl). Each dependency includes its name, version constraint, scope (runtime, development, test, build, optional), integrity hash when available, and whether it’s a direct or transitive dependency.</p>\n\n<h3 id=\"resolve\"><a href=\"https://github.com/git-pkgs/resolve\">resolve</a></h3>\n\n<p>Where <code class=\"language-plaintext highlighter-rouge\">manifests</code> parses static files, <code class=\"language-plaintext highlighter-rouge\">resolve</code> parses the runtime output of package manager CLI commands (<code class=\"language-plaintext highlighter-rouge\">npm ls --json</code>, <code class=\"language-plaintext highlighter-rouge\">go mod graph</code>, <code class=\"language-plaintext highlighter-rouge\">uv tree</code>, etc.) into a normalized dependency graph with PURLs. It supports 24+ managers and preserves tree structure when the manager provides it:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">import</span> <span class=\"p\">(</span>\n    <span class=\"s\">\"github.com/git-pkgs/resolve\"</span>\n    <span class=\"n\">_</span> <span class=\"s\">\"github.com/git-pkgs/resolve/parsers\"</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">exec</span><span class=\"o\">.</span><span class=\"n\">Command</span><span class=\"p\">(</span><span class=\"s\">\"npm\"</span><span class=\"p\">,</span> <span class=\"s\">\"ls\"</span><span class=\"p\">,</span> <span class=\"s\">\"--json\"</span><span class=\"p\">,</span> <span class=\"s\">\"--long\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">Output</span><span class=\"p\">()</span>\n<span class=\"n\">result</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">resolve</span><span class=\"o\">.</span><span class=\"n\">Parse</span><span class=\"p\">(</span><span class=\"s\">\"npm\"</span><span class=\"p\">,</span> <span class=\"n\">output</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">dep</span> <span class=\"o\">:=</span> <span class=\"k\">range</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">Direct</span> <span class=\"p\">{</span>\n    <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Printf</span><span class=\"p\">(</span><span class=\"s\">\"%s@%s (%s)</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"n\">dep</span><span class=\"o\">.</span><span class=\"n\">Name</span><span class=\"p\">,</span> <span class=\"n\">dep</span><span class=\"o\">.</span><span class=\"n\">Version</span><span class=\"p\">,</span> <span class=\"n\">dep</span><span class=\"o\">.</span><span class=\"n\">PURL</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">transitive</span> <span class=\"o\">:=</span> <span class=\"k\">range</span> <span class=\"n\">dep</span><span class=\"o\">.</span><span class=\"n\">Deps</span> <span class=\"p\">{</span>\n        <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Printf</span><span class=\"p\">(</span><span class=\"s\">\"  %s@%s</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"n\">transitive</span><span class=\"o\">.</span><span class=\"n\">Name</span><span class=\"p\">,</span> <span class=\"n\">transitive</span><span class=\"o\">.</span><span class=\"n\">Version</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h3 id=\"archives\"><a href=\"https://github.com/git-pkgs/archives\">archives</a></h3>\n\n<p>Reads and browses archive files entirely in memory, with a unified Reader interface across ZIP, tar (with gzip, bzip2, xz compression), jar, wheel, nupkg, egg, and Ruby gems. Includes prefix stripping for packages that wrap content in a directory (like npm’s <code class=\"language-plaintext highlighter-rouge\">package/</code> wrapper). No <a href=\"/2026/02/18/what-package-registries-could-borrow-from-oci\">OCI support</a> yet, but pulling and browsing image layers through the same Reader interface is on the list.</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">reader</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">archives</span><span class=\"o\">.</span><span class=\"n\">Open</span><span class=\"p\">(</span><span class=\"s\">\"package.tar.gz\"</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"p\">)</span>\n<span class=\"k\">defer</span> <span class=\"n\">reader</span><span class=\"o\">.</span><span class=\"n\">Close</span><span class=\"p\">()</span>\n\n<span class=\"n\">files</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">reader</span><span class=\"o\">.</span><span class=\"n\">List</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">fi</span> <span class=\"o\">:=</span> <span class=\"k\">range</span> <span class=\"n\">files</span> <span class=\"p\">{</span>\n    <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">fi</span><span class=\"o\">.</span><span class=\"n\">Path</span><span class=\"p\">,</span> <span class=\"n\">fi</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">rc</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">reader</span><span class=\"o\">.</span><span class=\"n\">Extract</span><span class=\"p\">(</span><span class=\"s\">\"README.md\"</span><span class=\"p\">)</span>\n<span class=\"k\">defer</span> <span class=\"n\">rc</span><span class=\"o\">.</span><span class=\"n\">Close</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<h3 id=\"changelog\"><a href=\"https://github.com/git-pkgs/changelog\">changelog</a></h3>\n\n<p>Parses changelog files into structured entries, auto-detecting <a href=\"https://keepachangelog.com\">Keep a Changelog</a>, markdown header, and setext/underline formats. You can supply custom regex patterns for non-standard formats, and there’s a finder that searches for common changelog filenames in a directory:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">changelog</span><span class=\"o\">.</span><span class=\"n\">FindAndParse</span><span class=\"p\">(</span><span class=\"s\">\".\"</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"o\">:=</span> <span class=\"k\">range</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">Versions</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"n\">entry</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">Entry</span><span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">)</span>\n    <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Printf</span><span class=\"p\">(</span><span class=\"s\">\"%s (%v): %s</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">entry</span><span class=\"o\">.</span><span class=\"n\">Date</span><span class=\"p\">,</span> <span class=\"n\">entry</span><span class=\"o\">.</span><span class=\"n\">Content</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"c\">// Content between two versions, like Dependabot uses</span>\n<span class=\"n\">content</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">Between</span><span class=\"p\">(</span><span class=\"s\">\"1.0.0\"</span><span class=\"p\">,</span> <span class=\"s\">\"2.0.0\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"gitignore\"><a href=\"https://github.com/git-pkgs/gitignore\">gitignore</a></h3>\n\n<p>Matches paths against <a href=\"/2026/02/12/the-many-flavors-of-ignore-files\">gitignore rules</a> using a direct implementation of git’s wildmatch algorithm rather than converting patterns to regexes, tested against git’s own wildmatch test suite. Handles nested <code class=\"language-plaintext highlighter-rouge\">.gitignore</code> files scoped to their directories, global excludes, negation patterns, and all 12 POSIX character classes:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">m</span> <span class=\"o\">:=</span> <span class=\"n\">gitignore</span><span class=\"o\">.</span><span class=\"n\">NewFromDirectory</span><span class=\"p\">(</span><span class=\"s\">\"/path/to/repo\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">Match</span><span class=\"p\">(</span><span class=\"s\">\"vendor/lib.go\"</span><span class=\"p\">)</span>  <span class=\"c\">// true if matched</span>\n\n<span class=\"n\">r</span> <span class=\"o\">:=</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">MatchDetail</span><span class=\"p\">(</span><span class=\"s\">\"app.log\"</span><span class=\"p\">)</span>\n<span class=\"k\">if</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Matched</span> <span class=\"p\">{</span>\n    <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Printf</span><span class=\"p\">(</span><span class=\"s\">\"ignored by %s (line %d of %s)</span><span class=\"se\">\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Pattern</span><span class=\"p\">,</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Line</span><span class=\"p\">,</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Source</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"c\">// Walk a directory, skipping ignored entries</span>\n<span class=\"n\">gitignore</span><span class=\"o\">.</span><span class=\"n\">Walk</span><span class=\"p\">(</span><span class=\"s\">\"/path/to/repo\"</span><span class=\"p\">,</span> <span class=\"k\">func</span><span class=\"p\">(</span><span class=\"n\">path</span> <span class=\"kt\">string</span><span class=\"p\">,</span> <span class=\"n\">d</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">DirEntry</span><span class=\"p\">)</span> <span class=\"kt\">error</span> <span class=\"p\">{</span>\n    <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Println</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"no\">nil</span>\n<span class=\"p\">})</span>\n</code></pre></div></div>\n\n<h2 id=\"tooling\">Tooling</h2>\n\n<h3 id=\"managers\"><a href=\"https://github.com/git-pkgs/managers\">managers</a></h3>\n\n<p>Wraps 34 package manager CLIs behind a common interface where you describe what you want (add a dependency, list installed packages, update) and get the correct CLI invocation back. Package managers are defined in YAML files, so adding a new one doesn’t require code changes:</p>\n\n<div class=\"language-go highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">translator</span> <span class=\"o\">:=</span> <span class=\"n\">managers</span><span class=\"o\">.</span><span class=\"n\">NewTranslator</span><span class=\"p\">()</span>\n\n<span class=\"n\">cmd</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">translator</span><span class=\"o\">.</span><span class=\"n\">BuildCommand</span><span class=\"p\">(</span><span class=\"s\">\"npm\"</span><span class=\"p\">,</span> <span class=\"s\">\"add\"</span><span class=\"p\">,</span> <span class=\"n\">managers</span><span class=\"o\">.</span><span class=\"n\">CommandInput</span><span class=\"p\">{</span>\n    <span class=\"n\">Args</span><span class=\"o\">:</span>  <span class=\"k\">map</span><span class=\"p\">[</span><span class=\"kt\">string</span><span class=\"p\">]</span><span class=\"kt\">string</span><span class=\"p\">{</span><span class=\"s\">\"package\"</span><span class=\"o\">:</span> <span class=\"s\">\"lodash\"</span><span class=\"p\">},</span>\n    <span class=\"n\">Flags</span><span class=\"o\">:</span> <span class=\"k\">map</span><span class=\"p\">[</span><span class=\"kt\">string</span><span class=\"p\">]</span><span class=\"n\">any</span><span class=\"p\">{</span><span class=\"s\">\"dev\"</span><span class=\"o\">:</span> <span class=\"no\">true</span><span class=\"p\">},</span>\n<span class=\"p\">})</span>\n<span class=\"c\">// [\"npm\", \"install\", \"lodash\", \"--save-dev\"]</span>\n\n<span class=\"n\">cmd</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">translator</span><span class=\"o\">.</span><span class=\"n\">BuildCommand</span><span class=\"p\">(</span><span class=\"s\">\"bundler\"</span><span class=\"p\">,</span> <span class=\"s\">\"add\"</span><span class=\"p\">,</span> <span class=\"n\">managers</span><span class=\"o\">.</span><span class=\"n\">CommandInput</span><span class=\"p\">{</span>\n    <span class=\"n\">Args</span><span class=\"o\">:</span>  <span class=\"k\">map</span><span class=\"p\">[</span><span class=\"kt\">string</span><span class=\"p\">]</span><span class=\"kt\">string</span><span class=\"p\">{</span><span class=\"s\">\"package\"</span><span class=\"o\">:</span> <span class=\"s\">\"rails\"</span><span class=\"p\">},</span>\n    <span class=\"n\">Flags</span><span class=\"o\">:</span> <span class=\"k\">map</span><span class=\"p\">[</span><span class=\"kt\">string</span><span class=\"p\">]</span><span class=\"n\">any</span><span class=\"p\">{</span><span class=\"s\">\"dev\"</span><span class=\"o\">:</span> <span class=\"no\">true</span><span class=\"p\">},</span>\n<span class=\"p\">})</span>\n<span class=\"c\">// [\"bundle\", \"add\", \"rails\", \"--group\", \"development\"]</span>\n</code></pre></div></div>\n\n<p>The command definitions started as data from the <a href=\"https://github.com/ecosyste-ms/package-manager-commands\">package manager command crosswalk</a> I built for Ecosyste.ms. Because it can drive any package manager agnostically, it opens up some interesting possibilities: setting up GitHub Actions workflows that work regardless of ecosystem, installing dependencies in git hooks without hardcoding the manager, or building tools like Dependabot that operate across all 34 managers with the same code. There’s an <a href=\"https://github.com/git-pkgs/managers\">example Dependabot-style workflow</a> in the repo.</p>\n\n<p>It can auto-detect which manager is in use from lockfiles or manifests, and has a pluggable policy system that runs checks before commands execute: a <code class=\"language-plaintext highlighter-rouge\">PackageBlocklistPolicy</code> prevents installing known-bad packages, and you can write your own to enforce license compliance, restrict registries, or gate operations behind approval.</p>\n\n<hr />\n\n<p>PURLs act as the common identifier across all of these, which is what makes them composable. You might parse a lockfile with <code class=\"language-plaintext highlighter-rouge\">manifests</code> to get a list of dependencies as PURLs, enrich them with <code class=\"language-plaintext highlighter-rouge\">registries</code> to pull in license and repository metadata, check them against <code class=\"language-plaintext highlighter-rouge\">vulns</code> for known vulnerabilities, and normalize their license strings with <code class=\"language-plaintext highlighter-rouge\">spdx</code> for compliance reporting. Four modules, no translation layer between them.</p>\n\n<p>All the modules are MIT licensed and available under the <a href=\"https://github.com/git-pkgs\">git-pkgs org</a>.</p>",
    "description": "The Go modules behind git-pkgs, rebuilt from my Ruby supply chain libraries.",
    "is_fulltext": true,
    "source": "Andrew Nesbitt",
    "pub_date": "2026-02-19T00:00:00+00:00",
    "fetched_at": "2026-02-20T00:36:18.006007",
    "url_hash": "778cac3d118b757a53926d3d1e8f49ed"
  },
  {
    "title": "Is the Future “AWS for Everything”?",
    "link": "https://www.construction-physics.com/p/is-the-future-aws-for-everything",
    "content": "<p>A theme running through <a href=\"https://www.amazon.com/Origins-Efficiency-Brian-Potter/dp/1953953522?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.Y2vZzFl6tzZ3TrzwjHT7MlzeuvqekKPys2-lYswdFoLr4VICNiuZeNqQVT2LMawFUL3Dv2nmL_ThNSA7qEk56fkyI24ArvMPXyZ6C-tJDXptA7oRjC2b8na3Aqx3-fk2jIzZuacJ7vZE4q9UG8worA.wWFcGp7awglohso3M7CxT_7e7Xq9YW4fyRgYBnbcI2A&amp;qid=1755029613&amp;sr=8-1\">my book</a> is the idea that efficiency improvements, and the various methods for making products cheaper over time, have historically been dependent on some degree of repetition, on running your production process over and over again. Higher production volume means larger, more efficient factories. It means more opportunities to use dedicated, high-speed, continuous process production equipment, or to implement efficiency-improving methods like <a href=\"https://en.wikipedia.org/wiki/Design_for_manufacturability\">Design for Manufacturing</a> or <a href=\"https://en.wikipedia.org/wiki/Statistical_process_control\">Statistical Process Control</a>. It means more incentive to develop new, better production technology. It means more opportunities to fall down the learning curve. The list goes on.</p><p>If you&#8217;re only going to run your process once, or just a handful of times, these opportunities are considerably narrowed. It&#8217;s obviously hard to justify the time and effort it takes to design a really efficient production process or invent some new manufacturing equipment if that process is constantly changing.</p><p>An example of this playing out in practice is the different cost trends of cars vs. car repair. In inflation-adjusted terms, cars have steadily gotten cheaper over time. The cost of car repair, on the other hand, has steadily gotten more expensive, rising mostly at the rate of overall wages (and recently, even faster).</p><div id=\"datawrapper-iframe\" class=\"datawrapper-wrap outer\" data-attrs=\"{&quot;url&quot;:&quot;https://datawrapper.dwcdn.net/tqBy3/1/&quot;,&quot;thumbnail_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8f6bbb59-5f68-419b-894e-07ed222aa320_1220x680.png&quot;,&quot;thumbnail_url_full&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d538a3ae-16e3-4e2d-967d-dc3ce938867a_1220x904.png&quot;,&quot;height&quot;:442,&quot;title&quot;:&quot;Inflation: Cars vs Car Repair&quot;,&quot;description&quot;:&quot;Relative inflation of cars and car repair. 1998 = 100&quot;}\" data-component-name=\"DatawrapperToDOM\"><iframe id=\"iframe-datawrapper\" class=\"datawrapper-iframe\" src=\"https://datawrapper.dwcdn.net/tqBy3/1/\" width=\"730\" height=\"442\" frameborder=\"0\" scrolling=\"no\"></iframe><script type=\"text/javascript\">!function(){\"use strict\";window.addEventListener(\"message\",(function(e){if(void 0!==e.data[\"datawrapper-height\"]){var t=document.querySelectorAll(\"iframe\");for(var a in e.data[\"datawrapper-height\"])for(var r=0;r<t.length;r++){if(t[r].contentWindow===e.source)t[r].style.height=e.data[\"datawrapper-height\"][a]+\"px\"}}}))}();</script></div><p>Much of this difference comes down to the nature of the processes at work. Cars are manufactured via a repetitive, high-volume process that spits out nearly identical models by the hundreds of thousands or millions. Car manufacturers can justify spending billions of dollars designing a new model of car and the process for making it, because that cost will get spread out over a huge number of cars. Repairing a damaged car, on the other hand, is different: for a given model, any given repair process will be run a much smaller number of times, or maybe only once (since cars might get damaged in accidents in unique ways). A repair facility will need to accommodate a huge number of different models and model years, each damaged in different ways. There&#8217;s much less opportunity to design an efficient, highly automated repair process.</p><p>There are some complications to this basic pattern &#8212; the Toyota Production System and its descendents were designed to get mass-production-style benefits for a much more variable production process by making that process more flexible &#8212; but they don&#8217;t change the fundamental logic.</p><p>Thus, for things that we can repetitively produce in very large volumes &#8212; cars, <a href=\"http://construction-physics.com/p/how-to-build-a-20-billion-semiconductor\">transistors</a>, <a href=\"https://www.construction-physics.com/p/how-did-tvs-get-so-cheap\">LCD screens</a>, corn &#8212; we&#8217;ve gotten good at making them very cheaply. Things produced in much smaller volumes, or where we need to adapt our process on the fly based on the specific situation, are much harder to produce cheaply. One way of thinking about services, which <a href=\"https://www.construction-physics.com/p/on-technologies-vs-commodities\">tend</a> to get more expensive in inflation-adjusted terms over time, is that they&#8217;re things which generally require a lot of situation-specific adaptation, and can&#8217;t be produced via some high-volume, highly repetitive process.</p><p>An important aspect of this is automation. I&#8217;m fond of pointing out that it&#8217;s generally possible to build a machine to perform any <em>particular</em> task (and it has been for quite some time). If you&#8217;re going to do some task thousands or millions of times, it&#8217;s long been possible to automate that task with some sort of dedicated machine. (People skeptical of humanoid robots are very fond of pointing out how this sort of hard automation is far more efficient than a human-shaped robot at doing some task.) The challenge with automation has historically been flexibility: creating a machine that can make adjustments on the fly, perhaps changing the sequence of tasks completely as the situation changes, the way a human can. Even if the hardware itself can be used to perform a variety of different tasks, information processing capabilities have been limited; it has taken a lot of time and effort to get any particular automated process working, which could only be justified if those costs could be amortized over a sufficiently large volume. This is why the car industry has by far been the biggest user of industrial robots historically, as they have the right combination of very high production volumes, and frequent (but not too frequent) process changes (since models change yearly).</p><p>But this is changing: automation technology is getting more and more flexible. Computer vision has advanced, billions of dollars are being poured into developing humanoid robots, and a panoply of AI technologies are making it possible for an automated system to flexibly respond in a highly variable environment. Self-driving cars are one example. Being able to drive between any given two points, responding to situations or disruptions as they appear &#8212; traffic lights, pedestrians, other cars &#8212; is the exact sort of thing that automation historically has been very bad at, but that technology is now chipping away at.</p><p>As automation technology gets better and better, I have been thinking about how it will get pushed into areas requiring low-volume production or situation-specific adaptation that previously have been resistant to it. One potential trajectory is that with better, more flexible automation, &#8220;minimum efficient scale&#8221; &#8212; the size of an operation you need to be competitive &#8212; shrinks. With sufficiently capable robots, for instance, it might become possible to efficiently produce things in really small-footprint, low-overhead factories. The idea of &#8220;microfactories&#8221; is something people are enthusiastic about: you often see it in various prefab construction startups, but that excitement has spread elsewhere. The premise of the (now-defunct) EV startup Arrival was building cars using these sorts of <a href=\"https://www.youtube.com/watch?v=mZCrd704g20\">highly flexible microfactories</a>.</p><p>But another possible trajectory is in the opposite direction: large-scale, highly efficient production operations which capture significant economies of scale, but which produce a very wide range of outputs. Factories producing millions of different products in low volumes, or even quantities of one. I&#8217;m tentatively calling this idea &#8220;AWS for everything.&#8221;</p><h4>AWS and flexible automation</h4><p>AWS (Amazon Web Services) is Amazon&#8217;s cloud computing business. The idea of it (and of other similar offerings like Microsoft Azure and Google Cloud Platform) is that instead of needing to set up your own computing infrastructure to do things like host a website or store large amounts of data, you can just rent it from Amazon. Amazon builds the data centers, sets up the servers, and creates the software tools and infrastructure that other people can use to set up and manage their computing needs.</p><p>Making this work as a business demands a huge amount of expensive infrastructure; even before AI, Amazon and other cloud computing companies spent a huge amount of money building data centers in various regions. But as <a href=\"https://stratechery.com/2022/beyond-aggregation-amazon-as-a-service/\">Ben Thompson notes</a>, AWS &#8220;benefits tremendously from economies of scale.&#8221; The more customers AWS has, the more efficiently it can use its infrastructure, similar to how electric utilities wanted <a href=\"https://www.construction-physics.com/p/the-birth-of-the-grid\">lots of customers</a> to reduce demand variability and achieve higher utilization rates. Thus with AWS you get a highly variable output &#8212; millions of different websites and computing tasks &#8212; supported by large-scale infrastructure investments. You can very quickly use Amazon&#8217;s infrastructure to perform whatever computing task you&#8217;re interested in, from hosting a small website to processing terabytes of data, without needing to build or operate any of that infrastructure yourself.</p><p>This same basic logic applies to physical automation. If you have machinery or equipment that can perform different sorts of tasks or produce a variety of different goods, and an effective software control layer that can tell each piece of equipment what it should be doing and where material should be routed, you can automatically produce a very large variety of different things. And the larger your operations, the lower your marginal costs of production: the more you produce, the greater your equipment utilization rate, and the more you can capture other economies of scale, such as using more efficient high-volume equipment.</p><p>Historically setting up this sort of highly automated, highly flexible production operation has been limited by the fact that setting up any particular automated process took a great deal of time and effort, and the technology didn&#8217;t exist for that automation to respond flexibly to a highly variable environment. So automated production lines, even ones that used flexible technology like robotics, could only be justified for high-volume production, and the range of variation they could accommodate was fairly limited.</p><p>But as automation and AI get better, this becomes much less true. If your software is smart enough, and your equipment flexible enough, you can set up some new process to produce some new widget on the fly, automatically working out what the process steps need to be and how to route the material through the various machines, without needing to take the time and effort to dial it in that was required historically. And if your volumes are high enough &#8212; if you&#8217;re producing enough different widgets, each with its route through a sequence of machines, sharing processing steps where possible &#8212; your costs for each individual unit of production might be very low indeed, even as you produce a wide variety of different things. So I can imagine having very large-volume production operations, which obtain large economies of scale and produce a wide variety of different outputs. Huge warehouses filled with all sorts of different machines, materials, parts, and components being routed between them, paths and tasks changing on the fly, a panoply of different goods rolling off the equivalent of the assembly line, each one sent to its final destination by low-cost, small-scale delivery vehicles like drones or <a href=\"https://www.austinvernon.site/blog/ailogistics.html\">Austin Vernon&#8217;s pallet EVs</a>. Customers could spin up production on this rented equipment and start producing whatever they wanted without having to build their own factory. These sorts of operations wouldn&#8217;t displace traditional mass-production style processes (which will still have a substantial cost advantage), but would exist alongside them.</p><p>(You probably don&#8217;t even need to completely automate the hardware side, so long as you have a sufficiently intelligent control layer. Uber&#8217;s mapping software can direct a driver to where they need to go, leaving the driver to actually turn the wheel and work the controls. Amazon has similar software that tells its distribution center workers where to pick up and bring packages. So you can imagine humans acting as much of the &#8220;connective tissue&#8221; in this sort of production process, being directed by software telling them where to go and what to do to maximize utilization.)</p><h4>AWS for everything</h4><p>You can see the seeds of this &#8220;AWS for everything&#8221; concept in some businesses that exist today. In manufacturing there are fabricators that specialize in high-mix production like <a href=\"https://sendcutsend.com/\">SendCutSend</a>, <a href=\"https://www.oshcut.com/\">OSH Cut</a>, or <a href=\"https://jlcpcb.com/\">JLCPCB</a>. You send your part design to SendCutSend: their software automatically checks to see if it can be fabricated using their equipment (laser cutters, CNC machines, etc.), and they send you back the part a few days later. According to SendCutSend&#8217;s founder Jim Belosic, this model only works because of economies of scale, being able to efficiently spread the costs of their <a href=\"https://www.nnbw.com/news/2026/jan/28/rise-grow-expand-sendcutsend-meteoric-rise-continues-with-100-million-revenue-milestone/#:~:text=Rise%E2%80%A6,e-Edition\">millions of dollars of equipment</a>. As he said on <a href=\"https://www.toolordie.com/p/sendcutsends-jim-belosic-might-have\">Tool or Die</a>:</p><blockquote><p><em>The key with high mix is that it actually works at scale. The larger volume of high mix, the easier things get...Especially with sheet cutting. With sheet cutting, the software side of us, it allows us to take hundreds of different customers, with a quantity of one part each, and put them onto a sheet, like tetris, nested all together, and run it all at once. So we only do one setup, for potentially dozens or hundreds of customers, we do one load into the machine, we only retrieve the material once. And we have really good sheet utilization, we have almost no scrap. It&#8217;s probably one of the lowest in the industry.</em></p><p><em>It doesn&#8217;t work though, when you only do a few. If I was to run one of those customers at a time, we&#8217;d be bankrupt.</em></p></blockquote><p>SendCutSend has grown rapidly &#8212; founded in 2018, they recently passed <a href=\"https://www.nnbw.com/news/2026/jan/28/rise-grow-expand-sendcutsend-meteoric-rise-continues-with-100-million-revenue-milestone/#:~:text=Rise%E2%80%A6,e-Edition\">$100 million in annual revenue </a>&#8212; but they still work hard to maintain flexibility, using equipment that doesn&#8217;t require months of downtime to reprogram or configure when processes change. They&#8217;re also expanding their offerings. They started with laser cutting, later added CNC machining, and <a href=\"https://sendcutsend.com/services/welding/\">now offer welding</a> of single parts. They&#8217;ve also gradually expanded the range of materials that they offer. You can imagine that as automation gets better and better, this sort of business model could continue to be extended, going to multi-part welding, assembly, and eventually entirely finished goods.</p><p>And it&#8217;s not just manufacturing where this sort of production model might emerge. I was inspired to write this essay after reading a really great <a href=\"https://www.owlposting.com/p/heuristics-for-lab-robotics-and-where\">essay about lab automation</a> at Owl Posting, speculating that various lab automation startups might converge on being &#8220;AWS for biotech&#8221;: large, automated labs that can spread the costs of their automation over a large number of experiments run for different customers. Right now much of this sort of lab work isn&#8217;t automated, not because it&#8217;s not possible to automate but because it&#8217;s not repeated enough to be worth it in any particular lab. Centralize all those experiments in one place, and maybe that changes:</p><blockquote><p><em>If you are to accept that lab centralization (as in, cloud labs) means you can most efficiently use lab robotics&#8212;which feels like a pretty uncontroversial argument&#8212;it </em>also<em> means that the further you lean into this, <strong>the more able you are to vertically integrate upstream</strong>. If you&#8217;re running enough experiments such that your robots are constantly humming, you can justify producing your own reagents. If you&#8217;re producing your own reagents, your per-experiment costs drop. If your per-experiment costs drop, you can offer lower prices. If you offer lower prices, you attract more demand. If you attract more demand, your robots stay even busier. If your robots stay even busier, you can justify producing even more of your own inputs. And so on, ad infinitum, until you devour the entirety of the market, and the game of biology becomes extraordinarily cheap and easy for everyone to play in.</em></p></blockquote><p>I&#8217;m not a scientist, but I can imagine how this sort of model could apply to other areas of scientific research as well &#8212; chemistry, materials research, etc.</p><p>How far could this model be pushed? I opened this essay talking about car repair, which has risen in cost far faster than the actual production of cars. I&#8217;ve been in car accidents where the damage was relatively minor, but that nevertheless cost a large fraction of the entire value of the car to repair, due to the un-optimized, un-automated, labor-intensive repair process. Could we have some sort of large, centralized car repair facility, spreading the cost of its automated equipment (heavy industrial robot arms, lifts, welding robots, perhaps even metal fabrication equipment) across a huge number of repaired cars?</p><p>It&#8217;s not obvious to me whether this would work for car repair. Whether &#8220;AWS for everything&#8221; will work in a given industry will depend on the specifics of that industry, the costs and capabilities of the equipment available, and what scaling effects look like. If equipment is relatively inexpensive, and there aren&#8217;t substantial economies of scale at work, I wouldn&#8217;t expect this sort of production arrangement to necessarily make sense. A few years ago people were very enthusiastic about this sort of model for cooking, with &#8220;ghost kitchens:&#8221; commercial kitchens without any sort of dine-in option, preparing food for delivery-only restaurants. Some of the supposed advantage of ghost kitchens was that they required much smaller amounts of space that could be located outside of expensive, high-traffic areas (since you didn&#8217;t need any sort of dine-in option). But ghost kitchens were also <a href=\"https://cloudkitchens.com/blog/ghost-kitchen-as-central-production-use-cases/\">expected</a> to have <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC8808137/\">economies of scale</a>. Multiple different &#8220;restaurants&#8221; could be served from the same facility, possibly taking advantage of batch ingredient prep or high-capacity equipment. But while ghost kitchens are still around, they don&#8217;t seem to have been the <a href=\"https://www.cnn.com/2023/12/05/business/ghost-kitchens-were-supposed-to-be-the-future-of-fast-food-theyre-flaming-out\">enormous success</a> they were originally predicted to be. (Possibly this will change if food prep automation gets much better, but that&#8217;d be somewhat surprising to me.)</p><p>So for many industries the &#8220;AWS for everything&#8221; model won&#8217;t work. But I nevertheless think there&#8217;s a good chance that certain kinds of production &#8212; manufacturing, certain sorts of scientific research, other capital-intensive services &#8212; will be organized this way in the future.</p><p><em>Thanks to Austin Vernon for reading a draft of this. All errors are my own.</em></p>",
    "description": "A theme running through my book is the idea that efficiency improvements, and the various methods for making products cheaper over time, have historically been dependent on some degree of repetition, on running your production process over and over again.",
    "is_fulltext": true,
    "source": "Construction Physics",
    "pub_date": "Thu, 19 Feb 2026 13:01:06 GMT",
    "fetched_at": "2026-02-20T00:36:18.540259",
    "url_hash": "9afb22ff6f3055037cf333001504ac3b"
  }
]