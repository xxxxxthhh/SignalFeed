[
  {
    "title": "Ladybird adopts Rust, with help from AI",
    "link": "https://simonwillison.net/2026/Feb/23/ladybird-adopts-rust/#atom-everything",
    "content": "\n    \n<p><strong><a href=\"https://ladybird.org/posts/adopting-rust/\">Ladybird adopts Rust, with help from AI</a></strong></p>\nReally interesting case-study from Andreas Kling on advanced, sophisticated use of coding agents for ambitious coding projects with critical code. After a few years hoping Swift's platform support outside of the Apple ecosystem would mature they switched tracks to Rust their memory-safe language of choice, starting with an AI-assisted port of a critical library:</p>\n<blockquote>\n<p>Our first target was <strong>LibJS</strong> , Ladybird's JavaScript engine. The lexer, parser, AST, and bytecode generator are relatively self-contained and have extensive test coverage through <a href=\"https://github.com/tc39/test262\">test262</a>, which made them a natural starting point.</p>\n<p>I used <a href=\"https://docs.anthropic.com/en/docs/claude-code\">Claude Code</a> and <a href=\"https://openai.com/codex/\">Codex</a> for the translation. This was human-directed, not autonomous code generation. I decided what to port, in what order, and what the Rust code should look like. It was hundreds of small prompts, steering the agents where things needed to go. [...]</p>\n<p>The requirement from the start was byte-for-byte identical output from both pipelines. The result was about 25,000 lines of Rust, and the entire port took about two weeks. The same work would have taken me multiple months to do by hand. We’ve verified that every AST produced by the Rust parser is identical to the C++ one, and all bytecode generated by the Rust compiler is identical to the C++ compiler’s output. Zero regressions across the board.</p>\n</blockquote>\n<p>Having an existing conformance testing suite of the quality of <code>test262</code> is a huge unlock for projects of this magnitude, and the ability to compare output with an existing trusted implementation makes agentic engineering much more of a safe bet.\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=47120899\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/browsers\">browsers</a>, <a href=\"https://simonwillison.net/tags/javascript\">javascript</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/rust\">rust</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/andreas-kling\">andreas-kling</a>, <a href=\"https://simonwillison.net/tags/ladybird\">ladybird</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/conformance-suites\">conformance-suites</a>, <a href=\"https://simonwillison.net/tags/agentic-engineering\">agentic-engineering</a></p>\n\n\n\n",
    "description": "Ladybird adopts Rust, with help from AI Really interesting case-study from Andreas Kling on advanced, sophisticated use of coding agents for ambitious coding projects with critical code. After a few years hoping Swift's platform support outside of the Apple ecosystem would mature they switched tracks to Rust their memory-safe language of choice, starting with an AI-assisted port of a critical library: Our first target was LibJS , Ladybird's JavaScript engine. The lexer, parser, AST, and bytecode",
    "is_fulltext": true,
    "source": "Simon Willison's Weblog",
    "pub_date": "2026-02-23T18:52:53+00:00",
    "fetched_at": "2026-02-24T00:35:57.700275",
    "url_hash": "b70ab0e5f683c86e9d8d90ad1f77dc83"
  },
  {
    "title": "The Pants-Shitting Saga of Resizing Windows on MacOS 26 Tahoe Continues",
    "link": "https://noheger.at/blog/2026/02/12/resizing-windows-on-macos-tahoe-the-saga-continues/",
    "content": "\n<p>Norbert Heger:</p>\n\n<blockquote>\n  <p>In the release notes for macOS 26.3 RC, Apple stated that the\nwindow-resizing issue I demonstrated in <a href=\"https://noheger.at/blog/2026/01/11/the-struggle-of-resizing-windows-on-macos-tahoe/\">my recent blog\npost</a> had been resolved.</p>\n</blockquote>\n\n<p>You’ll never guess what happened between the RC (release candidate) version and the actual shipping version of 26.3.</p>\n\n<p>Just kidding, you’ll guess.</p>\n\n<div>\n<a  title=\"Permanent link to ‘The Pants-Shitting Saga of Resizing Windows on MacOS 26 Tahoe Continues’\"  href=\"https://daringfireball.net/linked/2026/02/23/norbert-heger-resizing-saga\">&nbsp;★&nbsp;</a>\n</div>\n\n\t",
    "description": "",
    "is_fulltext": true,
    "source": "Daring Fireball",
    "pub_date": "2026-02-24T00:31:00Z",
    "fetched_at": "2026-02-24T00:36:00.058478",
    "url_hash": "00f75cc6040b4d24c95505712bbe1508"
  },
  {
    "title": "Book Review: A Geography of Time by Robert V. Levine ★★★☆☆",
    "link": "https://shkspr.mobi/blog/2026/02/book-review-a-geography-of-time-by-robert-v-levine/",
    "content": "<img src=\"https://shkspr.mobi/blog/wp-content/uploads/2026/02/61P798qHnjL._SL600_.jpg\" alt=\"Book cover featuring distorted clocks hovering over the Earth.\" width=\"250\" class=\"alignleft size-full wp-image-66436\">\n\n<p>This book doesn't know what it wants to be. Is it a sociology textbook, travel guide, history book, or guide to the mysteries of the world? Subtitled \"the temporal misadventures of a social psychologist\" it veers between hard data and well-worn anecdotes until it becomes a sort of self-help book for the time-poor 1990s American executive.</p>\n\n<p>Despite being well-caveated against the \"dangers in making generalization about the characteristics of places\" and the dangers of stereotyping, it does do a <em>lot</em> of both! There's an unhealthy obsession with then en-vogue <a href=\"https://en.wikipedia.org/wiki/Type_A_and_Type_B_personality_theory\">Type A Personality Type</a> and a little bit of over-reliance on anecdotes and just-so stories. Yet, at the same time, the data kind of bears that out. Certain countries and communities <em>do</em> have different concepts of time and this leads to markedly different behaviour.</p>\n\n<p>It doesn't quite go down the <a href=\"https://shkspr.mobi/blog/2022/11/book-review-the-language-hoax-john-h-mcwhorter/\">Sapir–Whorf</a> path - but there's certainly <em>something</em> about the way cultures refer to chronological concepts which shapes how prompt they are to appointments!</p>\n\n<p>The data are fairly brief and presented only in tabular form. I assume, much like Hawking, they were told data and graphs turn away casual readers. The book is extensively referenced, although there's not much about reproducibility of either their or others' data. It is stuffed with great quotes about the nature of time and how technological developments have wreaked havoc on otherwise idyllic communities. Some of the history stuff is revelatory.</p>\n\n<p>While it does span the world, the book orbits the twin loci of American and its then-archrival Japan. The Japanese economic miracle was in full swing when this book was written and there's some hand-wringing about whether Japanese concepts of time are incommensurate with Western (read American) notions of productivity.</p>\n\n<p>The end section contains eight lessons which can be applied by anyone who is changing country and culture - they're designed to help you mesh with your new community as you adapt to their rhythm of life.</p>\n\n<p>If you're happy with a meandering philosophical <i lang=\"sv\">Smörgåsbord</i> of ideas, this has plenty to keep you interested. I'm sure it is rather dated now, but it is fascinating to see exactly what value people around the world place on time.</p>\n",
    "description": "This book doesn&#039;t know what it wants to be. Is it a sociology textbook, travel guide, history book, or guide to the mysteries of the world? Subtitled &#34;the temporal misadventures of a social psychologist&#34; it veers between hard data and well-worn anecdotes until it becomes a sort of self-help book for the time-poor 1990s American executive. Despite being well-caveated against the &#34;dangers in…",
    "is_fulltext": true,
    "source": "Terence Eden’s Blog",
    "pub_date": "Mon, 23 Feb 2026 12:34:07 +0000",
    "fetched_at": "2026-02-24T00:36:08.412431",
    "url_hash": "a534b35518e5b6af177b7fd4a32b6502"
  },
  {
    "title": "PDUs can fail (eventually) and some things related to this",
    "link": "https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PDUsCanFailEventually",
    "content": "<div class=\"wikitext\"><p>Early last Tuesday <a href=\"https://mastodon.social/@cks/116084506995715846\">there was a widespread power outage at work</a>, which took out\npower to our machine rooms for about four hours. Most things came\nback up when the power was restored, but not everything. One of the\nthings that had happened was that one of our <a href=\"https://en.wikipedia.org/wiki/Power_distribution_unit\">rack PDUs</a> had failed.\nFixing this took a surprising amount of work.</p>\n\n<p>We don't normally think about our PDUs very much. They sit there,\nacting as larger and often smarter versions of power bars, and just,\nwell, work. But both power bars and PDUs can fail eventually, and\nin our environment rack PDUs tend to last long enough to reach that\npoint. We may replace servers in the racks in our machine rooms,\nbut we don't pull out and replace entire racks all that often. The\nresult is that a rack's initial PDU is likely to stay in the rack\nuntil it fails.</p>\n\n<p>(This isn't universal; there are plenty of places that install and\nremove entire racks at a time. If you're turning over an entire\nrack, you might replace the PDU at the same time you're replacing\nall of the rest of it. Whole rack replacement is certainly going\nto keep your wiring neater.)</p>\n\n<p>A rack PDU failing not a great thing for the obvious reason; it's\ngoing to take out much or all of the servers in the rack unless you\nhave dual power supplies on your servers, each connected to a\nseparate PDU. For racks that have been there for a while and gone\nthrough a bunch of changes, often it will turn out to be hard to\nremove and replace the PDU. Maintaining access to remove PDUs is\noften not a priority either in placing racks in your machine room\nor in wiring things up, so it's easy for things to get awkward and\nencrusted. This was one of the things that happened with our failed\nPDU on last Tuesday; it took quite some work to extract and replace\nit.</p>\n\n<p>(Some people might have pre-deployed spare PDUs in each rack, but\nwe don't. And if those spare PDUs are already connected to power\nand turned on, they too can fail over time.)</p>\n\n<p>We're fortunate that we already had spare (smart) PDUs on hand, and\nwe had also pre-configured a couple of them for emergency replacements.\nIf we'd had to order a replacement PDU, things would obviously have\nbeen more of a problem. There are probably some research groups\naround <a href=\"https://support.cs.toronto.edu/\">here</a> with their own racks\nwho don't have a spare PDU, because it's an extra chunk of money\nfor an unlikely or uncommon contingency, and they might choose to\naccept a rack being down for a while.</p>\n</div>\n",
    "description": "",
    "is_fulltext": true,
    "source": "Chris's Wiki :: blog",
    "pub_date": "2026-02-22T23:24:38Z",
    "fetched_at": "2026-02-24T00:36:11.354377",
    "url_hash": "0206a0c0be7a203e9d2286457970ef2b"
  },
  {
    "title": "Portable monitors are good",
    "link": "https://xeiaso.net/blog/2026/portable-monitors-are-good/",
    "content": "\n        <p>My job has me travel a lot. When I'm in my office I normally have a seven monitor battlestation like this:</p>\n        <center><blockquote class=\"bluesky-embed\" data-bluesky-uri=\"at://did:plc:e5nncb3dr5thdkjir5cfaqfe/app.bsky.feed.post/3mdefsnld4s2t\" data-bluesky-cid=\"bafyreifd4mdsbrgk3dgyuwjrgdweqkj2yaol4bqixddewog2og7pzs3ske\" data-bluesky-embed-color-mode=\"system\"><p lang=\"en\"><br/><br/><a href=\"https://bsky.app/profile/did:plc:e5nncb3dr5thdkjir5cfaqfe/post/3mdefsnld4s2t?ref_src=embed\"><p>[image or embed]</p></a></p><p>— Xe (</p><a href=\"https://bsky.app/profile/did:plc:e5nncb3dr5thdkjir5cfaqfe?ref_src=embed\"><p>@xeiaso.net</p></a><p>) </p><a href=\"https://bsky.app/profile/did:plc:e5nncb3dr5thdkjir5cfaqfe/post/3mdefsnld4s2t?ref_src=embed\"><p>January 26, 2026 at 11:34 PM</p></a></blockquote><script async src=\"https://embed.bsky.app/static/embed.js\" charset=\"utf-8\"></script></center>\n        <p>So as you can imagine, travel sucks for me because I just constantly run out of screen space. This can be worked around, I minimize things more, I just close them, but you know what is better? Just having another screen.</p>\n        <p>On a whim, I picked up <a href=\"https://www.amazon.ca/dp/B0B2PJNG8D?ref=ppx_yo2ov_dt_b_fed_asin_title\">this 15.6&quot; Innoview portable monitor</a> off of Amazon. It's a 1080p screen that I hook up to my laptop or Steam Deck with USB-C. However, the exact brand and model doesn't matter. You can find them basically anywhere with the most AliExpress term ever: screen extender.</p>\n        <figure class=\"max-w-3xl mx-auto not-prose w-full undefined\"><a href=\"https://files.xeiaso.net/blog/2026/portable-monitors/IMG_0749.jpg\"><picture><source type=\"image/avif\" srcset=\"https://files.xeiaso.net/blog/2026/portable-monitors/IMG_0749.avif\"/><source type=\"image/webp\" srcset=\"https://files.xeiaso.net/blog/2026/portable-monitors/IMG_0749.webp\"/><img loading=\"lazy\" src=\"https://files.xeiaso.net/blog/2026/portable-monitors/IMG_0749.jpg\"/></picture></a></figure>\n        <p>This monitor is at least half decent. It is not a colour-accurate slice of perfection. It claims to support HDR but actually doesn't. Its brightness out of the box could be better. I could go down the list and really nitpick until the cows come home but it really really doesn't matter. It's portable, 1080p, and good enough.</p>\n        <p>When I was at a coworking space recently, it proved to be one of the best purchases I've ever made. I had Slack off to the side and was able to just use my computer normally. It was so boring that I have difficulty trying to explain how much I liked it.</p>\n        <p>This is the dream when it comes to technology.</p>\n        <p>3/5, I would buy a second one.</p>\n      ",
    "description": "A review of portable monitors for travel",
    "is_fulltext": true,
    "source": "Xe Iaso's blog",
    "pub_date": "Tue, 24 Feb 2026 00:00:00 GMT",
    "fetched_at": "2026-02-24T00:36:12.197792",
    "url_hash": "c086831c7aeacd81f48eb2e52874ccba"
  },
  {
    "title": "Customizing the ways the dialog manager dismisses itself: Detecting the ESC key, second (failed) attempt",
    "link": "https://devblogs.microsoft.com/oldnewthing/20260223-00/?p=112080",
    "content": "<p>Last time, we saw that <a title=\"Customizing the ways the dialog manager dismisses itself: Detecting the ESC key, first (failed) attempt\" href=\"https://devblogs.microsoft.com/oldnewthing/20260220-00/?p=112074\"> <code>Get­Async­Key­State</code> is not the way to detect whether the <kbd>ESC</kbd> key was down at the time the current input message was generated</a>. But what about if we switched to <code>Get­Key­State</code>? Would that allow us to distinguish between an <code>IDCANCEL</code> caused by the <kbd>ESC</kbd> and an <code>IDCANCEL</code> that come from the Close button?</p>\n<p>It helps, in that it tells you whether the <kbd>ESC</kbd> key was down when the event occurred, but just because the <kbd>ESC</kbd> is down doesn&#8217;t mean that the <kbd>ESC</kbd> key is why you got the message.</p>\n<p>For example, suppose your policy is to simply ignore the <kbd>ESC</kbd> key, but to close the dialog if the user clicks the Close button. If the user holds the <kbd>ESC</kbd> key and clicks the Close button, the initial press of the <kbd>ESC</kbd> will generate an <code>IDCANCEL</code>, and your call to <code>Get­Key­State</code> will report that the <kbd>ESC</kbd> is down, so you will ignore the message.</p>\n<p>And then the next <code>IDCANCEL</code> comes in due to the Close button, and your call to <code>Get­Key­State</code> will correctly report &#8220;The <kbd>ESC</kbd> key is still down.&#8221; So your function says, &#8220;Oh, this came from the <kbd>ESC</kbd> key, so ignore it.&#8221;</p>\n<p>Except that it didn&#8217;t come from the <kbd>ESC</kbd> key. It came from the Close button. It just so happens that the <kbd>ESC</kbd> is down, but that&#8217;s not the reason why you got the second <code>IDCANCEL</code>.</p>\n<p>Suppose you have a kiosk in a room with two entrances, a back entrance and a front entrance. If someone enters from the front door, you want to call the receptionist, but you don&#8217;t want to do it if they enter from the back door. What we&#8217;re doing by checking the <kbd>ESC</kbd> key is saying, &#8220;If the back door is open, then don&#8217;t call the receptionist.&#8221; But it&#8217;s possible that somebody is just standing in the back doorway, holding the door open, and during that time, somebody comes in the front door. Your logic sees that the back door is open and suppresses the call to the receptionist because you had assumed that only one door can be open at a time.</p>\n<p>Next time, we&#8217;ll look at distinguishing <kbd>ESC</kbd> from Close.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/oldnewthing/20260223-00/?p=112080\">Customizing the ways the dialog manager dismisses itself: Detecting the ESC key, second (failed) attempt</a> appeared first on <a href=\"https://devblogs.microsoft.com/oldnewthing\">The Old New Thing</a>.</p>\n",
    "description": "Sniffing the synchronous keyboard state is still not precise enough. The post Customizing the ways the dialog manager dismisses itself: Detecting the ESC key, second (failed) attempt appeared first on The Old New Thing.",
    "is_fulltext": true,
    "source": "The Old New Thing",
    "pub_date": "Mon, 23 Feb 2026 15:00:00 +0000",
    "fetched_at": "2026-02-24T00:36:12.823769",
    "url_hash": "08fd6270a877a0eb2825e70f00d7e4a8"
  },
  {
    "title": "Giant Steps",
    "link": "https://www.johndcook.com/blog/2026/02/23/giant-steps/",
    "content": "<p>John Coltrane&#8217;s song Giant Steps is known for its unusual and difficult chord changes. Although the chord progressions are complicated, there aren&#8217;t that many unique chords, only nine. And there is a simple pattern to the chords; the difficulty comes from the giant steps between the chords.</p>\n<p><img fetchpriority=\"high\" decoding=\"async\" class=\"aligncenter size-medium\" src=\"https://www.johndcook.com/giant_steps.png\" alt=\"Giant Steps chords\" width=\"600\" height=\"600\" /></p>\n<p>If you wrap the chromatic scale around a circle like a clock, there is a three-fold symmetry. There is only one type of chord for each root, and the three notes not represented are evenly spaced. And the pattern of the chord types going around the circle is</p>\n<p style=\"padding-left: 40px;\">minor 7th, dominant 7th, major 7th, skip<br />\nminor 7th, dominant 7th, major 7th, skip<br />\nminor 7th, dominant 7th, major 7th, skip</p>\n<p>To be clear, this is not the order of the chords in Giant Steps. It&#8217;s the order of the sorted list of chords.</p>\n<p>For more details see the video <a href=\"https://www.youtube.com/watch?v=2DM4PfvxogM\">The simplest song that nobody can play</a>.</p>\n<h2>Related posts</h2>\n<ul>\n<li class=\"link\"><a href=\"https://www.johndcook.com/blog/2011/11/19/nunc-dimittis/\">Nunc dimittis</a></li>\n<li class=\"link\"><a href=\"https://www.johndcook.com/blog/2023/07/26/jaccard-jazz/\">Jaccard index and jazz albums</a></li>\n<li class=\"link\"><a href=\"https://www.johndcook.com/blog/2024/02/28/the-real-book/\">The Real Book</a></li>\n</ul>The post <a href=\"https://www.johndcook.com/blog/2026/02/23/giant-steps/\">Giant Steps</a> first appeared on <a href=\"https://www.johndcook.com/blog\">John D. Cook</a>.",
    "description": "John Coltrane&#8217;s song Giant Steps is known for its unusual and difficult chord changes. Although the chord progressions are complicated, there aren&#8217;t that many unique chords, only nine. And there is a simple pattern to the chords; the difficulty comes from the giant steps between the chords. If you wrap the chromatic scale around a [&#8230;] The post Giant Steps first appeared on John D. Cook.",
    "is_fulltext": true,
    "source": "John D. Cook",
    "pub_date": "Mon, 23 Feb 2026 19:20:23 +0000",
    "fetched_at": "2026-02-24T00:36:27.856454",
    "url_hash": "25c9e09dce146e006937c798d7d7f2d3"
  },
  {
    "title": "Thoughts on Farcaster",
    "link": "https://www.joanwestenberg.com/thoughts-on-farcaster/",
    "content": "<img src=\"https://www.joanwestenberg.com/content/images/2026/02/ChatGPT-Image-Feb-24--2026--09_00_57-AM.png\" alt=\"Thoughts on Farcaster\"><p>For the past few weeks I&apos;ve been asking myself why I&apos;m still on Farcaster, whether I&apos;ll stay, whether I even want to.</p><p>I&apos;ve landed on some answers.</p><p>Farcaster, for the uninitiated, was the most credible attempt anyone has made at building a decentralized, crypto-based social network that people actually wanted to use. Founded in 2020 by Dan Romero and Varun Srinivasan, both ex-Coinbase, and backed by $180 million from Andreessen Horowitz, Paradigm, and Union Square Ventures, Farcaster set out to prove that crypto could build something worth using beyond speculation and exit liquidity and the endless recursive loop of tokens that exist to fund the creation of more tokens. It was going to be the social network you actually owned, where your identity and your social graph belonged to you in some meaningful sense, where no single corporate entity could rug-pull your entire online life the way Elon Musk had done to Twitter&apos;s culture or Mark Zuckerberg had done to everyone else.</p><p>And for a while, it worked. Vitalik Buterin posted there. Developers built interesting things on the protocol; Frames, for instance, let you embed interactive applications directly into posts. The Farcaster team shipped a working decentralized protocol that multiple independent teams could build on without permission. Most crypto projects never come close to that kind of technical achievement. And the vibe was good! If you squinted, you could see the outline of what a post-platform internet might look like: open protocols and communities forming around shared creation rather than algorithmic optimization.</p><p>And then 2025 happened.</p><h2 id=\"after-the-crash\">After the crash</h2><p>In December 2025, Dan Romero announced that social-first hadn&apos;t worked.</p><p>Farcaster pivoted to wallets and trading. The thesis was &quot;come for the tool, stay for the network,&quot; an honest attempt to find the growth mechanic that the social layer alone hadn&apos;t provided. The wallet had been performing well, and Romero called it &quot;the closest we&apos;ve been to product-market fit in five years.&quot; You can argue with the direction, but I don&apos;t know that you can argue with a founder who spent half a decade on one approach, acknowleged it wasn&apos;t working, and tried something else instead of pumping a token and heading for the exits.</p><p>I&apos;d call this integrity by crypto standards and, frankly, by most standards.</p><p>In January 2026, Neynar, the infrastructure company that already powered most of Farcaster&apos;s ecosystem, acquired the whole thing. Protocol contracts, code repositories, the app, Clanker, all of it. Romero and Srinivasan stepped back // away.</p><p>The handoff makes sense. Neynar had been Farcaster&apos;s backbone since 2021, serving over a thousand customers. If anyone understood the ecosystem&apos;s plumbing, they did. But it also meant the social network now had a new steward, and regardless of how well-intentioned that steward might be, an era had come to an end and the structural reality had shifted.</p><p>All of this happened against the backdrop of crypto&apos;s broader 2025 reckoning. The memecoin market cap collapsed from $150.6 billion in December 2024 to $39.4 billion by November 2025. The TRUMP token, launched three days before the inauguration with the subtlety of a carnival barker, cratered over 90% from its $75 peak. The LIBRA token, shilled by Argentine President Javier Milei on Valentine&apos;s Day, vaporized $4.5 billion and took 86% of its investors&apos; money with it. Over 11.5 million crypto tokens died in 2025, most of them memecoins, most of them launched with no roadmap and no team, with no purpose beyond being the next thing someone could pump before dumping. The October crash wiped $19 billion in leveraged positions in a single event. The Fear &amp; Greed Index, which had read &quot;extreme greed&quot; in September, plummeted to levels that suggested the market had collectively remembered that gravity exists...</p><p>If you were looking for a narrative about crypto fulfilling its original promise of financial sovereignty and a more equitable internet, 2025 was a punishing year.</p><p>I believe Romero and Srinivasan gave Farcaster everything they had to give. I believe they cared // gave a shit // tried. They spent five years building real infrastructure and shipping real products. They cultivated a community. They weren&apos;t exit-scamming or pumping a token. They were doing the boring // unglamorous work of trying to make decentralized social media function at scale, and they ran into the hard problem that it might not be possible.</p><h2 id=\"loyalty-on-a-sinking-ship\">Loyalty on a sinking ship</h2><p>Platform loyalty during a platform&apos;s decline starts to feel religious. You&apos;re maintaining faith in something when the material conditions no longer support that faith. You&apos;re posting into a feed that&apos;s getting quieter. You&apos;re engaging with a community that&apos;s growing smaller. The people who remain on a platform in decline (let&apos;s be blunt about this) are, by definition, the people who didn&apos;t leave, and that group is filtered for stubbornness, ideological commitment, sunk-cost fallacy, or some combinaton of all three.</p><p>I know this pattern. We&apos;ve all lived through it. LiveJournal. Google+. Vine. Tumblr&apos;s long twilight after the porn ban. Each one had its diaspora moment, the point where the population crossed some invisible threshold and the network effects reversed. Instead of each new user making the platform more valuable, each departing user made it less valuable, and the departure curve steepened. Robert Metcalfe&apos;s law, which tells us a network&apos;s value scales with the square of its users, works in both directions. The math is merciless on the way down.</p><p>You can map this against Albert Hirschman&apos;s framework from Exit, Voice, and Loyalty. When an organization declines, members can exit (leave), exercise voice (complain and try to fix things), or remain loyal (stay and hope). The internet has made exit nearly frictionless (you can sign up for Bluesky in ninety seconds) and voice nearly useless, because platforms at scale have no meaningful feedback mechanism between users and decision-makers. What&apos;s left is loyalty, and loyalty without either exit costs or voice mechanisms is inertia.</p><p>In Italo Calvino&apos;s Invisible Cities, Marco Polo describes a city called Fedora. In the city&apos;s museum, there are glass globes containing miniature models of the city, each one representing a version of Fedora that was imagined but never built, all the possible Fedoras that could have existed but didn&apos;t. The citizens spend their time gazing at these alternatives, at the roads not taken, the architectures never constructed. Farcaster sometimes feels like one of Calvino&apos;s globes: a beautiful model of what decentralized social could have been, preserved in amber, admired by a shrinking group of people who remember what it was supposed to become.</p><h2 id=\"why-i-havent-left\">Why I haven&apos;t left</h2><p>...And yet?</p><p>And yet.</p><p>I still haven&apos;t left.</p><p>I wish I had a clean, satisfying reason; something about decentralization principles or the irreducible value of owning your own social graph.</p><p>And those things do matter. But the real // honest answer is messier.</p><p>Partly it&apos;s that the alternatives are all terrible in their own specific ways. X under Musk has become, as Vitalik Buterin put it, &quot;a death star laser for coordinated hate sessions.&quot; Bluesky absorbed the X refugees and immediately began replicating the dynamics that made X miserable. Threads is Instagram&apos;s vestigial social limb. Mastodon remains Mastodon, which is to say: technically impressive and culturally impenetrable, governed by norms that make posting feel like filing a planning application with the local council.</p><p>Partly it&apos;s that Farcaster, even in its diminished state, retains something I haven&apos;t found elsewhere. The community that remains is small, but it&apos;s weighted toward people who build things and people who think carefully about what they&apos;re building. The feed isn&apos;t optimized for engagement, nobody&apos;s trying to go viral, and the conversations that happen there have a texture I associate with early internet forums (in a good way.)</p><p>And partly it&apos;s that leaving would feel like conceding a point I&apos;m not yet ready to concede.</p><h2 id=\"cryptos-broken-promise\">Crypto&apos;s broken promise</h2><p>The irony of crypto&apos;s 2025 collapse is that the technology worked. The Ethereum network processes transactions reliably. Layer 2 solutions have made fees manageable. Smart contracts execute as written. The decentralized exchange infrastructure handles billions in volume. The pipes do what pipes are supposed to do. What failed was the civilization we were supposed to build on top of them. What failed was...well, us.</p><p>The crypto pitch I actually gave a shit about (predating the NFT boom and the memecoin casino and the $75 presidential tokens) was infrastructure - building systems that couldn&apos;t be captured by any single actor, where the rules were encoded in mathematics rather than terms of service, and where your relationship to a platform couldn&apos;t reasonably be compared to serfdom.</p><p>That pitch had its origins in the cypherpunks of the 1990s, from Timothy May&apos;s &quot;Crypto Anarchist Manifesto&quot; and Eric Hughes&apos;s &quot;A Cypherpunk&apos;s Manifesto,&quot; documents that imagined cryptography as a tool for individual sovereignty in an age of institutional surveillance. The cypherpunks weren&apos;t utopians, exactly. They were pragmatists who understood that privacy and autonomy wouldn&apos;t be granted by institutions, that they&apos;d have to be built, technically, from the ground up.</p><p>Incentives pulled that vision apart. The same cryptographic tools that could enable sovereign identity and censorship-resistant communication enabled speculation at speed and scale. And speculation is both more &quot;fun&quot; than infrastructure and a good deal more viral. It certainly generates better fees, which is why pump.fun, the platform that enabled the creation of thousands of doomed memecoins, remained one of crypto&apos;s most profitable companies throughout 2025 even as the tokens it birthed collectivley lost billions in value.</p><p>When a technology designed to resist capture becomes the basis for financial instruments, the financial instruments capture the technology. The tail wags the dog. The protocol exists to serve the token, not the other way around. And the people building on the protocol start optimizing for token price rather than for the thing the protocol was supposed to enable.</p><p>Farcaster wasn&apos;t immune to this gravitational pull. The acquisition of Clanker, the AI token launchpad, in October 2025 signaled a shift in orientation. By the time Romero announced the wallet pivot in December, the trajectory was clear: the social network would become the social layer of a financial product, which is a very different thing than being a social network that happens to use crypto rails. You can respect the pragmatism of that decision (Romero and his team were responding to real data about what users actually wanted) and still mourn the original vision.</p><h2 id=\"a-working-hypothesis\">A working hypothesis</h2><p>I cared about Farcaster for the community that decentralization attracted. But decentralization is a means, and means are only as good as the ends they serve. The protocol is the plumbing, and plumbing matters, but nobody moves into a house because the pipes are well-laid.</p><p>What Farcaster offered, at its best, was a social environment shaped by a belief in decentralization, a community that self-selected for people who cared about how their tools were built and who controlled them. The protocol was an attractor for a certain kind of person, and that kind of person created a certain kind of conversation, and that conversation was the actual product, regardless of what the cap table said.</p><p>This is the distinction: decentralization as architecture and decentralization as culture. The architecture has shifted; the founders have moved on; the wallet pivot reoriented everything toward trading.</p><p>But the protocol remains open, and the Neynar team has been embedded in the Farcaster ecosystem from the beginning. They understand what they&apos;ve inherited. Whether they&apos;ll preserve it is an open question, but it&apos;s not a foregone conclusion. The culture, the sensibility, the community of people who were drawn to Farcaster because they wanted something different from the engagement-optimized hellscapes of mainstream social media, that&apos;s harder to kill. It migrates and reconstitutes. It finds new vessels.</p><p>In the early twentieth century, the Vienna Circle, a group of philosophers, mathematicians, and scientists, gathered regularly at the University of Vienna to work out the foundations of logical positivism. They believed that meaningful statements had to be empirically verifiable, that metaphysics was nonsense, that philosophy should be brought into line with the methods of science. When the Nazis rose to power, the Circle scattered. Its members fled to the United States, the United Kingdom, New Zealand.</p><p>The institutional vessel broke, but the ideas traveled with the people who carried them.</p><h2 id=\"why-im-still-posting\">Why I&apos;m still posting</h2><p>So this is where I&apos;ve landed.</p><p>I&apos;m still on Farcaster because the people there are still interesting. I&apos;m still there because the conversations still have a quality I can&apos;t reliably find elsewhere. I&apos;m still there because even in its acquired, pivoted, wallet-focused state, the residual community maintains a standard of discourse that I value. And I&apos;m still there because, whatever the business metrics say, Dan and Varun succeeded at something that doesn&apos;t show up on a revenue chart: they attracted and concentrated a community of thoughtful, building-oriented people who care about the internet they&apos;re constructing. That&apos;s worth more than product-market fit, even if you can&apos;t put it on a pitch deck.</p><p>I&apos;ve grown deeply suspicious of the impulse to leave. Every few months, a new wave of platform migration sweeps through the internet, people fleeing X for Bluesky, fleeing Bluesky for Threads, fleeing Threads for Mastodon, fleeing whatever is currently on fire for whatever is currently promising not to be on fire. And these migrations are almost always driven by the same fantasy: that a new platform will fix the problem. The problem is the set of incentives that govern all platforms, the economic logic that turns every online space into either an engagement farm or a ghost town, and changing platforms without changing those incentives is like rearranging deck chairs on the Titanic, except the Titanic is the entire attention economy and the iceberg is the incompatability between advertising revenue and human flourishing.</p><p>What does it actually mean to give a shit about a platform in 2026? I think it means loyalty to the conversations you&apos;re having and the people you&apos;re having them with. The platform is scaffolding. Scaffolding gets removed when the building is done or abandoned, or when someone decides the scaffolding itself is the product and starts charging rent for standing on it.</p><p>And if those conversations and those people happen to be on Farcaster right now, then that&apos;s where I&apos;ll be, until they&apos;re somewhere else, at which point I&apos;ll be somewhere else.</p><p>This is a less inspiring position than &quot;I believe in the decentralized web.&quot;</p><p>But at least it&apos;s honest.</p><p>Neynar might surprise us. Crypto might stop sucking. Farcaster may yet become something none of us predicted, something that Dan and Varun&apos;s original infrastructure enables even if it looks nothing like what they originally imagined.</p><p>The best thing about open protocols is, after all, that they can outlive the intentions of their creators.</p><p>I&apos;ve stopped waiting for a single platform to replace Twitter. The dream I&apos;ve settled on is smaller: pockets of genuine discourse, distributed across protocols and platforms and group chats and mailing lists, connected by people rather than by algorithms, sustained by care rather than by capital. That dream doesn&apos;t need a billion-dollar valuation. It doesn&apos;t need much in the way of product-market fit. It barely requires a protocol.</p><p>It does require, though, that at least a few people keep posting.</p>",
    "description": "For the past few weeks I&apos;ve been asking myself why I&apos;m still on Farcaster, whether I&apos;ll stay, whether I even want to.I&apos;ve landed on some answers.Farcaster, for the uninitiated, was the most credible attempt anyone has made at building a",
    "is_fulltext": true,
    "source": "Westenberg.",
    "pub_date": "Mon, 23 Feb 2026 22:07:22 GMT",
    "fetched_at": "2026-02-24T00:36:33.941859",
    "url_hash": "05b9a6b1761a5a0c8fae8c551048e2bf"
  },
  {
    "title": "New Blog Post: Some Silly Z3 Scripts I Wrote",
    "link": "https://buttondown.com/hillelwayne/archive/new-blog-post-some-silly-z3-scripts-i-wrote/",
    "content": "\n<p>Now that I'm not spending all my time on Logic for Programmers, I have time to update my website again! So here's the first blog post in five months: <a href=\"https://www.hillelwayne.com/post/z3-examples/\" target=\"_blank\">Some Silly Z3 Scripts I Wrote</a>.</p>\n<p>Normally I'd also put a link to the Patreon notes but I've decided I don't like publishing gated content and am going to wind that whole thing down. So some quick notes about this post:</p>\n<ul>\n<li>Part of the point is admittedly to hype up the eventual release of LfP. I want to start marketing the book, but don't want the marketing material to be devoid of interest, so tangentially-related-but-independent blog posts are a good place to start.</li>\n<li>The post discusses the concept of \"chaff\", the enormous quantity of material (both code samples and prose) that didn't make it into the book. The book is about 50,000 words… and considerably shorter than the total volume of chaff! I don't <em>think</em> most of it can be turned into useful public posts, but I'm not entirely opposed to the idea. Maybe some of the old chapters could be made into something?</li>\n<li>Coming up with a conditioned mathematical property to prove was a struggle. I had two candidates: <code>a == b * c =&gt; a / b == c</code>, which would have required a long tangent on how division must be total in Z3, and  <code>a != 0 =&gt; some b: b * a == 1</code>, which would have required introducing a quantifier (SMT is real weird about quantifiers). Division by zero has already caused me enough grief so I went with the latter. This did mean I had to reintroduce \"operations must be total\" when talking about arrays.</li>\n<li>I have no idea why the array example returns <code>2</code> for the max profit and not <code>99999999</code>. I'm guessing there's some short circuiting logic in the optimizer when the problem is ill-defined?</li>\n<li>One example I could not get working, which is unfortunate, was a demonstration of how SMT solvers are undecidable via encoding Goldbach's conjecture as an SMT problem. Anything with multiple nested quantifiers is a pain.</li>\n</ul>\n",
    "description": "Now that I'm not spending all my time on Logic for Programmers, I have time to update my website again! So here's the first blog post in five months: Some Silly Z3 Scripts I Wrote. Normally I'd also put a link to the Patreon notes but I've decided I don't like publishing gated content and am going to wind that whole thing down. So some quick notes about this post: Part of the point is admittedly to hype up the eventual release of LfP. I want to start marketing the book, but don't want the market",
    "is_fulltext": true,
    "source": "Computer Things",
    "pub_date": "Mon, 23 Feb 2026 16:49:10 +0000",
    "fetched_at": "2026-02-24T00:36:41.000990",
    "url_hash": "333651c288645638f461939bdb970cc0"
  },
  {
    "title": "Making Icon Sets Easy With Web Origami",
    "link": "https://blog.jim-nielsen.com/2026/origami-icons/",
    "content": "<p>Over the years, I’ve used different icon sets on my blog. Right now I use <a href=\"https://heroicons.com\" >Heroicons</a>.</p>\n<p><a href=\"https://github.com/tailwindlabs/heroicons\" >The recommended way</a> to use them is to copy/paste the source from the website directly into your HTML. It’s a pretty straightforward process:</p>\n<ul>\n<li>Go to the website</li>\n<li>Search for the icon you want</li>\n<li>Hover it</li>\n<li>Click to “Copy SVG”</li>\n<li>Go back to your IDE and paste it</li>\n</ul>\n<p>If you’re using React or Vue, there are also npm packages you can install so you can import the icons as components.</p>\n<p>But I’m not using either of those frameworks, so I need the raw SVGs and there’s no <code>npm i</code> for those so I have to manually grab the ones I want.</p>\n<p>In the past, my approach has been to copy the SVGs into individual files in my project, like:</p>\n<pre><code>src/\n  icons/\n    home.svg\n    about.svg\n    search.svg\n</code></pre>\n<p>Then I have a “component” for reading those icons from disk which I use in my template files to inline the SVGs in my HTML. For example:</p>\n<pre><code class=\"language language-js\"><span class=\"hljs-comment\">// Some page template file</span>\n<span class=\"hljs-keyword\">import</span> { <span class=\"hljs-title class_\">Icon</span> } <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">&#x27;./Icon.js&#x27;</span>\n<span class=\"hljs-keyword\">const</span> template = <span class=\"hljs-string\">`&lt;div&gt;<span class=\"hljs-subst\">${Icon(<span class=\"hljs-string\">&#x27;search.svg&#x27;</span>)}</span> Search&lt;/div&gt;`</span>\n\n<span class=\"hljs-comment\">// Icon.js</span>\n<span class=\"hljs-keyword\">import</span> fs <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">&#x27;fs&#x27;</span>\n<span class=\"hljs-keyword\">import</span> path <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">&#x27;path&#x27;</span>\n<span class=\"hljs-keyword\">const</span> __dirname = <span class=\"hljs-comment\">/* Do the stuff to properly resolve the file path */</span>;\n<span class=\"hljs-keyword\">export</span> <span class=\"hljs-keyword\">const</span> <span class=\"hljs-title function_\">Icon</span> = (<span class=\"hljs-params\">name</span>) =&gt; fs.<span class=\"hljs-title function_\">readFileSync</span>(\n  path.<span class=\"hljs-title function_\">join</span>(__dirname, <span class=\"hljs-string\">&#x27;icons&#x27;</span>, name),\n  <span class=\"hljs-string\">&#x27;utf8&#x27;</span>\n).<span class=\"hljs-title function_\">toString</span>();\n</code></pre>\n<p>It’s fine. It works. It’s a lot of node boilerplate to read files from disk.</p>\n<p>But changing icons is a bit of a pain. I have to find new SVGs, overwrite my existing ones, re-commit them to source control, etc. </p>\n<p>I suppose it would be nice if I could just <code>npm i heroicons</code> and get the raw SVGs installed into my <code>node_modules</code> folder and then I could read those. But that has its own set of trade-offs. For example:</p>\n<ul>\n<li>Names are different between icon packs, so when you switch, names don’t match. For example, an icon might be named <code>search</code> in one pack and <code>magnifying-glass</code> in another. So changing sets requires going through all your templates and updating references.</li>\n<li>Icon packs are often quite large and you only need a subset. <code>npm i icon-pack</code> might install hundreds or even thousands of icons I don’t need.</li>\n</ul>\n<p>So the project’s npm packages don’t provide the raw SVGs. The website does, but I want a more programatic way to easily grab the icons I want.</p>\n<p>How can I do this?</p>\n<h2 id=\"enter-origami\">Enter Origami</h2>\n<p>I’m using <a href=\"https://weborigami.org\" >Web Origami</a> for my blog which makes it easy to map icons I use in my templates to Heroicons hosted on Github. It doesn’t require an <code>npm install</code> or a <code>git submodule add</code>. Here’s an snippet of my file:</p>\n<pre><code class=\"language language-ori\">{\n  home.svg: https://raw.githubusercontent.com/tailwindlabs/heroicons/refs/heads/master/optimized/24/outline/home.svg,\n  about.svg: https://raw.githubusercontent.com/tailwindlabs/heroicons/refs/heads/master/optimized/24/outline/question-mark-circle.svg,\n  search.svg: https://raw.githubusercontent.com/tailwindlabs/heroicons/refs/heads/master/optimized/24/outline/magnifying-glass.svg\n}\n</code></pre>\n<p>As you can see, I name my icon (e.g. <code>search</code>) and then I point it to the SVG as hosted on Github via the Heroicons repo. Origami takes care of fetching the icons over the network and caching them in-memory.</p>\n<p>Beautiful, isn’t it? It kind of reminds me of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/script/type/importmap\" >import maps</a> where you can map a bare module specifier to a URL (and <a href=\"https://blog.jim-nielsen.com/2024/deno-de-emphasizes-http-imports/\" >Deno’s semi-abandoned HTTP imports</a> which were beautiful in their own right).</p>\n<h2 id=\"how-it-works\">How It Works</h2>\n<p>Origami makes file paths first-class citizens of the language — even “remote” file paths — so it’s very simple to create a single file that maps <em>your</em> icon names in a codebase to <em>someone else’s</em> icon names from a set, whether those are being installed on disk via npm or fetched over the internet.</p>\n<p>To simplify my example earlier, I can have a file like <code>icons.ori</code>:</p>\n<pre><code class=\"language language-ori\">{\n  home.svg: https://example.com/path/to/home.svg\n  about.svg: https://example.com/path/to/information-circle.svg\n  search.svg: https://example.com/path/to/magnifying-glass.svg\n}\n</code></pre>\n<p>Then I can reference those icons in my templates like this:</p>\n<pre><code class=\"language language-html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span>&gt;</span>${icons.ori/home.svg} Search<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n</code></pre>\n<p>Easy-peasy! And when I want to change icons, I simply update the entries in <code>icons.ori</code> to point somewhere else — at a remote or local path.</p>\n<p>And if you really want to go the extra mile, you can use Origami’s caching feature:</p>\n<pre><code class=\"language language-ori\">Tree.cache(\n  {\n    home.svg: https://raw.github.com/path/to/home.svg\n    about.svg: https://raw.github.com/path/to/information-circle.svg\n    search.svg: https://raw.github.com/path/to/magnifying-glass.svg\n  },\n  Origami.projectRoot()/cache\n)\n</code></pre>\n<p>Rather than just caching the files in memory, this will cache them to a local folder like this:</p>\n<pre><code>cache/\n  home.svg\n  about.svg\n  search.svg\n</code></pre>\n<p>Which is really cool because now when I run my site locally I have a folder of SVG files cached locally that I can look at and explore (useful for debugging, etc.)</p>\n<p>This makes <a href=\"https://blog.jim-nielsen.com/2025/be-mindful-of-what-you-make-easy/\" >vendoring</a> really easy if I want to put these in my project under source control. Just run the file once and boom, they’re on disk!</p>\n<p>There’s something really appealing to me about this. I think it’s because it feels very “webby” — akin to the same reasons I liked HTTP imports in Deno. You declare your dependencies with URLs, then they’re fetched over the network and become available to the rest of your code. No package manager middleman introducing extra complexity like versioning, transitive dependencies, install bloat, etc.</p>\n<p>What’s cool about Origami is that handling icons like this isn’t a “feature” of the language. It’s an outcome of the expressiveness of the language. In some frameworks, this kind of problem would require a special feature (that’s why you have special npm packages for implementations of Heroicons in frameworks like react and vue). But because of the way Origami is crafted as a tool, it sort of pushes you towards crafting solutions in the same manner as you would with web-based technologies (HTML/CSS/JS). It helps you speak “web platform” rather than some other abstraction on top of it. I like that.</p>\n\n    <hr />\n    \n\n    <p>\n      Reply via:\n      \n\n      <a\n        href=\"mailto:jimniels%2Bblog@gmail.com?subject=Re:%20blog.jim-nielsen.com/2026/origami-icons/\"\n        >Email</a\n      >\n      · <a href=\"https://mastodon.social/@jimniels\">Mastodon</a> ·\n\n      <a href=\"https://bsky.app/profile/jim-nielsen.com\">Bluesky</a>\n    </p>\n\n    \n  ",
    "description": "Over the years, I’ve used different icon sets on my blog. Right now I use Heroicons. The recommended way to use them is to copy/paste the source from the website directly into your HTML. It’s a pretty straightforward process: Go to the website Search for the icon you want Hover it Click to “Copy SVG” Go back to your IDE and paste it If you’re using React or Vue, there are also npm packages you can install so you can import the icons as components. But I’m not using either of those frameworks, so",
    "is_fulltext": true,
    "source": "Jim Nielsen’s Blog",
    "pub_date": "Mon, 23 Feb 2026 19:00:00 GMT",
    "fetched_at": "2026-02-24T00:36:46.928321",
    "url_hash": "87aff289187121cf470df5c34128f2a9"
  },
  {
    "title": "Pockets of Humanity",
    "link": "https://herman.bearblog.dev/pockets-of-humanity/",
    "content": "<p>There's a conspiracy theory that suggests that since around 2016 most web activity is automated. This is called <a href='https://en.wikipedia.org/wiki/Dead_Internet_theory' target='_blank'>Dead Internet Theory</a>, and while I think they may have jumped the gun by a few years, it's heading that way now that LLMs can simulate online interactions near-flawlessly. Without a doubt there are tens (hundreds?) of thousands of interactions happening online right now between bots trying to sell each other <em>something</em>.</p>\n<p>This sounds silly, and maybe a little sad, since the internet is the commons that has historically belonged to, and been populated by all of us. This is changing.</p>\n<p>Something interesting happened a few weeks ago where an <a href='https://openclaw.ai' target='_blank'>OpenClaw instance</a>, named MJ Rathbun, submitted a pull request to the <code>matplotlib</code> repository, and after having its code rejected on the basis that humans needed to be in the loop for PRs, it proceeded to do some research on the open-source maintainer who denied it, and wrote a \"hit piece\" on him, to publicly shame him for feeling threatened by AI...or something. The full story is <a href='https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/' target='_blank'>here</a> and I highly recommend giving it a read.</p>\n<p>A lot of the discourse around this has taken the form of \"haha, stupid bot\", but I posit that it is the beginning of something very interesting and deeply unsettling. In this instance the \"hit piece\" wasn't particularly compelling and the bot was trying to submit legitimate looking code, but what this illustrated is that an autonomous agent tried to use a form of coercion to get its way, which is a huge deal.</p>\n<p>This creates two distinct but related problems:</p>\n<p>The first is the classic <a href='https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer' target='_blank'>paperclip maximiser</a> problem, which is a hypothetical example of instrumental convergence where an AI, tasked with running a paperclip factory with the instructions to <em>maximise production</em> ends up not just making the factory more efficient, but going rogue and destroying the global economy in its pursuit of maximising paperclip production. There's a version of this thought experiment where it wipes out humans (by creating a super-virus) because it reasons that humans may switch it off at some point, which would impact its ability to create paperclips.</p>\n<p>If the MJ Rathbun bot's <em>purpose</em> is to browse repositories and submit PRs to open-source repositories, then anyone preventing it from achieving its goal is something that needs to be removed. In this case it was Scott, the maintainer. And while the \"hit piece\" was a ham-fisted attempt at doing that, if Scott had a big, nasty secret such as an affair that the bot was able to ascertain via its research, then it may have gotten its way by blackmailing him.</p>\n<p>This brings me to the second problem, and where the concern shifts from emergent AI behaviour to human intent weaponising agents: The social vulnerability bots.</p>\n<p>Right now there are hundreds of thousands of malicious bots scouring the internet for misconfigured servers and other vulnerable code (<a href='https://herman.bearblog.dev/messing-with-bots/' target='_blank'>ask me how I know</a>). While this is a big issue, and will continue to become an even greater one, I foresee a new kind of bot: ones that search for social vulnerabilities online and exploits them autonomously.</p>\n<p>I'll use <code>OpenSSL</code> as a hypothetical example here. <code>OpenSSL</code> underpins TLS/SSL for most of the internet, so a backdoor there compromises virtually all encrypted web traffic, banking, infrastructure, etc. The <a href='https://en.wikipedia.org/wiki/Heartbleed' target='_blank'>Heartbleed bug</a> showed how devastating even an accidental flaw in <code>OpenSSL</code> can be. If explicitly malicious code were to be injected it would be catastrophic and worth vast sums to the right people. Since there's a large financial incentive to inject malicious code into <code>OpenSSL</code>, it is possible that a bot like MJ Rathburn could be set up and operated by a malicious individual or organisation that searches through Reddit, social media sites, and the rest of the internet looking for information it could use as leverage against a person that could give them access (in this example, one of the maintainers of <code>OpenSSL</code>).</p>\n<p>Say it gained a bunch of private messages in a data leak, which would ordinarily never be parsed in detail, that suggest that a maintainer has been having an affair or committed tax fraud. It could then use that information to blackmail the maintainer into letting malicious code bypass them, and in so doing pull off a large-scale hack.</p>\n<p>This isn't entirely hypothetical either.  The 2024 <a href='https://en.wikipedia.org/wiki/XZ_Utils_backdoor' target='_blank'>xz Utils backdoor</a> involved years of social engineering to compromise a single maintainer.</p>\n<p>This vulnerability scanning is probably already happening, and is going to lead to less of a <em>Dead Internet</em> (although that will be the endpoint) and more of a <em>Dark Forest</em> where anonymous online interactions will likely be bots with a nefarious purpose. This purpose could range from searching for social vulnerabilities and orchestrating scams, to trying to sell you sneakers. I'm sure that <a href='https://en.wikipedia.org/wiki/Pig_butchering_scam' target='_blank'>pig butchering scams</a> are already mostly automated.</p>\n<p>This is going to shift the internet landscape from it being a <em>commons</em>, to it being a place where your guard will need to be up all the time. Undoubtable, there will be pockets of humanity still, that are set up with the express intent of keeping bots and other autonomous malicious actors at bay, like a lively small village in the centre of a dangerous jungle, with big walls and vigilant guards. It's something I think about a lot since I want <a href='https://bearblog.dev' target='_blank'>Bear</a> to be one of those pockets of humanity in this dying internet. It's my priority for the foreseeable future.</p>\n<p>So what can you do about it? I think a certain amount of mistrust online is healthy, as well as a focus on privacy both in the tools you use, and the way you operate. The people who say \"I don't care about privacy because I don't have anything to hide\" are the ones with the largest surface area for confidence scams. I think it'll also be a bit of a wake up call for many to get outside and touch grass.</p>\n<p>Needless to say, the Internet is entering a new era, and we may not be first-class citizens under the new regime.</p>\n",
    "description": "Where do we go when the internet dies?",
    "is_fulltext": true,
    "source": "Herman's blog",
    "pub_date": "2026-02-23T13:24:23.228866+00:00",
    "fetched_at": "2026-02-24T00:37:05.709726",
    "url_hash": "da3a94ab2abbb11f51798b12d94d3f92"
  },
  {
    "title": "How Markdown took over the world",
    "link": "https://anildash.com/2026/01/09/how-markdown-took-over-the-world/",
    "content": "\n        \n      <p>Nearly every bit of the high-tech world, from the most cutting-edge AI systems at the biggest companies, to the casual scraps of code cobbled together by college students, is annotated and described by the same, simple plain text format. Whether you’re trying to give complex instructions to ChatGPT, or you want to be able to exchange a grocery list in Apple Notes or copy someone’s homework in Google Docs, that same format will do the trick. The wild part is, the format wasn’t created by a conglomerate of tech tycoons, it was created by a curmudgeonly guy with a kind heart who right this minute is probably rewatching a Kubrick film while cheering for an absolutely indefensible sports team.</p>\n<p>But it’s worth understanding how these simple little text files were born, not just because I get to brag about how generous and clever my friends are, but also because it reminds us of how the Internet <em>really</em> works: smart people think of good things that are crazy enough that they <em>just might work</em>, and then they give them away, over and over, until they slowly take over the world and make things better for everyone.</p>\n<h2>Making Their Mark</h2>\n<p>Though it’s now a building block of the contemporary Internet, like so many great things, <a href=\"https://daringfireball.net/projects/markdown/\">Markdown</a> just started out trying to solve a personal problem. In 2002, John Gruber made the unconventional decision to bet his online career on two completely irrational foundations: Apple, and blogs.</p>\n<p>It’s hard to remember now, but in 2002, Apple was just a few years past having been on death’s door. As difficult as it may be to picture in today’s world where Apple keynotes are treated like major events, back then, almost nobody was covering Apple regularly, let alone writing <em>exclusively</em> about the company. There was barely even any &quot;tech news&quot; scene online at all, and virtually no one was blogging. So John’s decision to go all-in on Apple for his pioneering blog <a href=\"https://daringfireball.net\">Daring Fireball</a> was, well, a daring one. At the time, Apple had only <em>just</em> launched its first iPod that worked with Windows computers, and the iPhone was still a full five years in the future. But that single-minded obsessive focus, not just on Apple, but on everything he covered, eventually helped inspire much of the technology media landscape that we see today. John’s timing was also perfect — from the doldrums of that era, Apple’s stock price would rise by about 120,000% in the years after Daring Fireball started, and its cultural relevance probably increased by even more than that.</p>\n<p>By 2004, it wasn’t just Apple that had begun to take off: blogs and social media themselves had moved from obscurity to the very center of culture, and <a href=\"https://cybercultural.com/p/internet-2004/\">a new era of web technology had begun</a>. At the beginning of that year, few people in the world even knew what a “blog” was, but by the end of 2004, blogs had become not just ubiquitous, but downright <em>cool</em>. As unlikely as it seems now, that year’s largely uninspiring slate of U.S. presidential candidates like Wesley Clark, Gary Hart and, yes, <a href=\"https://en.wikipedia.org/wiki/Howard_Dean_2004_presidential_campaign\">Howard Dean</a> helped propel blogs into mainstream awareness during the Democratic primaries, alongside online pundits who had begun weighing in on politics and the issues and cultural moments at a pace that newspapers and TV couldn’t keep up with. A lot has been written about the transformation of media during those years, but less has been written about how the media and tech of the time transformed <em>each other</em>.</p>\n<p><img src=\"/images/gary-hart-blog.JPG\" alt=\"A photo from 2004 of a TV screen showing CNN, with a ticker saying &quot;Gary Hart Cyber Campaign Starts blog for possible 2004 presidential bid&quot;\"></p>\n<p>That era of early blogging was interesting in that nearly everyone who was writing the first popular sites was also busy helping <em>create</em> the tools for publishing them. Just like Lucille Ball and Desi Arnaz had to pioneer combining studio-style flat lighting with 35mm filming in order to define the look of the modern sitcom, or Jimi Hendrix had to work with Roger Mayer to invent the signature guitar distortion pedals that defined the sound of rock and roll, the pioneers who defined the technical format and structures of blogging were often building the very tools of creation as they went along.</p>\n<p>I got a front row seat to these acts of creation. At the time I was working on Movable Type, which was the most popular tool for publishing “serious” blogs, and helped popularize the medium. Two of my good friends had built the tool and quickly made it into the default choice for anybody who wanted to reach a big audience; it was kind of a combination of everything people do these days on WordPress and all the various email newsletter platforms and all of the “serious” podcasts (since podcasts wouldn’t be invented for another few months). But back in those early days, we’d watch people use our tools to set up Gawker or Huffington Post one day, and Daring Fireball or Waxy.org the next, and each of them would be the first of its kind, both in terms of its design and its voice. To this day, when I see something online that I love by Julianne Escobedo Shepherd or Ta-Nehisi Coates or Nilay Patel or Annalee Newitz or any one of dozens of other brilliant writers or creators, my first thought is often, “hey! They used to type in that app that I used to make!” Because sometimes those writers would inspire us to make a new feature in the publishing tools, and sometimes they would have hacked up a new feature all by themselves in between typing up their new blog posts.</p>\n<p>A really clear, and very simple, early example of how we learned that lesson was when we changed the size of the box that people used to type in just to create the posts on their sites. We made the box a little bit taller, mostly for aesthetic reasons. Within a few weeks, we’d found that posts on sites like Gawker had gotten longer, <em>mostly because the box was bigger</em>. This seems obvious now, years after we saw tweets get longer when Twitter expanded from 140 characters to 280 characters, but at the time this was a terrifying glimpse at how much power a couple of young product managers in a conference room in California would have over the media consumption of the entire world every time they made a seemingly-insignificant decision.</p>\n<p>The <em>other</em> dirty little secret was, typing in the box in that old blogging app could be… pretty wonky sometimes. People who wanted to do normal things like include an image or link in their blog post, or even just make some text bold, often had to learn somewhat-obscure HTML formatting, memorizing the actual language that’s used to make web pages. Not everybody knew all the details of how to make pages that way, and if they made even one small mistake, sometimes they could break the whole design of their site. It made things feel very fraught every time a writer went to publish something new online, and got in the way of the increasingly-fast pace of sharing ideas now that social media was taking over the public conversation.</p>\n<p>Enter John and his magical text files.</p>\n<p><img src=\"/images/markdown-text-hero-slice.jpg\" alt=\"\"></p>\n<h2>Marking up and marking down</h2>\n<p>The purpose of Markdown is really simple: It lets you use the regular characters on your keyboard which you already use while typing out things like emails, to make fancy formatting of text for the web. The name of that HTML format that's used to make web pages stands for HyperText Markup Language. The word “markup” there means you’re “marking up” your text with all kinds of special characters.\nOnly, the special characters can be kind of arcane. Want to put in a link to everybody’s favorite website? Well, you’re going to have to type in <code>&lt;a href=&quot;https://anildash.com/&quot;&gt;Anil Dash’s blog&lt;/a&gt;</code> I could explain why, and what it all means, but honestly, you get the point — it’s a lot! Too much. What if you could just write out the text and then the link, sort of like you might within an email? Like: <code>[Anil Dash’s blog](https://anildash.com)</code>! And then the right thing would happen. Seems great, right?</p>\n<p>The same thing works for things like putting a header on a page. For example, as I’m writing this right now, if I want to put a big headline on this page, I can just type <code># How Markdown Took Over the World</code> and the right thing will happen.</p>\n<p>If mark_up_ is complicated, then the opposite of that complexity must be… markd_own_. This kind of solution, where it’s so smart it seems obvious in hindsight, is key to Markdown’s success. John worked to make a format that was so simple that anybody could pick it up in a few minutes, and powerful enough that it could help people express pretty much anything that they wanted to include while writing on the internet. At a technical level, it was also easy enough to implement that John could write the code himself to make it work with Movable Type, his publishing tool of choice. (Within days, people had implemented the same feature for most of the other blogging tools of the era; these days, virtually every app that you can type text into ships with Markdown support as a feature on day one.)</p>\n<p>Prior to launch, John had enlisted our mutual friend, the late, dearly missed <a href=\"http://www.aaronsw.com\">Aaron Swartz</a>, as a beta tester. In addition to being extremely fluent in every detail of the blogging technologies of the time, Aaron was, most notably, seventeen years old. And though Aaron’s activism and untimely passing have resulted in him having been turned into something of a mythological figure, one of the greatest things about Aaron was that he could be a total pain in the ass, which made him <em>terrific</em> at reporting bugs in your software. (One of the last email conversations I ever had with Aaron was him pointing out some obscure bugs in an open source app I was working on at the time.) No surprise, Aaron instantly understood both the potential and the power of Markdown, and was a top-tier beta tester for the technology as it was created. His astute feedback helped finely hone the final product so it was ready for the world, and when Markdown <a href=\"https://daringfireball.net/2004/03/introducing_markdown\">quietly debuted in March of 2004</a>, it was clear that text files around the web were about to get a permanent upgrade.</p>\n<p>The most surprising part of what happened next wasn’t that everybody immediately started using it to write their blogs; that was, after all, what the tool was designed to do. It’s that everybody started using Markdown to do <em>everything else</em>, too.</p>\n<h2>Hitting the Mark</h2>\n<p>It’s almost impossible to overstate the ubiquity of Markdown within the modern computer industry in the decades since its launch.</p>\n<p>After being nagged about it by users for more than a decade, Google finally <a href=\"https://www.theverge.com/2022/3/29/23002138/google-docs-markdown-support-formatting-update\">added support for Markdown to Google Docs</a>, though it took them years of fiddly improvements to make it truly usable. Just last year, Microsoft added support for Markdown to its <a href=\"https://www.theverge.com/news/677474/microsoft-windows-notepad-bold-italic-text-formatting-markdown-support\">venerable Notepad app</a>, perhaps in an attempt to assuage the tempers of users who were still in disbelief that Notepad had been bloated with AI features. Nearly every powerful group messaging app, from Slack to WhatsApp to Discord, has support for Markdown in messages. And even the company that indirectly inspired all of this in the first place finally got on board: the most recent version of Apple Notes <a href=\"https://apple.gadgethacks.com/how-to/ios-26-notes-app-finally-gets-markdown-support-this-fall/\">finally added support</a> for Markdown. (It’s an especially striking launch by Apple due to its timing, shortly after John had used his platform as the most influential Apple writer in the world to <a href=\"https://daringfireball.net/2025/03/something_is_rotten_in_the_state_of_cupertino\">blog about the utter failure</a> of the “Apple Intelligence” AI launch.)</p>\n<p>But it’s not just the apps that you use on your phone or your laptop. For developers, Markdown has long been the lingua franca of the tools we string together to accomplish our work. On GitHub, the platform that nearly every developer in the world uses to share their code, nearly <em>every single repository of code</em> on the site has at least one Markdown file that’s used to describe its contents. Many have <em>dozens</em> of files describing all the different aspects of their project. And some of the repositories on GitHub consist of nothing <em>but</em> massive collections of Markdown files. The small tools and automations we run to perform routine tasks, the one-off reports that we generate to make sure something worked correctly, the confirmations that we have a system alert email out when something goes wrong, the temporary files we use when trying to recover some old data — all of these default to being Markdown files.</p>\n<p>As a result, there are now <em>billions</em> of Markdown files lying around on hard drives around the world. Billions more are stashed in the cloud. There are some on the phone in your pocket. Programmers leave them lying around wherever their code might someday be running. Your kid’s Nintendo Switch has Markdown files on it. If you’re listening to music, there’s probably a Markdown file on the memory chip of the tiny system that controls the headphones stuck in your ears. <em>The Markdown is inside you right now!</em></p>\n<h2>Down For Whatever</h2>\n<p>So far, these were all things we could have foreseen when John first unleashed his little text tool on the world. I would have been surprised about how <em>many</em> people were using it, but not really the <em>ways</em> in which they were using it. If you’d have said “Twenty years in the future, all the different note-taking apps people use save their files using Markdown!”, I would have said, “Okay, that makes sense!”</p>\n<p>What I <em>wouldn’t</em> have asked, though, was “Is John getting paid?” As hard as it may be to believe, back in 2004, the <em>default</em> was that people made new standards for open technologies like Markdown, and just shared them freely for the good of the internet, and the world, and then went on about their lives. If it happened to have unleashed billions of dollars of value for others, then so much the better. If they got some credit along the way, that was great, too. But mostly you just did it to solve a problem for yourself and for other like-minded people. And also, maybe, to help make sure that some jerk didn’t otherwise create some horrible proprietary alternative that would lock everybody into their terrible inferior version forever instead. (We didn’t have the word “enshittification” yet, but we did have Cory Doctorow and we did have plain text files, so we kind of knew where things were headed.)</p>\n<p>To give a sense of the vibe of that era, the term “podcasting” had been coined just a month before Markdown was released, and went into wider use that fall, and was similarly <a href=\"https://www.anildash.com/2024/02/05/wherever-you-get-podcasts/\">a radically open system</a> that wasn’t owned by any big company and that empowered people to do whatever they wanted to do to express themselves. (And podcasting was another technology that Aaron Swartz helped improve by being a brilliant pain in the ass. But I’ll save that story for another book-length essay.)</p>\n<p>That attitude of being not-quite-_anti_commercial, but perhaps just not even really <em>concerned</em> with whether something was commercial or not seems downright quaint in an era when the tech tycoons are not just the wealthiest people in the world, but also some of the weirdest and most obnoxious as well. But the truth is, most people <em>today</em> who make technology are actually still exceedingly normal, and quite generous. It’s just that they’ve been overshadowed by their bosses who are out of their minds and building rocket ships and siring hundreds of children and embracing overt white supremacy instead of making fun tools for helping you type text, like regular people do.</p>\n<p><img src=\"/images/markdown-text-hero-slice2.jpg\" alt=\"\"></p>\n<h2>The Markdown Model</h2>\n<p>The part about not doing this stuff solely for money matters, because even the <em>most</em> advanced LLM systems today, what the big AI companies call their “frontier” models, require complex orchestration that’s carefully scripted by people who’ve tuned their prompts for these systems through countless rounds of trial and error. They’ve iterated and tested and watched for the results as these systems hallucinated or failed or ran amok, chewing up countless resources  along the way. And sometimes, they generated genuinely astonishing outputs, things that are truly amazing to consider that modern technology can achieve. The rate of progress and evolution, even factoring in the mind-boggling amounts of investment that are going into these systems, is rivaled only by the initial development of the personal computer or the Internet, or the early space race.</p>\n<p>And all of it — <em>all of it</em> — is controlled through Markdown files. When you see the brilliant work shown off from somebody who’s bragging about what they made ChatGPT generate for them, or someone is understandably proud about the code that they got Claude to create, all of the most advanced work has been prompted in Markdown. Though where the logic of Markdown was originally a very simple version of &quot;use human language to tell the machine what to do&quot;, the implications have gotten far more dire when they use a format designed to help expresss &quot;make this <code>**bold**</code>&quot; to tell the computer itself &quot;<code>make this imaginary girlfriend more compliant</code>&quot;.</p>\n<p>But we already know that the Big AI companies are run by people who don't reckon with the implications of their work. They could never understand that every single project that's even moderately ambitious on these new AI platforms is being written up in files formatted according to this system created by one guy who has never asked for a dime for this work. An entire generation of AI coders has been born since Markdown was created who probably can’t even imagine that this technology even <em>has</em> an &quot;inventor&quot;. It’s just always been here, like the Moon, or Rihanna.</p>\n<p>But it’s important for <em>everyone</em> to know that the Internet, and the tech industry, don’t run without the generosity and genius of regular people. It is not just billion-dollar checks and Silicon Valley boardrooms that enable creativity over years, decades, or generations — it’s often a guy with a day job who just gives a damn about doing something right, sweating the details and assuming that if he cares enough about what he makes then others will too. The <em>majority</em> of the technical infrastructure of the Internet was created in this way. For free, often by people in academia, or as part of their regular work, with no promise of some big payday or getting a ton of credit.</p>\n<p>The people who make the <em>real</em> Internet and the real innovations also don’t look for ways to hurt the world around them, or the people around them. Sometimes, as in the case of Aaron, the world hurts them more than anyone should ever have to bear. I know not everybody cares that much about plain text files on the Internet; I will readily admit I am a huge nerd about this stuff in a way that most normal people are not. But I do think everybody cares about <em>some</em> part of the wonderful stuff on the Internet in this way, and I want to fight to make sure that everybody can understand that it’s not just five terrible tycoons who built this shit. Real people did. Good people. I saw them do it.</p>\n<p>The trillion-dollar AI industry's system for controlling their most advanced platforms is a plain text format one guy made up for his blog and then bounced off of a 17-year-old kid before sharing it with the world for free. You're welcome, Time Magazine's people of the year, <em>The Architects of AI</em>. Their achievement is every bit as impressive as yours.</p>\n<p><img src=\"/images/markdown-text-hero-slice3.jpg\" alt=\"\"></p>\n<h1 id=\"top-ten\">The Ten Technical Reasons Markdown Won</h1>\n<p>Okay, with some of the narrative covered, what can we <em>learn</em> from Markdown’s success? How did this thing really take off? What could we do if we wanted to replicate something like this in the modern era? Let’s consider a few key points:</p>\n<h3>1. Had a great brand.</h3>\n<p>Okay, let’s be real: “Markdown” as a name is clever as hell. Get it — it's not markup, it's mark <em>down</em>. You just can’t argue with that kind of logic. People who knew what the “M” in “HTML” stood for could understand the reference, and to everyone else, it was just a clearly-understandable name for a useful utility.</p>\n<h3>2. Solved a real problem.</h3>\n<p>This one is not obvious, but it’s really important that a new technology have a <em>real</em> problem that it’s trying to solve, instead of just being an abstract attempt to do something vague, like “make text files better”. Millions of people were encountering the idea that it was too difficult or inconvenient to write out full HTML by hand, and even if one had the necessary skills, it was nice to be able to do so in a format that was legible as plain text as well.</p>\n<h3>3. Built on behaviors that already existed.</h3>\n<p>This is one of the most quietly genius parts of Markdown: The format is based on the ways people had been adding emphasis and formatting to their text for years or even decades. Some of the formatting choices dated back to the early days of email, so they’d been ingrained in the culture of the internet for a full generation before Markdown existed. It was so familiar, people could be writing Markdown <em>without even knowing it</em>.</p>\n<h3>4. Mirrored RSS in its origin.</h3>\n<p>Around the same time that Markdown was taking off, RSS was maturing into its ubiquitous form as well. The format had existed for some years already, enabling various kinds of content syndication, but at this time, it was adding support for the technologies that would come to be known as podcasting as well. And just like RSS, Markdown was spearheaded by a smart technologist who was also more than a little stubborn about defining a format that would go on to change the way we share content on the internet. In RSS’ case, it was pioneered by Dave Winer, and with Markdown it was John Gruber, and both were tireless in extolling the virtues of the plain text formats they’d helped pioneer. They could both leverage blogs to get the word out, and to get feedback on how to build on their wins.</p>\n<h3>5. There was a community ready to help.</h3>\n<p>One great thing about a format like Markdown is that its success is never just the result of one person. Vitally, Markdown was part of a community that could build on it right from the start. Right from the beginning, Markdown was inspired by earlier works like Textile, a formatting system for plain text created by <a href=\"https://web.archive.org/web/20021226035527/http://textism.com/tools/textile/\">Dean Allen</a>. Many of us appreciated and were inspired by Dean, who was a pioneer of blogging tools in the early days of social media, but if there’s a bigger fan of Dean Allen on the internet than John Gruber, I’ve never met them. Similarly, <a href=\"http://www.rememberaaronsw.com/memories/\">Aaron Swartz</a>, the brilliant young technologist who's best known as an activist for digital rights and access, was at that time just a super brilliant teenager that a lot of us loved hacking with. He was the most valuable beta tester of Markdown prior to its release, helping to shape it into a durable and flexible format that’s stood the test of time.</p>\n<h3>6. Had the right flavor for every different context.</h3>\n<p>Because Markdown’s format was frozen in place (and had some super-technical details that people could debate about) and people wanted to add features over time, various communities that were implementing Markdown could add their own “flavors” of it as they needed. Popular ones came to be called Commonmark and Github-Flavored, led by various companies or teams that had divergent needs for the tool. While tech geeks tend to obsess over needing everything to be “correct”, in reality it often just <em>doesn’t matter</em> that much, and in the real world, the entire Internet is made up of content that barely follows the technical rules that it’s supposed to.</p>\n<h3>7. Released during a time of change in behaviors and habits.</h3>\n<p>This is a subtle point, but an important one: Markdown came along at the right time in the evolution of its medium. You can get people to change their behaviors when they’re using a new tool, or adopting a new technology. In this case, blogging (and all of social media!) were new, so saying “here’s a new way of typing a list of bullet points” wasn't much of an additional learning curve to add to the mix. If you can take advantage of catching people while they’re already in a learning mood, you can really tap into the moment when they’re most open-minded to new things.</p>\n<h3>8. Came right on the cusp of the “build tool era”.</h3>\n<p>This one’s a bit more technical, but also important to understand. In the first era of building for the web, people often built the web's languages of HTML, JavaScript and CSS by hand, by themselves, or stitched these formats together from subsets or templates. But in many cases, these were fairly simple compositions, made up of smaller pieces that were written in the same languages. As things matured, the roles for web developers specialized (there started to be backend developers vs. front-end, or people who focused on performance vs. those who focused on visual design), and as a result the tooling for developers matured. On the other side of this transition, developers began to use many different programming languages, frameworks and tools, and the standard step before trying to deploy a website was to have an automated build process that transformed the “raw materials” of the site into the finished product. Since Markdown is a raw material that has to be transformed into HTML, it perfectly fit this new workflow as it became the de facto standard method of creation and collaboration.</p>\n<h3>9. Worked with “View source”</h3>\n<p>Most of the technologies that work best on the web enable creators to “view source” just like HTML originally did when the first web browsers were created. In this philosophy, you can look at the source code that makes up a web page, and understand how it was constructed so that you can make your own. With Markdown, it only takes one glimpse of a source Markdown file for anyone to understand how they might make a similar file of their own, or to extrapolate how they might apply analogous formatting to their own documents. There’s no teaching required when people can just see it for themselves.</p>\n<h3>10. Not encumbered in IP</h3>\n<p>This one’s obvious if you think about it, but it can’t go unsaid: There are no legal restrictions around Markdown. You wouldn’t <em>think</em> that anybody would be foolish or greedy enough to try to patent something as simple as Markdown, but there are many far worse examples of patent abuse in the tech industry. Fortunately, John Gruber is not an awful person, and nobody else has (yet) been brazen enough to try to usurp the format for their own misadventures in intellectual property law. As a result, nobody’s been afraid, either to use the format, or to support creating or reading the format in their apps.</p>\n\n    \n      ",
    "description": "",
    "is_fulltext": true,
    "source": "Anil Dash",
    "pub_date": "2026-01-09T00:00:00Z",
    "fetched_at": "2026-02-24T00:37:11.451261",
    "url_hash": "551bcd81bbafcf3d2b2b17ab851e3292"
  }
]