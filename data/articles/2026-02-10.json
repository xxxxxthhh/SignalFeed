[
  {
    "title": "Structured Context Engineering for File-Native Agentic Systems",
    "link": "https://simonwillison.net/2026/Feb/9/structured-context-engineering-for-file-native-agentic-systems/#atom-everything",
    "content": "\n    \n<p><strong><a href=\"https://arxiv.org/abs/2602.05447\">Structured Context Engineering for File-Native Agentic Systems</a></strong></p>\nNew paper by Damon McMillan exploring challenging LLM context tasks involving large SQL schemas (up to 10,000 tables) across different models and file formats:</p>\n<blockquote>\n<p>Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables.</p>\n</blockquote>\n<p>Unsurprisingly, the biggest impact was the models themselves - with frontier models (Opus 4.5, GPT-5.2, Gemini 2.5 Pro) beating the leading open source models (DeepSeek V3.2, Kimi K2, Llama 4).</p>\n<p>Those frontier models benefited from filesystem based context retrieval, but the open source models had much less convincing results with those, which reinforces my feeling that the filesystem coding agent loops aren't handled as well by open weight models just yet. The <a href=\"https://www.tbench.ai/leaderboard/terminal-bench/2.0\">Terminal Bench 2.0</a> leaderboard is still dominated by Anthropic, OpenAI and Gemini.</p>\n<p>The \"grep tax\" result against <a href=\"https://github.com/toon-format/toon\">TOON</a> was an interesting detail. TOON is meant to represent structured data in as few tokens as possible, but it turns out the model's unfamiliarity with that format led to them spending significantly more tokens over multiple iterations trying to figure it out:</p>\n<p><img alt=\"Screenshot of a figure from a research paper. Introductory text reads: &quot;As schema size increased, TOON showed dramatically increased token consumption for Claude models despite being ~25% smaller in file size. Scale experiments used Claude models only.&quot; Below is &quot;Figure 7: The 'Grep Tax' - TOON Token Overhead at Scale&quot;, a bar chart with a logarithmic y-axis labeled &quot;Tokens&quot; comparing YAML (teal) and TOON (purple) at two schema sizes: S5 (500 tables) and S9 (10,000 tables). At S5, TOON is +138% more tokens than YAML (~1,100 vs ~450). At S9, TOON is +740% more tokens (~50,000 vs ~7,000). Below the chart, explanatory text reads: &quot;The 'grep tax' emerged as schema size scaled. At S5 (500 tables), TOON consumed 138% more tokens than YAML; at S9 (10,000 tables), this grew to 740%. Root cause: models lacked familiarity with TOON's syntax and could not construct effective refinement patterns.&quot;\" src=\"https://static.simonwillison.net/static/2026/grep-tax.jpg\" />\n\n    <p><small></small>Via <a href=\"https://twitter.com/omarsar0/status/2020150077637997013\">@omarsar0</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/prompt-engineering\">prompt-engineering</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/paper-review\">paper-review</a>, <a href=\"https://simonwillison.net/tags/context-engineering\">context-engineering</a></p>\n\n\n\n",
    "description": "Structured Context Engineering for File-Native Agentic Systems New paper by Damon McMillan exploring challenging LLM context tasks involving large SQL schemas (up to 10,000 tables) across different models and file formats: Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas rang",
    "is_fulltext": true,
    "source": "Simon Willison's Weblog",
    "pub_date": "2026-02-09T23:56:51+00:00",
    "fetched_at": "2026-02-10T00:44:18.965425",
    "url_hash": "6068e368f09ac9287e2e2e4af5e589ed"
  },
  {
    "title": "Gadget Review: Orico Power Strip (UK) ★★⯪☆☆",
    "link": "https://shkspr.mobi/blog/2026/02/gadget-review-orico-power-strip-uk/",
    "content": "<p>The good folks at <a href=\"https://amzn.to/3MnnG2x\">Orico</a> have sent me their latest power-strip to review. On the surface, the specs are pretty good - two UK sockets, two USB-C for PowerDelivery, and two USB-A for legacy devices.</p>\n\n<img src=\"https://shkspr.mobi/blog/wp-content/uploads/2026/02/PDC25.webp\" alt=\"Power Strip in black.\" width=\"1200\" height=\"1200\" class=\"aligncenter size-full wp-image-67535\">\n\n<p>Let's put it though its paces!</p>\n\n<h2 id=\"specs\"><a href=\"https://shkspr.mobi/blog/2026/02/gadget-review-orico-power-strip-uk/#specs\">Specs</a></h2>\n\n<p>Physically, it is a little larger than I was expecting. The two UK sockets are far enough apart to easily get your fingers around the plugs. Similarly, the USB ports are well-spaced. There's a tiny LED to show that power is connected, but it isn't offensively bright.</p>\n\n<p>The UK plug is <em>tiny</em>:</p>\n\n<img src=\"https://shkspr.mobi/blog/wp-content/uploads/2026/02/plug.webp\" alt=\"Photo of a plug, the body is 1.3cm high.\" width=\"664\" height=\"202\" class=\"aligncenter size-full wp-image-67538\">\n\n<p>Even better, it comes with a proper fuse! The power cord isn't removable, but is long enough for most purposes.</p>\n\n<p>How much power can it supply? This is what the spec sheet says:</p>\n\n<table>\n<thead>\n<tr>\n  <th align=\"right\"></th>\n  <th align=\"center\">V</th>\n  <th align=\"center\">A</th>\n  <th align=\"center\">W</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td align=\"right\">USB-A</td>\n  <td align=\"center\">5</td>\n  <td align=\"center\">3</td>\n  <td align=\"center\">15</td>\n</tr>\n<tr>\n  <td align=\"right\">USB-A</td>\n  <td align=\"center\">9</td>\n  <td align=\"center\">2.22</td>\n  <td align=\"center\">20</td>\n</tr>\n<tr>\n  <td align=\"right\">USB-A</td>\n  <td align=\"center\">12</td>\n  <td align=\"center\">1.67</td>\n  <td align=\"center\">15</td>\n</tr>\n<tr>\n  <td align=\"right\">USB-C</td>\n  <td align=\"center\">5</td>\n  <td align=\"center\">3</td>\n  <td align=\"center\">15</td>\n</tr>\n<tr>\n  <td align=\"right\">USB-C</td>\n  <td align=\"center\">9</td>\n  <td align=\"center\">2.77</td>\n  <td align=\"center\">25</td>\n</tr>\n<tr>\n  <td align=\"right\">USB-C</td>\n  <td align=\"center\">12</td>\n  <td align=\"center\">2.08</td>\n  <td align=\"center\">25</td>\n</tr>\n</tbody>\n</table>\n\n<p>But there is a fly in the ointment. While 25W is the most that a single USB-C port can output, the power drops once <em>multiple</em> devices are connected. If you have two or more plugged in, the total output is limited to a mere 15W. Not per-port; total!</p>\n\n<p>25W is already fairly low by PowerDelivery standards, so you won't be using this to power your gaming laptop while charging your tablet and headphones.</p>\n\n<h2 id=\"real-world-testing\"><a href=\"https://shkspr.mobi/blog/2026/02/gadget-review-orico-power-strip-uk/#real-world-testing\">Real World Testing</a></h2>\n\n<img src=\"https://shkspr.mobi/blog/wp-content/uploads/2026/02/double-plug.webp\" alt=\"Two plugs and two USB cables plugged into the unit.\" width=\"1024\" height=\"768\" class=\"aligncenter size-full wp-image-67770\">\n\n<p>I used my <a href=\"https://shkspr.mobi/blog/2023/10/gadget-review-plugable-usb-c-voltage-amperage-meter-240w/\">Plugable USB-C Power Meter</a> with some high-quality USB cables. The Orico <em>mostly</em> lives up to its promises.</p>\n\n<p>When charging my laptop from either USB-C port, I was able to measure 22W (12V ⎓ 1.85A). Pretty close to the spec.</p>\n\n<p>As soon as I plugged my phone into the other USB-C port, that dropped that down to just under 8W (4.8 ⎓ 1.65A) per port. Again, right on the promised 15W total.</p>\n\n<p>The USB-A port happily delivered 7.5W (5V ⎓ 1.5A) - much lower than expected. That dropped to around 5W (5V ⎓ 1A) once a USC-C load was connected. The C port was only delivering ~10W which wasn't enough to meaningfully charge the laptop.</p>\n\n<h2 id=\"final-thoughts\"><a href=\"https://shkspr.mobi/blog/2026/02/gadget-review-orico-power-strip-uk/#final-thoughts\">Final Thoughts</a></h2>\n\n<p>The flat plug is handy for plugging this in to those hard-to-reach spaces. The cable is long enough for most uses. The mixture of ports isn't for everyone, but handy if you still have legacy devices you need to power.</p>\n\n<p>It meets the promised specification - but the specs are a bit of a let-down. You can get smaller devices which will do 60W charging from USB-C, and they'll spread that out over all their ports.</p>\n\n<p>The two UK sockets are a nice-to-have, but I can't help feeling that they'll mostly be used for adding additional chargers.</p>\n\n<p>It is cheap-ish - US$30 / £20 - and comes in a range of colours. If you need a long cable and don't need ultra-fast charging, this will do.</p>\n",
    "description": "The good folks at Orico have sent me their latest power-strip to review. On the surface, the specs are pretty good - two UK sockets, two USB-C for PowerDelivery, and two USB-A for legacy devices. Let&#039;s put it though its paces! Specs Physically, it is a little larger than I was expecting. The two UK sockets are far enough apart to easily get your fingers around the plugs. Similarly, the USB…",
    "is_fulltext": true,
    "source": "Terence Eden’s Blog",
    "pub_date": "Mon, 09 Feb 2026 12:34:42 +0000",
    "fetched_at": "2026-02-10T00:44:29.306837",
    "url_hash": "d6434d10d5cca63539dac15bb47e8d11"
  },
  {
    "title": "Systemd and blocking connections to localhost, including via 'any'",
    "link": "https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdAndConnectToAny",
    "content": "<div class=\"wikitext\"><p>I recently discovered <a href=\"https://utcc.utoronto.ca/~cks/space/blog/web/LocalhostSurpriseAccessViaAny\">a surprising path to accessing localhost\nURLs and services</a>, where\ninstead of connecting to 127.0.0.1 or the IPv6 equivalent, you\nconnected to 0.0.0.0 (or the IPv6 equivalent). In that entry I\nmentioned that I didn't know if <a href=\"https://www.freedesktop.org/software/systemd/man/latest/systemd.resource-control.html#IPAddressAllow=ADDRESS%5B/PREFIXLENGTH%5D%E2%80%A6\">systemd's IPAddressDeny</a>\nwould block this. I've now tested this, and the answer is that\nsystemd's restrictions do block this. If you set\n'IPAddressDeny=localhost', the service or whatever is blocked from\nthe 0.0.0.0 variation as well (for both outbound and inbound\nconnections). This is exactly the way it should be, so you might\nwonder why I was uncertain and felt I needed to test it.</p>\n\n<p>There are a variety of ways at different levels that you might\nimplement access controls on a process (or a group of processes)\nin Linux, for IP addresses or anything else. For example, you might\ncreate an eBPF program that filtered the system calls and system\ncall arguments allowed and attach it to a process and all of its\nchildren using <a href=\"https://www.man7.org/linux/man-pages/man2/seccomp.2.html\">seccomp(2)</a>.\nAlternately, for filtering IP connections specifically, you might\nuse <a href=\"https://docs.ebpf.io/linux/program-type/BPF_PROG_TYPE_CGROUP_SOCK_ADDR/\">a cgroup socket address eBPF program</a>\n(<a href=\"https://eunomia.dev/tutorials/cgroup/\">also</a>), which are among\nthe <a href=\"https://docs.ebpf.io/linux/program-type/\">the cgroup program types</a>\nthat are available. Or perhaps you'd prefer to use <a href=\"https://docs.ebpf.io/linux/program-type/BPF_PROG_TYPE_CGROUP_SKB/\">a cgroup socket\nbuffer program</a>.</p>\n\n<p>How a program such as systemd implements filtering has implications\nfor what sort of things it has to consider and know about when doing\nthe filtering. For example, if we reasonably conclude that the\nkernel will have mapped 0.0.0.0 to 127.0.0.1 by the time it invokes\ncgroup socket address eBPF programs, such a program doesn't need\nto have any special handling to block access to localhost by people\nusing '0.0.0.0' as the target address to connect to. On the other\nhand, if you're filtering at the system call level, the kernel has\nalmost certainly not done such mapping at the time it invokes you,\nso your connect() filter had better know that '0.0.0.0' is equivalent\nto 127.0.0.1 and it should block both.</p>\n\n<p>This diversity is why I felt I couldn't be completely sure about\nsystemd's behavior without actually testing it. To be honest, I\ndidn't know what the specific options were until I researched them\nfor this entry. I knew systemd used eBPF for <a href=\"https://www.freedesktop.org/software/systemd/man/latest/systemd.resource-control.html#IPAddressAllow=ADDRESS%5B/PREFIXLENGTH%5D%E2%80%A6\">IPAddressDeny</a>\n(because it mentions that in the manual page in passing), but I vaguely\nknew there are a lot of ways and places to use eBPF and I didn't know if\nsystemd's way needed to know about 0.0.0.0 or if systemd did know.</p>\n\n<h3>Sidebar: What systemd uses</h3>\n\n<p>As I found out through use of '<a href=\"https://man.archlinux.org/man/bpftool.8.en\">bpftool</a> <a href=\"https://man.archlinux.org/man/bpftool-cgroup.8.en\">cgroup</a> list\n/sys/fs/cgroup/&lt;relevant thing>' on a systemd service that I knew\nuses systemd IP address filtering, systemd uses <a href=\"https://docs.ebpf.io/linux/program-type/BPF_PROG_TYPE_CGROUP_SKB/\">cgroup socket\nbuffer programs</a>, and\nis presumably looking for good and bad IP addresses and netblocks\nin those programs. This unfortunately means that it would be hard for\nsystemd to have different filtering for inbound connections as opposed\nto outgoing connections, because at the socket buffer level it's all\npackets.</p>\n\n<p>(You'd have to go up a level to more complicated filters on <a href=\"https://docs.ebpf.io/linux/program-type/BPF_PROG_TYPE_CGROUP_SOCK_ADDR/\">socket\naddress operations</a>.)</p>\n</div>\n",
    "description": "",
    "is_fulltext": true,
    "source": "Chris's Wiki :: blog",
    "pub_date": "2026-02-09T04:22:04Z",
    "fetched_at": "2026-02-10T00:44:32.426231",
    "url_hash": "86693b9875dc0e6961695a182645b9a8"
  },
  {
    "title": "What should I do if a wait call reports WAIT_ABANDONED?",
    "link": "https://devblogs.microsoft.com/oldnewthing/20260209-00/?p=112049",
    "content": "<p>If you call a wait function like <code>Wait­For­Single­Object</code> and receive the code <code>WAIT_<wbr />ABANDONED</code>, what does it mean and what should you do?</p>\n<p>The documentation says that <code>WAIT_<wbr />ABANDONED</code> means that you successfully claimed a mutex, but the thread that previously owned the mutex failed to release the mutex before it exited. This could be an oversight because the code encountered a code path that forgot to release the mutex. Or it could be because the thread crashed before it could release the mutex.</p>\n<p>The documentation also suggests that &#8220;If the mutex was protecting persistent state information, you should check it for consistency.&#8221; This is to handle the second case: The thread crashes before it can release the mutex. If the purpose of the mutex was to prevent other threads from accessing the data while it is in an inconsistent state, then the fact that the thread crashed while holding the mutex means that the data might still be in that inconsistent state.</p>\n<p>Now, maybe you have no way to check whether the data is in an inconsistent state or have no way to repair it if such an inconsistent state is discovered. (Most people don&#8217;t bother to design their data structures with rollback or transactions, because the point of the mutex was to avoid having to write that fancy code in the first place!) In that case, you really have only two choices.</p>\n<p>One option is to just cover your ears and pretend you didn&#8217;t hear anything. Just continue operating normally and hope that any latent corruption is not going to cause major problems.</p>\n<p>Another option is to give up and abandon the operation. However, if that&#8217;s your choice, you have to give up properly.</p>\n<p>The abandoned state is not sticky; is reported only to the <i>first</i> person to wait for the mutex after it was abandoned. Subsequent waits succeed normally. Therefore, if you decide, &#8220;Oh it&#8217;s corrupted, I&#8217;m not touching it,&#8221; and release the mutex and walk away, then the next person to wait for the mutex will receive a normal successful wait, and they will dive in, unaware that the data structures are corrupted!</p>\n<p>One solution is to add a flag inside your data that says &#8220;Possibly corrupted.&#8221; The code that detects the <code>WAIT_<wbr />ABANDONED</code> can set that flag, and everybody who acquires the mutex can check the flag to decide if they want to take a chance by operating on corrupted data.</p>\n<p>I&#8217;m not saying that you have to do it that way, but it&#8217;s a choice you&#8217;re making. In for a penny, in for a pound.</p>\n<p>In summary, here are some options when you encounter an abandoned mutex:</p>\n<ul>\n<li>Try to fix the problem.</li>\n<li>Ignore the problem.</li>\n<li>Give up and create a warning to others.</li>\n<li><span style=\"text-decoration: line-through;\">Give up and make everybody else think that everything is fine</span>.</li>\n</ul>\n<p>The final choice doesn&#8217;t make sense, because if you&#8217;re going to make everybody else think that everything is fine, then that&#8217;s the same as having everybody else simply ignore the problem. In which case, you may as well ignore the problem too!</p>\n<p><b>Related reading</b>: <a title=\"Understanding the consequences of WAIT_ABANDONED\" href=\"https://devblogs.microsoft.com/oldnewthing/20050912-14/?p=34253\"> Understanding the consequences of WAIT_ABANDONED</a>.</p>\n<p><b>Bonus chatter</b>: Don&#8217;t forget that if you get <code>WAIT_<wbr />ABANDONED</code>, the mutex <i>is owned by you</i>, so make sure to release it.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/oldnewthing/20260209-00/?p=112049\">What should I do if a wait call reports &lt;CODE&gt;WAIT_&lt;WBR&gt;ABANDONED&lt;/CODE&gt;?</a> appeared first on <a href=\"https://devblogs.microsoft.com/oldnewthing\">The Old New Thing</a>.</p>\n",
    "description": "It's your one chance to make amends. The post What should I do if a wait call reports &lt;CODE&gt;WAIT_&lt;WBR&gt;ABANDONED&lt;/CODE&gt;? appeared first on The Old New Thing.",
    "is_fulltext": true,
    "source": "The Old New Thing",
    "pub_date": "Mon, 09 Feb 2026 15:00:00 +0000",
    "fetched_at": "2026-02-10T00:44:33.702802",
    "url_hash": "27ff23a9e684f09cb6da567f7c813bbb"
  },
  {
    "title": "A Brief History of App Icons From Apple’s Creator Studio",
    "link": "https://blog.jim-nielsen.com/2026/history-of-creator-studio-icons/",
    "content": "<p>I recently updated <a href=\"https://www.macosicongallery.com\" >my collection of macOS icons</a> to include Apple’s new <a href=\"https://www.apple.com/apple-creator-studio/\" >“Creator Studio”</a> family of icons.</p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-icon-gallery.png\" width=\"756\" height=\"510\" alt=\"\" />\n\n</p><p>Doing this — in tandem with seeing funny things like <a href=\"https://mastodon.social/@heliographe_studio/115890819509545391\" >this post on Mastodon</a> — got me thinking about the history of these icons.</p>\n<p><a href=\"https://blog.jim-nielsen.com/2025/comparing-icons-in-my-collection/\" >I built</a> a feature on my icon gallery sites that’s useful for comparing icons over time. For example, <a href=\"https://www.macosicongallery.com/apps/409183694/compare/\" >here’s Keynote</a>:</p>\n<p><video controls src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-keynote-compare.mp4\" width=\"548\" height=\"750\"></video></p>\n<p>(Unfortunately, the newest Keynote isn’t part of that collection because I have them linked in my data by their App Store ID and it’s not the same ID anymore for the Creator Studio app — I’m going to have to look at addressing that somehow so they all show up together in my collection.)</p>\n<p>That’s one useful way of looking at these icons. But I wanted to see them side-by-side, so I dug them all up.</p>\n<p>Now, <a href=\"https://www.macosicongallery.com\" >my collection of macOS icons</a> isn’t complete. It doesn’t show every variant since the beginning of time, but it’s still interesting to see what’s changed within my own collection.</p>\n<p>So, without further ado, I present the variants in my collection. The years labeled in the screenshots represent the year in which I added the to my collection (not necessarily the year that Apple changed them).</p>\n<p>For convenience, I’ve included a link to the screenshot of icons as they exist in my collection (<a href=\"https://blog.jim-nielsen.com/2025/transform-html-with-edge-functions/\" >how I made that page</a>, if you’re interested).</p>\n<p><a href=\"https://www.macosicongallery.com/lookup/?id=keynote-design-presentations-2026-02-04&id=keynote-2021-11-15&id=keynote-2020-12-10&id=keynote-2015-04-14&id=keynote-2014-09-22\" >Keynote:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-keynote.png\" width=\"832\" height=\"197\" alt=\"A horizontal row of Apple Keynote app icons from different years—2014, 2015, 2020, 2021, and 2026—showing the evolution of the blue presentation podium icon from a detailed lectern to a simplified, abstract symbol.\" data-og-image />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=pages-create-documents-2026-02-04&id=pages-2021-11-15&id=pages-2020-12-10&id=pages-2015-04-14&id=pages-2014-09-22\" >Pages:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-pages.png\" width=\"832\" height=\"215\" alt=\"A horizontal row of Apple Pages app icons labeled 2014, 2015, 2020, 2021, and 2026, showing the evolution from a detailed pen-on-document icon to a simplified, abstract pen symbol on an orange background.\" />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=numbers-make-spreadsheets-2026-02-04&id=numbers-2021-11-15&id=numbers-2020-12-10&id=numbers-2015-04-14\" >Numbers:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-numbers.png\" width=\"672\" height=\"215\" alt=\"A horizontal row of Apple Numbers app icons labeled 2015, 2020, 2021, and 2026, showing the evolution from a detailed multicolored bar chart on a grid to a simplified, abstract green bar chart symbol.\" />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=final-cut-pro-create-video-2026-02-04&id=final-cut-pro-2025-11-10&id=final-cut-pro-2020-12-10&id=final-cut-pro-2015-04-14&id=final-cut-pro-2012-10-09\" >Final Cut Pro:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-final-cut.png\" width=\"832\" height=\"215\" alt=\"A horizontal row of Apple Final Cut app icons labeled 2012, 2015, 2020, 2025, and 2026, showing the evolution from a detailed clapperboard with a colorful light burst to a simplified purple clapperboard symbol.\" />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=compressor-encode-media-2026-02-04&id=compressor-2020-12-10&id=compressor-2015-04-14&id=compressor-2011-11-21\" >Compressor:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-compressor.png\" width=\"672\" height=\"215\" alt=\"A horizontal row of Apple Compressor app icons labeled 2011, 2015, 2020, and 2026, showing the evolution from a detailed metallic clamp over film strips to a simplified, abstract golden compression symbol.\" />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=logic-pro-make-music-2026-02-04&id=logic-pro-2020-12-10&id=logic-pro-x-2015-04-14&id=logic-pro-x-2013-07-26\" >Logic Pro:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-logic-pro.png\" width=\"672\" height=\"215\" alt=\"A horizontal row of Apple Logic Pro app icons labeled 2013, 2015, 2020, and 2026, showing the evolution from a realistic metallic dial on a dark interface to a simplified, abstract blue control knob symbol.\" />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=motion-animate-effects-2026-02-04&id=motion-2020-12-10&id=motion-2015-04-14&id=motion-2013-05-22\" >Motion:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-motion.png\" width=\"672\" height=\"215\" alt=\"A horizontal row of Apple Motion app icons labeled 2013, 2015, 2020, and 2026, showing the evolution from a detailed, metallic orbital graphic around a color wheel to a simplified, abstract magenta motion symbol.\" />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=mainstage-perform-live-2026-02-04&id=mainstage-2020-12-10&id=mainstage-3-2015-03-13&id=mainstage-2012-10-09&\" >MainStage:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-main-stage.png\" width=\"672\" height=\"215\" alt=\"A horizontal row of Apple MainStage app icons labeled 2012, 2015, 2020, and 2026, showing the evolution from a detailed concert pass with a guitarist silhouette to a simplified, abstract teal stage-control symbol.\" />\n\n</p><p><a href=\"https://www.macosicongallery.com/lookup?id=pixelmator-pro-edit-images-2026-02-04&id=pixelmator-pro-2021-03-10&id=pixelmator-pro-2018-01-19&id=pixelmator-2015-03-13&id=pixelmator-2012-08-13\" >Pixelmator Pro:</a></p>\n<p class=\"image-container\"><img src=\"https://cdn.jim-nielsen.com/blog/2026/macos-icon-history-pixelmator.png\" width=\"832\" height=\"215\" alt=\"A horizontal row of Pixelmator app icons labeled 2012, 2015, 2018, 2021, and 2026, showing the evolution from a photo-and-brush motif to a simplified, abstract layered-shapes symbol on a red background.\" />\n\n</p><p>(Granted, Pixelmator wasn’t one of Apple’s own apps until recently but its changes follow the same pattern showing how Apple sets the tone for itself as well as the ecosystem.)</p>\n<p>One last non-visual thing I noticed while looking through these icons in my archive. Apple used to call their own apps in the App Store by their name, e.g. “Keynote”. But now Apple seems to have latched on to what the ecosystem does by attaching a description to the name of the app, e.g. “Keynote: Design Presentations”.</p>\n<ul>\n<li>Keynote -&gt; Keynote: Design Presentations</li>\n<li>Pages -&gt; Pages: Create Documents</li>\n<li>Numbers -&gt; Numbers: Make Spreadsheets</li>\n<li>Final Cut Pro -&gt; Final Cut Pro: Create Video</li>\n<li>Compressor -&gt; Compressor: Encode Media</li>\n<li>Logic Pro -&gt; Logic Pro: Make Music</li>\n<li>MainStage -&gt; MainStage: Perform Live</li>\n<li>Pixelmator Pro -&gt; Pixelmator Pro: Edit Images</li>\n</ul>\n\n    <hr />\n    \n\n    <p>\n      Reply via:\n      \n\n      <a\n        href=\"mailto:jimniels%2Bblog@gmail.com?subject=Re:%20blog.jim-nielsen.com/2026/history-of-creator-studio-icons/\"\n        >Email</a\n      >\n      · <a href=\"https://mastodon.social/@jimniels\">Mastodon</a> ·\n\n      <a href=\"https://bsky.app/profile/jim-nielsen.com\">Bluesky</a>\n    </p>\n\n    \n  ",
    "description": "I recently updated my collection of macOS icons to include Apple’s new “Creator Studio” family of icons. Doing this — in tandem with seeing funny things like this post on Mastodon — got me thinking about the history of these icons. I built a feature on my icon gallery sites that’s useful for comparing icons over time. For example, here’s Keynote: (Unfortunately, the newest Keynote isn’t part of that collection because I have them linked in my data by their App Store ID and it’s not the same ID a",
    "is_fulltext": true,
    "source": "Jim Nielsen’s Blog",
    "pub_date": "Mon, 09 Feb 2026 19:00:00 GMT",
    "fetched_at": "2026-02-10T00:45:05.037377",
    "url_hash": "c5cf9abf2e2759b947a5b497123ddb1e"
  },
  {
    "title": "GitButler CLI Is Really Good",
    "link": "https://matduggan.com/gitbutler-cli-is-really-good/",
    "content": "<p>My workflow has remained mostly the same for over a decade. I write everything in Vim using the configuration found <a href=\"https://github.com/braintreeps/vim_dotfiles\" rel=\"noreferrer\">here</a>. I run Vim from inside of tmux with a configuration found <a href=\"https://github.com/braintreeps/vim_dotfiles/blob/master/tmux_example.conf\" rel=\"noreferrer\">here</a>. I write things on a git branch, made with the <code>git</code> CLI, then I add them with <code>git add --patch</code> to that branch, trying to run all of the possible linting and tests with <code>git hooks</code> before I waste my time on GitHub Actions. Then I run <code>git up</code> which is an alias to <code>pull --rebase --autostash</code>. Finally I successfully commit, then I copy paste the URL returned by GitHub to open a PR. Then I merge the PR and run <code>git ma</code> to go back to the primary branch, which is an alias to <code>ma = &quot;!f() {git checkout $(git primary) &amp;&amp;git pull;}; f&quot;</code>.</p><p>This workflow, I think, is pretty familiar for anyone working with GitHub a lot. Now you&apos;ll notice I&apos;m not saying <code>git</code> because almost nothing I&apos;m doing has anything to do with <code>git</code>. There&apos;s no advantage to my repo being local to my machine, because everything I need to actually merge and deploy code lives on GitHub. The CI runs there, the approval process runs there, the monitoring of the CI happens there, the injection of secrets happens there. If GitHub is down my local repo does, effectively, nothing. </p><p>My source of truth is always remote, which means I pay the price for <code>git</code> complexity locally but I don&apos;t benefit from it. At most jobs:</p><ul><li>You can&apos;t merge without GitHub (PRs are the merge mechanism)</li><li>You can&apos;t deploy without GitHub (Actions is the deployment trigger)</li><li>You can&apos;t get approval without GitHub (code review lives there)</li><li>Your commits are essentially &quot;drafts&quot; until they exist on GitHub</li></ul><p>This means the following is also true:</p><ul><li>You never work disconnected intentionally</li><li>You don&apos;t use local branches as long-lived divergent histories</li><li>You don&apos;t merge locally between branches (GitHub PRs handle this)</li><li>You don&apos;t use <code>git log</code> for archaeology &#x2014; you use GitHub&apos;s blame/history UI (I often use git log personally but I have determined I&apos;m in the minority on this). </li></ul><p>Almost all the features of <code>git</code> are wasted on me in this flow. Now because this tool serves a million purposes and is designed to operate in a way that almost nobody uses it for, we all pay the complexity price of <code>git</code> and never reap any of the benefits. So instead I keep having to add more aliases to paper over the shortcomings of <code>git</code>. </p><p>These are all the aliases I use at least once a week. </p><pre><code>[alias]\n  up = pull --rebase --autostash\n  l = log --pretty=oneline -n 20 --graph --abbrev-commit\n  # View the current working tree status using the short format\n  s = status -s\n  p = !&quot;git pull; git submodule foreach git pull origin master&quot;\n  ca = !git add -A &amp;&amp; git commit -av\n  # Switch to a branch, creating it if necessary\n  go = &quot;!f() { git checkout -b \\&quot;$1\\&quot; 2&gt; /dev/null || git checkout \\&quot;$1\\&quot;; }; f&quot;\n  # Show verbose output about tags, branches or remotes\n  tags = tag -l\n  branches = branch -a\n  remotes = remote -v\n  dm = &quot;!git branch --merged | grep -v &apos;\\\\*&apos; | xargs -n 1 git branch -d&quot;\n  contributors = shortlog --summary --numbered\n  st = status\n  primary = &quot;!f() { \\\n    git branch -a | \\\n    sed -n -E -e &apos;/remotes.origin.ma(in|ster)$/s@remotes/origin/@@p&apos;; \\\n  }; f&quot;\n  # Switch to main or master, whichever exists, and update it.\n  ma = &quot;!f() { \\\n    git checkout $(git primary) &amp;&amp; \\\n    git pull; \\\n  }; f&quot;\n  mma = &quot;!f() { \\\n    git ma &amp;&amp; \\\n    git pull upstream $(git primary) --ff-only &amp;&amp; \\\n    git push; \\\n  }; f&quot;</code></pre><h3 id=\"enter-gitbutler-cli\">Enter GitButler CLI</h3><p><strong>Git&apos;s offline-first design creates friction for online-first workflows, and GitButler CLI eliminates that friction by being honest about how we actually work.</strong></p><p>(Edit: I forgot to add this disclaimer. I am not, nor have ever been an employee/investor/best friends with anyone from GitButler. They don&apos;t care that I&apos;ve written this and I didn&apos;t communicate with anyone from that team before I wrote this.)</p><p>So let&apos;s take the most basic command as an example. This is my flow that I do 2-3 times a day without my aliases. </p><pre><code>git checkout main\ngit pull\ngit checkout -b my-feature\n# or if you&apos;re already on a branch:\ngit pull --rebase --autostash \ngit status</code></pre><p>I do this because <code>git</code> can&apos;t make assumptions about the state of the world. </p><ul><li>Your local repo might be offline for days or weeks</li><li>The &quot;remote&quot; might be someone else&apos;s laptop, not a central server</li><li>Divergent histories are expected and merging is a deliberate, considered act</li></ul><p>However because GitButler is designed with the assumption that I&apos;m working online, we can skip a lot of this nonsense. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-8.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1586\" height=\"488\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-8.png 600w, https://matduggan.com/content/images/size/w1000/2026/02/image-8.png 1000w, https://matduggan.com/content/images/2026/02/image-8.png 1586w\" sizes=\"(min-width: 720px) 720px\"></figure><p>It&apos;s status command understands that there is always a remote main that I care about and that when I run a status that I need to understand my status <em>relative</em> to the remote main as it exists right now. Not how it existed the last time I remembered to pull. </p><p>However this is far from the best trick it has up its sleeve. </p><h2 id=\"parallel-branches-the-problem-git-cant-solve\"><strong>Parallel Branches: The Problem Git Can&apos;t Solve</strong></h2><p>You&apos;re working on a feature, notice an unrelated bug, and now you have to stash, checkout, fix, commit, push, checkout back, stash pop. Context switching is expensive and error-prone. </p><p>GitButler effectively hacks a solution into <code>git</code> that fixes this with multiple branches applied simultaneously. Assign files to different branches without leaving your workspace. What do I mean by that. Let&apos;s start again with my status </p><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-9.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1582\" height=\"482\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-9.png 600w, https://matduggan.com/content/images/size/w1000/2026/02/image-9.png 1000w, https://matduggan.com/content/images/2026/02/image-9.png 1582w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Great looks good. Alright so lets say I make 2 new branches. I&apos;m working on a new feature for adding auth and while I&apos;m working on that, I see a typo I need to fix in a YAML. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-10.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1586\" height=\"912\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-10.png 600w, https://matduggan.com/content/images/size/w1000/2026/02/image-10.png 1000w, https://matduggan.com/content/images/2026/02/image-10.png 1586w\" sizes=\"(min-width: 720px) 720px\"></figure><p>I can work on both things at the same time:</p><pre><code>but stage istar_metrics_text.py feature-auth\nbut stage example.txt bugfix-typo</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-11.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1590\" height=\"804\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-11.png 600w, https://matduggan.com/content/images/size/w1000/2026/02/image-11.png 1000w, https://matduggan.com/content/images/2026/02/image-11.png 1590w\" sizes=\"(min-width: 720px) 720px\"></figure><p>And easily commit to both at the same time without doing <em>anything weird</em>. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-12.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1588\" height=\"946\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-12.png 600w, https://matduggan.com/content/images/size/w1000/2026/02/image-12.png 1000w, https://matduggan.com/content/images/2026/02/image-12.png 1588w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"stacked-prs-without-the-rebase-nightmare\">Stacked PRs Without the Rebase Nightmare</h3><p>Stacked PRs are the &quot;right&quot; way to break up large changes so people on your team don&apos;t throw up at being asked to review 2000 lines, but Git makes them miserable. When the base branch gets feedback, you have to rebase every dependent branch, resolve conflicts, force-push, and pray. Git doesn&apos;t understand branch dependencies. It treats every branch as independent, so <em>you</em> have to manually maintain the stack.</p><p>GitButler solves this problem with First-class stacked branches. The dependency is explicit, and updates propagate automatically.</p><p>So what do I mean. Let&apos;s say I make a new API endpoint in some Django app. First I make the branch. </p><pre><code>but branch new api-endpoints\n# Then add my stuff to it\nbut commit -m &quot;add REST endpoints&quot; api-endpoints\n# Create a stacked branch on top\nbut branch new --anchor api-endpoints api-tests\n</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-14.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"630\" height=\"216\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-14.png 600w, https://matduggan.com/content/images/2026/02/image-14.png 630w\"></figure><p>So let&apos;s say I&apos;m working on the <code>api-endpoints</code> branch and get some good feedback on my PR. It&apos;s easy to resolve the comments there while leaving my <code>api-tests</code> branched off this <code>api-endpoints</code> as a stacked thing that understands the relationship back to the first branch as shown here. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-15.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"762\" height=\"276\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-15.png 600w, https://matduggan.com/content/images/2026/02/image-15.png 762w\" sizes=\"(min-width: 720px) 720px\"></figure><p>In practice this is just a much nicer way of dealing with a super common workflow. </p><h3 id=\"easy-undo\">Easy Undo</h3><p>Maybe the most requested feature from new <code>git</code> users I encounter is an easier undo. When you mess up in Git, recovery means diving into <code>git reflog</code>, understanding the cryptic output, and hoping you pick the right <code>HEAD@{n}</code>. One wrong move and you&apos;ve made it worse.</p><p>GitButlers <code>oplog</code> is just easier to use. So the basic undo functionality is super simple to understand. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-16.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"896\" height=\"388\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-16.png 600w, https://matduggan.com/content/images/2026/02/image-16.png 896w\" sizes=\"(min-width: 720px) 720px\"></figure><p><code>but undo</code> rolls me back one operation. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://matduggan.com/content/images/2026/02/image-17.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1104\" height=\"558\" srcset=\"https://matduggan.com/content/images/size/w600/2026/02/image-17.png 600w, https://matduggan.com/content/images/size/w1000/2026/02/image-17.png 1000w, https://matduggan.com/content/images/2026/02/image-17.png 1104w\" sizes=\"(min-width: 720px) 720px\"></figure><p>To me the mental model of a snapshot makes a lot more sense than the git history model. I do an action, I want to undo that action. This is better than the git option of:</p><pre><code>git log --oneline                 # figure out what you committed\ngit reset --soft HEAD~1           # undo commit, keep changes staged\ngit stash                         # stash the changes\ngit checkout correct-branch       # switch branches\ngit stash pop                     # restore changes (hope no conflict)\ngit add .                         # re-stage\ngit commit -m &quot;message&quot;           # recommit</code></pre><h3 id=\"very-exciting-tool\">Very exciting tool</h3><p>I&apos;ve been using GitButler in my daily work since I got the email that the CLI was available and I&apos;ve really loved it. I&apos;m a huge fan of what this team is doing to effectively remodel and simplify Git operations in a world where almost nobody is using it in the way the tool was originally imagined to be used. I strongly encourage folks go check it out for free at: <a href=\"https://docs.gitbutler.com/cli-guides/cli-tutorial/tutorial-overview\">https://docs.gitbutler.com/cli-guides/cli-tutorial/tutorial-overview</a>. It does a ton of things (like help you manage PRs) that I didn&apos;t even touch on here. </p><p>Let me know if you find something cool that I forgot at: <a href=\"https://c.im/@matdevdug\">https://c.im/@matdevdug</a></p>",
    "description": "My workflow has remained mostly the same for over a decade. I write everything in Vim using the configuration found here. I run Vim from inside of tmux with a configuration found here. I write things on a git branch, made with the git CLI, then I add them with",
    "is_fulltext": true,
    "source": "matduggan.com",
    "pub_date": "Mon, 09 Feb 2026 12:33:02 GMT",
    "fetched_at": "2026-02-10T00:45:18.458500",
    "url_hash": "73aab2912c763216104fbc6d39f65fe7"
  }
]