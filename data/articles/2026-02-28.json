[
  {
    "title": "Please, please, please stop using passkeys for encrypting user data",
    "link": "https://simonwillison.net/2026/Feb/27/passkeys/#atom-everything",
    "content": "\n    \n<p><strong><a href=\"https://blog.timcappalli.me/p/passkeys-prf-warning/\">Please, please, please stop using passkeys for encrypting user data</a></strong></p>\nBecause users lose their passkeys <em>all the time</em>, and may not understand that their data has been irreversibly encrypted using them and can no longer be recovered.</p>\n<p>Tim Cappalli:</p>\n<blockquote>\n<p>To the wider identity industry: <em>please stop promoting and using passkeys to encrypt user data. I’m begging you. Let them be great, phishing-resistant authentication credentials</em>.</p>\n</blockquote>\n\n    <p><small></small>Via <a href=\"https://lobste.rs/s/tf8j5h/please_stop_using_passkeys_for\">lobste.rs</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/security\">security</a>, <a href=\"https://simonwillison.net/tags/usability\">usability</a>, <a href=\"https://simonwillison.net/tags/passkeys\">passkeys</a></p>\n\n\n\n",
    "description": "Please, please, please stop using passkeys for encrypting user data Because users lose their passkeys all the time, and may not understand that their data has been irreversibly encrypted using them and can no longer be recovered. Tim Cappalli: To the wider identity industry: please stop promoting and using passkeys to encrypt user data. I’m begging you. Let them be great, phishing-resistant authentication credentials. Via lobste.rs Tags: security, usability, passkeys",
    "is_fulltext": false,
    "source": "Simon Willison's Weblog",
    "pub_date": "2026-02-27T22:49:32+00:00",
    "fetched_at": "2026-02-28T00:33:18.385445",
    "url_hash": "a844e88e10e391f9ed94c76aa9cded7f"
  },
  {
    "title": "Upgrading my Open Source Pi Surveillance Server with Frigate",
    "link": "https://www.jeffgeerling.com/blog/2026/upgrading-my-open-source-pi-surveillance-server-frigate/",
    "content": "<p>In 2024 I built a <a href=\"https://www.jeffgeerling.com/blog/2024/building-pi-frigate-nvr-axzezs-interceptor-1u-case/\">Pi Frigate NVR with Axzez's Interceptor 1U Case</a>, and installed it in my 19&quot; rack. Using a Coral TPU for object detection, it's been dutifully surveilling my property—on <em>my</em> terms (100% local, no cloud integration or account required).</p>\n<figure class=\"insert-image\"><img src=\"https://www.jeffgeerling.com/blog/2026/upgrading-my-open-source-pi-surveillance-server-frigate/exaviz-cruiser-mini-rack-enclosure-with-annke-camera.jpeg\"\n alt=\"Exaviz Cruiser CM5 carrier board inside DeskPi mini rack enclosure with Annke 4K camera on top\" width=\"700\" height=\"auto\">\n</figure>\n\n<p>I've wanted to downsize the setup while keeping <del>cheap</del> large hard drives<sup id=\"fnref:1\"><a href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\">1</a></sup>, and an AI accelerator.</p>",
    "description": "In 2024 I built a Pi Frigate NVR with Axzez's Interceptor 1U Case, and installed it in my 19&quot; rack. Using a Coral TPU for object detection, it's been dutifully surveilling my property—on my terms (100% local, no cloud integration or account required). I've wanted to downsize the setup while keeping cheap large hard drives1, and an AI accelerator.",
    "is_fulltext": false,
    "source": "Jeff Geerling",
    "pub_date": "Fri, 27 Feb 2026 09:00:00 -0600",
    "fetched_at": "2026-02-28T00:33:18.753474",
    "url_hash": "457a677435686c86142e96aea33917d5"
  },
  {
    "title": "West Virginia’s Anti-Apple CSAM Lawsuit Would Help Child Predators Walk Free",
    "link": "https://www.techdirt.com/2026/02/25/west-virginias-anti-apple-csam-lawsuit-would-help-child-predators-walk-free/",
    "content": "\n<p>Mike Masnick, writing for Techdirt:</p>\n\n<blockquote>\n  <p>Read that again. If West Virginia wins — if an actual court\norders Apple to start scanning iCloud for CSAM — then every\nimage flagged by those mandated scans becomes <em>evidence obtained\nthrough a warrantless government search conducted without\nprobable cause</em>. The Fourth Amendment’s exclusionary rule means\ndefense attorneys get to walk into court and demand that evidence\nbe thrown out. And they’ll win that motion. It’s not even a\nparticularly hard case to make.</p>\n</blockquote>\n\n<div>\n<a  title=\"Permanent link to ‘West Virginia’s Anti-Apple CSAM Lawsuit Would Help Child Predators Walk Free’\"  href=\"https://daringfireball.net/linked/2026/02/27/west-virginia-apple-csam\">&nbsp;★&nbsp;</a>\n</div>\n\n\t",
    "description": "",
    "is_fulltext": true,
    "source": "Daring Fireball",
    "pub_date": "2026-02-27T19:28:44Z",
    "fetched_at": "2026-02-28T00:33:19.919114",
    "url_hash": "7b61cc64bb1286d02f25b7ac0c6a3964"
  },
  {
    "title": "We Need Process, But Process Gets in the Way",
    "link": "https://idiallo.com/blog/when-process-get-in-the-way?src=feed",
    "content": "\n\t\t\t\t\t\n\t\t\t<p>How do you manage a company with 50,000 employees? You need processes that give you visibility and control across every function such as technology, logistics, operations, and more. But the moment you try to create a single process to govern everyone, it stops working for anyone.</p>\n\t\t\t<p>One system can't cater to every team, every workflow, every context. When implemented you start seeing in-fighting, projects missing deadlines, people quitting. Compromises get made, and in my experience, it almost always becomes overwhelming.</p>\n\n<p>The first time I was part of a merger, I was naïve about how it would go. The narrative we were sold was reassuring. The larger company was acquiring us because we were successful. The last thing they'd want to do was get in the way of that success. But that's not how it went.</p>\n\n<p>It doesn't matter what made you successful before you join a larger organization. The principles and processes of the acquiring company are what will dominate. Your past success is acknowledged, maybe even celebrated, but it doesn't protect you from assimilation.</p>\n\n<p>One of the first things we had to adopt was Scrum. It may be standard practice now, but at the time it was still making its way through the industry. Our team, developers and product managers, already had a process that worked. We knew how to communicate, how to prioritize, how to ship. Adopting this new set of ceremonies felt counterproductive. It didn't make us faster. It didn't improve communication. What it did do was increase administrative overhead. Standups, sprints, retrospectives, layer after layer of structure added on top of work that was already getting done.</p>\n\n<p>But there was no going back. We were never going to return to being that nimble, ad hoc team that could resolve issues quickly and move on. We had to adopt methods that got in the way.</p>\n\n<p>Eventually, we adapted. We adopted the process. And in doing so, we became less efficient at the local level. A lot of people, frustrated by the slowdown, left for other opportunities.</p>\n\n<p>But as far as the larger company was concerned, that was acceptable. Our product was just one of many in their portfolio. Slowing down one team to get everyone aligned was a price they were willing to pay. It wasn't efficient, but it was manageable from their perspective. The math made sense at the organizational level, even if it felt like a loss from where we were standing.</p>\n\n<p>I understand that logic. I just don't think it's the best way forward.</p>\n\n<div class=\"image\">\n  <img src=\"https://cdn.idiallo.com/images/assets/624/cpu.jpg\" alt=\"CPU\" copyright=\"Pixabay CC0\" />\n</div>\n\n<p>Think about how a computer works. A CPU doesn't concern itself with how a hard drive retrieves data. Whether it's spinning magnetic disks or a solid state drive, the internal mechanics are irrelevant to the CPU. All it knows is that it can make a request, and the response will come back in the expected format. If the CPU had to get involved in the actual process of fetching data, it would waste enormous processing power on something that isn't its concern.</p>\n\n<p>Organizations can work the same way.</p>\n\n<p>Rather than imposing a single process across every team, a company can treat its departments as independent components. You make a request, the department delivers an output. How they produce that output like what tools they use, how they run their meetings, how they structure their work, that shouldn't be a concern, as long as the result meets the requirement.</p>\n\n<p>There are places where unified processes make sense. Legal and compliance, for example, probably need to be consistent across the whole organization. But for how individual teams operate day to day, autonomy is often the better choice. Will every team's process be perfectly aligned with every other team's? No. But they'll actually work. And the people doing the work will be far less likely to walk out the door.</p>\n\n<p>Sometimes in large organizations, it's important to identify which process works, and which team is better left alone.</p>\n\t\t\t\n\t\t\t\t",
    "description": "How do you manage a company with 50,000 employees? You need processes that give you visibility and control across every function such as technology, logistics, operations, and more. But the moment you try to create a single process to govern everyone, it stops working for anyone. One system can't cater to every team, every workflow, every context. When implemented you start seeing in-fighting, projects missing deadlines, people quitting. Compromises get made, and in my experience, it almost alwa",
    "is_fulltext": true,
    "source": "iDiallo.com",
    "pub_date": "Fri, 27 Feb 2026 12:00:00 GMT",
    "fetched_at": "2026-02-28T00:33:23.647364",
    "url_hash": "90ca3a0ae816e2516810f5c1f5630d11"
  },
  {
    "title": "Book Review: Weird Things Customers Say in Bookshops by Jen Campbell ★★☆☆☆",
    "link": "https://shkspr.mobi/blog/2026/02/book-review-weird-things-customers-say-in-bookshops-by-jen-campbell/",
    "content": "<img src=\"https://shkspr.mobi/blog/wp-content/uploads/2026/03/1366054116.webp\" alt=\"Book cover\" width=\"200\" class=\"alignleft size-full wp-image-66622\">\n\n<p>Remember back in the early 2010s when any moderately popular Twitter account could become a book (or even a <a href=\"https://en.wikipedia.org/wiki/Shit_My_Dad_Says\">TV series</a>)?</p>\n\n<p>This is a collection of Tweet-sized \"overheard in\" stories. All set in book shops.</p>\n\n<p>Isn't it funny that some people don't know how books work! ROFL!</p>\n\n<p>Aren't the general public strange? LOLOL!</p>\n\n<p>That's a bit harsh of me. It only rarely becomes mean-spirited. But in a book this short, it rather contaminates the joy.</p>\n\n<p>That said, this one will live rent-free in my head for a while:</p>\n\n<blockquote><p>Did Beatrix Potter ever write a book about dinosaurs?</p></blockquote>\n\n<p>It's the sort of stocking-filler book which is reasonable for perusing on the loo. Light-hearted but ultimately disposable.</p>\n\n<p>Still, at least Neil Gaiman found it funny enough to leave a blurb…</p>\n",
    "description": "Remember back in the early 2010s when any moderately popular Twitter account could become a book (or even a TV series)? This is a collection of Tweet-sized &#34;overheard in&#34; stories. All set in book shops. Isn&#039;t it funny that some people don&#039;t know how books work! ROFL! Aren&#039;t the general public strange? LOLOL! That&#039;s a bit harsh of me. It only rarely becomes mean-spirited. But in a book this…",
    "is_fulltext": true,
    "source": "Terence Eden’s Blog",
    "pub_date": "Fri, 27 Feb 2026 12:34:11 +0000",
    "fetched_at": "2026-02-28T00:33:27.877622",
    "url_hash": "e1f938d9e4c107a03007df4fccc3ff1c"
  },
  {
    "title": "Intercepting messages inside Is­Dialog­Message, fine-tuning the message filter",
    "link": "https://devblogs.microsoft.com/oldnewthing/20260227-00/?p=112094",
    "content": "<p>Last time, we <a title=\"Intercepting messages inside Is­Dialog­Message, installing the message filter\" href=\"https://devblogs.microsoft.com/oldnewthing/20260226-00/?p=112090\"> used a <code>MSGF_<wbr />DIALOG­BOX</code> message filter</a> to hook into the <code>Is­Dialog­Message</code> so that we had the option to grab the <kbd>ESC</kbd> before it gets turned into an <code>IDCANCEL</code>. There are some problems with our initial foray.</p>\n<p>One is the problem of recursive dialogs. If the first dialog shows another copy of itself (for example, a certificate dialog showing a dialog for its parent certificate), then the thread-local variable gets overwritten, and the first dialog&#8217;s information is lost.</p>\n<p>We could solve that by having each dialog remember the original value and restore it when the dialog dismisses. Alternatively, we could maintain an explicit stack of dialogs, pushing when a new dialog is created and popping when it is destroyed.</p>\n<p>However, this fails to handle the case where the dialog is modeless. In that case, the two dialogs could be running concurrently rather than recursively. Instead of a stack, we really need a per-thread <i>set</i> of active dialogs.</p>\n<p>Another thing to worry about is that if this code is put into a static library, and two components in the same thread both use that static library, then you have to be careful that the two copies of the library don&#8217;t conflict with each other.</p>\n<p>I came up with this initial idea:</p>\n<pre>#define DIALOG_WANTS_ESC_PROP TEXT(\"DialogWantsEsc\")\n\nLRESULT CALLBACK DialogEscHookProc(int nCode, WPARAM wParam, LPARAM lParam)\n{\n    if (nCode == MSGF_DIALOGBOX) {\n        auto msg = (MSG*)lParam;\n        if (msg-&gt;message == WM_KEYDOWN &amp;&amp;\n            msg-&gt;wParam == VK_ESCAPE) {\n            auto hdlg = GetAncestor(msg-&gt;hwnd, GA_ROOT);\n            auto customMessage = PtrToUint(GetProp(hdlg,\n                                           DIALOG_WANTS_ESC_PROP));\n            if (customMessage &amp;&amp;\n                !(SendMessage(msg-&gt;hwnd, WM_GETDLGCODE,\n                             msg-&gt;wParam, lParam) &amp;\n                         (DLGC_WANTALLKEYS | DLGC_WANTMESSAGE))) {\n                return SendMessage(hdlg, customMessage, 0, lParam);\n            }\n        }\n    }\n    return CallNextHookEx(nullptr, nCode, wParam, lParam);\n}\n</pre>\n<p>The idea here is that instead of having to manage a table of per-thread registrations, we just let dialogs self-register by setting the <code>DIALOG_<wbr />WANTS_<wbr />ESC_<wbr />PROP</code> property to the message number they want to receive when the user presses <kbd>ESC</kbd>.</p>\n<p>If there are two copies of this hook installed, then the <code>Dialog­Esc­Hook­Proc</code> is called twice. The first one sends the custom message and gets the dialog&#8217;s response, and returns it; it never passes the message down the hook chain. Therefore, the second and subsequent hooks never get to run, so we don&#8217;t have a problem of the custom message getting sent multiple times for the same call to <code>Is­Dialog­Message</code>.</p>\n<p>This design has the advantage that multiple DLLs using this pattern can coexist because the first hook (whichever it is) does all the work for everybody.</p>\n<p>An alternate, more complex, design would pass the call down the chain if the dialog box declined to handle the <kbd>ESC</kbd> key, in case some other hook wanted to do something special. The catch is that if there are multiple copies of this hook installed, each one will send the custom message to the dialog, which would be bad if the handler for the custom message had side effects like showing a confirmation dialog.</p>\n<p>So we can add the rule that the custom message must be safe to call multiple times if it returns <code>FALSE</code>. This means that if it wants to display a confirmation dialog, it should always return <code>TRUE</code> even if the user cancels.</p>\n<pre>LRESULT CALLBACK DialogEscHookProc(int nCode, WPARAM wParam, LPARAM lParam)\n{\n    if (code == MSGF_DIALOGBOX) {\n        auto msg = (MSG*)lParam;\n        if (msg-&gt;message == WM_KEYDOWN &amp;&amp;\n            msg-&gt;wParam == VK_ESCAPE) {\n            auto hdlg = GetAncestor(msg-&gt;hwnd, GA_ROOT);\n            auto customMessage = PtrToUInt(GetProp(hdlg,\n                                           DIALOG_WANTS_ESC_PROP));\n            if (customMessage &amp;&amp;\n                !(SendMessage(msg-&gt;hwnd, WM_GETDLGCODE,\n                             msg-&gt;wParam, msg) &amp;\n                         (DLGC_WANTALLKEYS | DLGC_WANTMESSAGE)) &amp;&amp;\n                 <span style=\"border: solid 1px currentcolor; border-bottom: none;\">SendMessage(hdlg, customMessage, 0, lParam)) {</span>\n                 <span style=\"border: solid 1px currentcolor; border-top: none;\">return TRUE;                                  </span>\n            }\n        }\n    }\n    return CallNextHookEx(nullptr, nCode, wParam, lParam);\n}\n</pre>\n<p>Or we can have the first hook leave a note for the other hooks that the message has already been handled and that they shouldn&#8217;t try to handle it again.</p>\n<pre>#define DIALOG_WANTS_ESC_PROP TEXT(\"DialogWantsEsc\")\n#define CURRENT_MESSAGE_PROP TEXT(\"DialogWantsEscCurrentMessage\")\n\nLRESULT CALLBACK DialogEscHookProc(int nCode, WPARAM wParam, LPARAM lParam)\n{\n    if (code == MSGF_DIALOGBOX) {\n        auto msg = (MSG*)lParam;\n        if (msg-&gt;message == WM_KEYDOWN &amp;&amp;\n            msg-&gt;wParam == VK_ESCAPE) {\n            auto hdlg = GetAncestor(msg-&gt;hwnd, GA_ROOT);\n            auto customMessage = PtrToUInt(GetProp(hdlg,\n                                           DIALOG_WANTS_ESC_PROP));\n            if (customMessage) {\n                <span style=\"border: solid 1px currentcolor; border-bottom: none;\">auto previous = GetProp(hdlg, CURRENT_MESSAGE_PROP);</span>\n                <span style=\"border: solid 1px currentcolor; border-top: none;\">if (previous != msg &amp;&amp;                              </span>\n                    !(SendMessage(msg-&gt;hwnd, WM_GETDLGCODE,\n                                 msg-&gt;wParam, msg) &amp;\n                             (DLGC_WANTALLKEYS | DLGC_WANTMESSAGE))) {\n                    return SendMessage(hdlg, customMessage, 0, lParam);\n                }\n                <span style=\"border: solid 1px currentcolor; border-bottom: none;\">SetProp(hdlg, CURRENT_MESSAGE_PROP, msg);                     </span>\n                <span style=\"border: 1px currentcolor; border-style: none solid;\">auto result = CallNextHookEx(nullptr, nCode, wParam, lParam); </span>\n                <span style=\"border: 1px currentcolor; border-style: none solid;\">SetProp(hdlg, CURRENT_MESSAGE_PROP, previous);                </span>\n                <span style=\"border: solid 1px currentcolor; border-top: none;\">return result;                                                </span>\n            }\n        }\n    }\n    return CallNextHookEx(nullptr, nCode, wParam, lParam);\n}\n</pre>\n<p>The first hook will send the message to the dialog. and if the dialog declines to handle it, it passes the messages to the other hooks, but setes the &#8220;current message&#8221; property to the message that was already handled, so that other hooks won&#8217;t try to handle it again.</p>\n<p>The last part of the puzzle is installing the hook. Since we are assuming that we cannot alter the dialog loop, the hook has to be installed by the dialog itself.</p>\n<p>Let&#8217;s assume that this dialog box already allocates other dialog state, so we can add the hook handle to the state structure.</p>\n<pre>struct DIALOGSTATE\n{\n    wil::unique_hhook escapeHook;\n    ⟦ other stuff ⟧\n};\n\n// each dialog can choose its own custom message\n#define DM_ESCPRESSED (WM_USER+1000)\n\nINT_PTR CALLBACK DialogProc(HWND hdlg, UINT message, WPARAM wParam, LPARAM lParam)\n{\n    switch (message) {\n    case WM_INITDIALOG:\n        {\n            DIALOGSTATE* state = new(std:nothrow) DIALOGSTATE();\n            if (!state) { EndDialog(hdlg, -1); return FALSE; }\n            SetWindowLongPtr(hdlg, DWLP_USER, (LONG_PTR)state);\n            <span style=\"border: solid 1px currentcolor; border-bottom: none;\">state-&gt;escapeHook.reset(SetWindowsHookEx(WM_MSGFILTER,     </span>\n            <span style=\"border: 1px currentcolor; border-style: none solid;\">                 DialogEscHookProc,                        </span>\n            <span style=\"border: 1px currentcolor; border-style: none solid;\">                 nullptr, GetCurrentThreadId()));          </span>\n            <span style=\"border: 1px currentcolor; border-style: none solid;\">SetProp(hdlg, DIALOG_WANTS_ESC_PROP,                       </span>\n            <span style=\"border: solid 1px currentcolor; border-top: none;\">        IntToPtr(DM_ESCPRESSED));                          </span>\n            ⟦ other dialog initialization as before ⟧\n            ⟦ ending with \"return (whatever)\" ⟧\n        }\n\n    case DM_ESCPRESSED:\n        if (⟦ we want to process the ESC key ourselves ⟧) {\n            ⟦ do custom ESC key processing ⟧\n            SetWindowLongPtr(hdlg, DWLP_MSGRESULT, TRUE);\n            return TRUE;\n        }\n        break;\n\n    case WM_DESTROY:\n        {\n            auto state = (DLGSTATE*)GetWindowLongPtr(hdlg, DWLP_USER);\n            delete state;\n        }\n        break;\n\n    ⟦ handle other messages ⟧\n    }\n    return FALSE;\n}\n</pre>\n<p>The dialog installs the hook when it is created and removes it when it is destroyed. The hook has become an implementation detail of the dialog.</p>\n<p>Now, I don&#8217;t recommend doing all this. Better is to just treat with the <kbd>ESC</kbd> like any other press of the (possibly imaginary) Cancel button. One of the few scenarios I can think of where this could be useful is if you want to display an extra confimation for the Close button (since its meaning is potentially ambiguous). This is still nonstandard, but at least it&#8217;s not <i>too</i> nonstandard. And for that, you can just intercept <code>WM_CLOSE</code> instead of trying to intercept the <kbd>ESC</kbd>. Intercepting the <kbd>ESC</kbd> was really just an excuse to show off message filters, which tend to be unappreciated.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/oldnewthing/20260227-00/?p=112094\">Intercepting messages inside &lt;CODE&gt;Is&shy;Dialog&shy;Message&lt;/CODE&gt;, fine-tuning the message filter</a> appeared first on <a href=\"https://devblogs.microsoft.com/oldnewthing\">The Old New Thing</a>.</p>\n",
    "description": "Making sure it triggers when you need it, and not when you don't. The post Intercepting messages inside &lt;CODE&gt;Is&shy;Dialog&shy;Message&lt;/CODE&gt;, fine-tuning the message filter appeared first on The Old New Thing.",
    "is_fulltext": true,
    "source": "The Old New Thing",
    "pub_date": "Fri, 27 Feb 2026 15:00:00 +0000",
    "fetched_at": "2026-02-28T00:33:31.496803",
    "url_hash": "5dc8e376ba79ebb13ae7668dabc1afab"
  },
  {
    "title": "Premium: The Hater's Guide to Private Equity",
    "link": "https://www.wheresyoured.at/hatersguide-pe/",
    "content": "<p>We have a global intelligence crisis, in that a lot of people are being really fucking stupid.</p><p><a href=\"https://www.wheresyoured.at/on-nvidia-and-analyslop/\"><u>As I discussed in this week&#x2019;s free piece</u></a>, alleged financial analyst Citrini Research put out a truly awful screed called the &#x201C;2028 Global Intelligence Crisis&#x201D; &#x2014; a slop-filled scare-fiction written and framed with the authority of deeply-founded analysis, <a href=\"https://www.wsj.com/livecoverage/stock-market-today-dow-sp-500-nasdaq-tariffs-02-23-2026/card/software-stocks-are-having-another-ugly-day-LlAj9avDeFocxKHzVwRZ?ref=wheresyoured.at\"><u>so much so that it caused a global selloff in stocks</u></a>.&#xA0;</p><p>At 7,000 words, you&#x2019;d expect the piece to have some sort of argument or base in reality, but what it actually says is that &#x201C;AI will get so cheap that it will replace everything, and then most white collar people won&#x2019;t have jobs, and then they won&#x2019;t be able to pay their mortgages, also AI will cause private equity to collapse because AI will write all software.&#x201D;&#xA0;</p><p>This piece is written specifically to spook *and* ingratiate anyone involved in the financial markets with the idea that their investments are bad but investing in AI companies is good, and also that if they don&apos;t get behind whatever this piece is about (which is unclear!), they&apos;ll be subject to a horrifying future where the government creates a subsidy generated by a tax on AI inference (seriously). And, most damningly, its most important points about HOW this all happens are single sentences that read &quot;and then AI becomes more powerful and cheaper too and runs on a device.&quot;&#xA0;</p><p>Part of the argument is that AI agents will use cryptocurrency to replace MasterCard and Visa. It&#x2019;s dogshit. I&#x2019;m shocked that anybody took it seriously.</p><p>The fact this moved markets should suggest that we have a fundamentally flawed financial system &#x2014; and here&#x2019;s <a href=\"https://www.dropbox.com/scl/fi/1p1n0y1ip48ianok9dvbp/Annotation-The-Global-Intelligence-Crisis.pdf?rlkey=qaar8ea6l5hh6jqls4x6g8q4b&amp;e=1&amp;dl=0&amp;ref=wheresyoured.at\"><u>an annotated version</u></a> with my own comments.</p><p>This is the second time our markets have been thrown into the shitter based on AI booster hype. A mere week and a half ago, <a href=\"https://www.cnbc.com/2026/02/06/ai-anthropic-tools-saas-software-stocks-selloff.html?ref=wheresyoured.at\"><u>a software sell-off began because of the completely fanciful and imaginary idea that AI <em>would now write all software</em></u></a>.</p><p>I really want to be explicit here: AI does not threaten the majority of SaaS businesses, and they are jumping at ghost stories.&#xA0;</p><p>If I am correct, those dumping software stocks believe that AI will replace these businesses <em>because people will be able to code their own software solutions. </em>This is an intellectually bankrupt position, one that shows an alarming (and common) misunderstanding of very basic concepts. It is not just a matter of &#x201C;enough prompts until it does this&#x201D; &#x2014; good (or even functional!) software engineering is technical, infrastructural, and philosophical, and the thing you are &#x201C;automating&#x201D; is not just the code that makes a thing run.&#xA0;</p><p>Let&apos;s start with the simplest, and least-technical way of putting it: even in the best-case scenario, you do not just type &quot;Build Be A Salesforce Competitor&quot; and it erupts, fully-formed, from your Terminal window. It is not capable of <em>building it,</em> but even if it <em>were, </em>it would need to actually be on a cloud hosting platform, and have all manner of actual customer data entered into it. Building software is not writing code and then hitting enter and a website appears, requiring all manner of infrastructural things (such as &quot;how does a customer access it in a consistent and reliable way,&quot; &quot;how do I make sure that this can handle a lot of people at once,&quot; and &quot;is it quick to access,&quot; with the more-complex database systems requiring entirely separate subscriptions <em>just to keep them connecting</em>).&#xA0;</p><p>Software is a tremendous pain in the ass. You write code, then you have to make sure the code actually runs, and that code needs to run in some cases on specific hardware, and that hardware needs to be set up right, and some things are written in different languages, and those languages sometimes use more memory or less memory and if you give them the wrong amounts or forget to close the door in your code on something everything breaks, sometimes costing you money or introducing security vulnerabilities.&#xA0;</p><p>In any case, even for experienced, well-versed software engineers, maintaining software that involves any kind of customer data requires significant investments in compliance, including things like SOC-2 audits if the customer itself ever has to interact with the system, as well as massive investments in security.&#xA0;</p><p>And yet, the myth that LLMs are an existential threat to existing software companies has taken root in the market, sending the share prices of the legacy incumbents tumbling. A great example would be SAP, down 10% in the last month.&#xA0;</p><p>SAP makes ERP (Enterprise Resource Planning,<a href=\"https://www.wheresyoured.at/haters-guide-oracle/#erp-enterprise-resource-planning-%E2%80%94-lucrative-confusing-and-only-sometimes-functional\"> <u>which I wrote about in the Hater&apos;s Guide To Oracle</u></a>) software, and has been affected by the sell-off. SAP is also a massive, complex, resource-intensive database-driven system that involves things like accounting, provisioning and HR, and is so heinously complex that you often have to pay SAP just to make it function (if you&apos;re lucky it might even do so). If you were to build this kind of system yourself, even with &quot;the magic of Claude Code&quot; (which I will get to shortly), it would be an incredible technological, infrastructural and <strong><em>legal</em></strong> undertaking.&#xA0;</p><p>Most software is like this. I&#x2019;d say all software that people rely on is like this. I am begging with you, pleading with you to think about how much you trust the software that&#x2019;s on every single thing you use, and what you do when a piece of software stops working, and how you feel about the company that does that. If your money or personal information touches it, they&#x2019;ve had to go through all sorts of shit that doesn&#x2019;t involve the code to bring you the software.&#xA0;</p><blockquote><strong>Sidenote: </strong>I want to be clear that there is nothing <em>good</em> about this. To quote a friend of mine &#x2014; an editor at a large tech publication &#x2014; &#x201C;Oracle is a lawfirm with a software company attached.&#x201D; SaaS companies regularly get by through scurrilous legal means and bullshit contracts, and their features are, in many cases, only as good as they need to be. Regardless, my point is that you will not just &#x201C;make your own software.&#x201D;&#xA0;</blockquote><p>Any company of a reasonable size would likely be committing hundreds of thousands if not millions of dollars of legal and accounting fees to make sure it worked, engineers would have to be hired to maintain it, and you, as the sole customer of this massive ERP system, would have to build<strong> every single new feature and integration you want.</strong> Then you&apos;d have to keep it running, this massive thing that involves, in many cases, <em>tons of personally identifiable information. </em>You&apos;d also need to make sure, without fail, that this system that involves money was aware of any and all currencies and how they fluctuate, because that is now your problem. Mess up that part and your system of record could massively over or underestimate your revenue or inventory, which could destroy your business.</p><p>If that happens, you won&apos;t have anyone to sue. When bugs happen, you&apos;ll have someone who&apos;s job it is to fix it that you can fire, but replacing them will mean finding a new person to fix the mess that another guy made.&#xA0;</p><p>And then we get to the fact that building stuff with Claude Code is not that straightforward. Every example you&apos;ve read about somebody being amazed by it has built a toy app or website that&apos;s very similar to many open source projects or website templates that Anthropic trained its training data on. </p><p>Every single piece of SaaS anyone pays for is paying for both access to the product and a transfer of the inherent risk or chaos of running software that involves people or money. Claude Code does not actually build unique software. You can say &quot;create me a CRM,&quot; but whatever CRM it pops out will not magically jump onto Amazon Web Services, nor will it magically be efficient, or functional, or compliant, or secure, nor will it be differentiated at all from, I assume, the open source or publicly-available SaaS it was trained on. You really still need engineers, if not <em>more </em>of them than you had before.</p><p>It might tell you it&apos;s completely compliant and that it will run like a hot knife through butter &#x2014; but LLMs don&#x2019;t know anything, and you cannot be sure Claude is telling the truth as a result. Is your argument that you&#x2019;d still have a team of engineers (so they know what the outputs mean), but they&#x2019;d be working on replacing your SaaS subscription? You&#x2019;re basically becoming a startup with none of the benefits.&#xA0;</p><p>To quote Nik Suresh, an incredibly well-credentialed and respected software engineer (author of <a href=\"https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/?ref=wheresyoured.at\"><u>I Will Fucking Piledrive You If You Mention AI Again</u></a>), &#x201C;...for some engineers, [Claude Code] is a great way to solve certain, tedious problems more quickly, and the responsible ones understand you have to read most of the output, which takes an appreciable fraction of the time it would take to write the code in many cases. Claude doesn&apos;t write terrible code all the time, it&apos;s actually good for many cases because many cases are boring. You just have to read all of it if you aren&apos;t a fucking moron because it periodically makes company-ending decisions.&#x201D;</p><p>Just so you know, &#x201C;company-ending decisions&#x201D; could start with your vibe-coded Stripe clone leaking user credit card numbers or social security numbers because you asked it to &#x201C;just handle all the compliance stuff.&#x201D; Even if you have very talented engineers, are those engineers talented in the specifics of, say, healthcare data or finance? They&#x2019;re going to need to be to make sure Claude doesn&#x2019;t do anything <em>stupid</em>!&#xA0;</p><h1 id=\"the-intelligence-crisis-in-private-investing-and-private-equity\">The Intelligence Crisis In Private Investing and Private Equity</h1><p>So, despite all of this being <em>very obvious</em>, it&#x2019;s clear that the markets and an alarming number of people in the media<em> simply do not know what they are talking about.</em> The &#x201C;AI replaces software&#x201D; story is literally &#x201C;Anthropic has released a product and now the resulting industry is selling off,&#x201D; such as when it launched a cybersecurity tool that could check for vulnerabilities (a product that has existed in some form for nearly a decade) <a href=\"https://www.cnbc.com/2026/02/23/cybersecurity-stocks-anthropic-ai-crowdstrike.html?ref=wheresyoured.at\"><u>causing a sell-off in cybersecurity stocks like Crowdstrike</u></a> &#x2014; you know, <a href=\"https://www.wheresyoured.at/crowdstruck-2/\"><u>the one that had a faulty bit of code cause a global cybersecurity incident</u></a> that <a href=\"https://www.theguardian.com/technology/article/2024/jul/24/crowdstrike-outage-companies-cost?ref=wheresyoured.at\"><u>lost the Fortune 500 billions</u></a>, and <a href=\"https://www.bbc.co.uk/news/articles/c6284e7r7d7o?ref=wheresyoured.at\"><u>led to Delta Air Lines suspending over 1,200 flights over six long days of disruption</u></a>.&#xA0;</p><p>There is no rational basis for anything about this sell-off other than that our financial media and markets do not appear to understand the very basic things about the stuff they invest in. Software may <em>seem</em> complex, but (especially in these cases) it&#x2019;s really quite simple: investors are conflating &#x201C;an AI model can spit out code&#x201D; with &#x201C;an AI model can create the entire experience of what we know as &#x201C;software,&#x201D; or is close enough that we have to start freaking out.&#x201D;</p><p>This is thanks to the intentionally-deceptive marketing pedalled by Anthropic and validated by the media. In a piece from September 2025, <a href=\"https://archive.is/6mKsM?ref=wheresyoured.at\"><u>Bloomberg reported</u></a> that Claude Sonnet 4.5 could &#x201C;code on its own for up to 30 hours straight,&#x201D;&#xA0; <a href=\"https://arstechnica.com/ai/2025/09/anthropic-says-its-new-ai-model-maintained-focus-for-30-hours-on-multistep-tasks/?ref=wheresyoured.at\"><u>a statement directly from Anthropic repeated by other outlets</u></a> that added that it did so &#x201C;on complex, multi-step tasks,&#x201D; none of which were explained. The Verge, however, added that apparently Anthropic &#x201C;<a href=\"https://archive.is/yglfX?ref=wheresyoured.at\"><u>coded a chat app akin to Slack or Teams</u></a>,&#x201D; <strong>and no, you can&#x2019;t see it, or know anything about how much it costs or its functionality. </strong>Does it run? Is it useful? Does it work in any way? What does it look like? We have <strong>absolutely no proof this happened other than them saying it, but because the media repeated it it&#x2019;s now a fact.&#xA0;</strong></p><p>Perhaps it&#x2019;s not a particularly novel statement, but it&#x2019;s becoming kind of obvious that <em>maybe the people with the money don&#x2019;t actually know what they&#x2019;re doing, which will eventually become a problem when they all invest in the wrong thing for the wrong reasons.</em>&#xA0;</p><p>SaaS (Software as a Service, which almost always refers to business software) stocks became a hot commodity because they were perpetual growth machines with giant sales teams that existed <em>only to make numbers go up, </em>leading to a flurry of investment based on the assumption that<em> all numbers will always increase forever, and every market is as giant as we want. </em>Not profitable? No problem! You just had to show growth.</p><p>It was easy to raise money because everybody saw a big, obvious path to liquidity, either from selling to a big firm or taking the company public&#x2026;</p><p>&#x2026;in theory.&#xA0;</p><h1 id=\"how-private-equity-created-a-pump-and-dump-crisis-in-software-by-assuming-everything-would-grow-forever-%E2%80%94-and-everything-broke-in-2021\">How Private Equity Created A Pump-And-Dump Crisis In Software By Assuming Everything Would Grow Forever &#x2014; And Everything Broke In 2021</h1><p><a href=\"http://techcrunch.com/2017/11/30/theres-an-implosion-of-early-stage-vc-funding-and-no-ones-talking-about-it/?ref=wheresyoured.at\"><u>Per Victor Basta</u></a>, between 2014 and 2017, the number of VC rounds in technology companies halved with a much smaller drop in funding, adding that a big part was the collapse of companies describing themselves as SaaS, which dropped by 40% in the same period. In a 2016 chat with VC David Yuan, <a href=\"https://www.linkedin.com/pulse/private-equity-eating-saas-world-what-pe-means-ceos-david-yuan/?ref=wheresyoured.at\"><u>Gainsight CEO Nick Mehta</u></a> added that &#x201C;the bar got higher and weights shifted in the public markets,&#x201D; citing that profitability was now becoming more important to investors.&#xA0;</p><p>Per Mehta, one savior had arrived &#x2014; Private Equity, with Thoma Bravo <a href=\"https://www.thomabravo.com/press-releases/thoma-bravo-acquires-blue-coat-systems-for-1.3-billion?ref=wheresyoured.at\"><u>buying Blue Coat Systems in 2011 for $1.3 billion</u></a> (which had been backed by a Canadian teacher&#x2019;s pension fund!), <a href=\"https://www.bloomberg.com/news/articles/2014-09-29/tibco-software-to-be-acquired-by-vista-equity-for-43-billion?ref=wheresyoured.at\"><u>Vista Equity buying Tibco for $4.3 billion</u></a> in 2014, and Permira Advisers (along with the Canadian Pension Plan Investment Board) <a href=\"https://www.channelfutures.com/mergers-acquisitions/microsoft-salesforce-late-investors-in-informatica-5-3-billion-private-equity-deal?ref=wheresyoured.at\"><u>buying Informatica for $5.3 billion</u></a> (<a href=\"https://www.channelfutures.com/mergers-acquisitions/microsoft-salesforce-late-investors-in-informatica-5-3-billion-private-equity-deal?ref=wheresyoured.at\"><u>with participation from both Salesforce and Microsoft</u></a>) in 2015, 16 years after its first IPO. In each case, these firms were purchased using debt that immediately gets dumped onto the company&#x2019;s balance sheet, known as a leveraged buyout.&#xA0;</p><p>In simple terms, you buy a company with money that the company you just bought has to pay off. The company in question also has to grow like gangbusters to keep up with both that debt and the private equity firm&#x2019;s expectations. And instead of being an investor with a board seat who can yell at the CEO, <em>it&#x2019;s quite literally your company, and you can do whatever you want with (or to) it.</em></p><p>Yuan added that the size of these deals made the acquisitions problematic, as did their debt-filled:</p><blockquote>Recent SaaS PE deals are different. At more than six times revenues, unless you can increase EBITDA margins to over 40%, it&#x2019;s hard to get your arms around the effective EBITDA multiple. It seems the new breed of PE buyer is taking a bet that SaaS companies will exit on revenue multiples and show rapid growth over many years. Both are arguably new bets for private equity. It&#x2019;s not about financial or cost engineering. They are starting to look a bit more like us in the growth investing industry and taking a bet on category leadership and growth<br><br>&#x2026;<br><br>So while revenue multiples are accepted, they are viewed as risky by private equity. Take Salesforce.com, the bellwether of SaaS. Over the last 10 years, it&#x2019;s traded below 2 times next-twelve-months (NTM) revenues and over 10 times NTM revenues. Even in the past 12 months, it&#x2019;s traded as low as 4.7 times NTM multiples and as high as close to 9 times NTM multiples. In this example, if the private equity firm paid 9 times NTM revenues and multiples traded down to 4.7 times NTM, their $300 million in equity would be wiped out. In fact, they would owe the bank close to $100 million. Now it&#x2019;s not that bad, as these companies are growing revenue at the same time. But it does show you why private equity has largely been wary of revenue multiples and have relied on EBITDA and free cash flow multiples.</blockquote><p><a href=\"https://techcrunch.com/2016/06/13/symantec-grabs-blue-coat-systems-for-4-65-billion/?ref=wheresyoured.at\"><u>Symantec would acquire Blue Coat for $4.65 billion in 2016</u></a>, for just under a 4x return. Things were a little worse for Tibco. <a href=\"https://www.cnbc.com/2021/07/23/vista-equity-considers-sale-of-tibco-sources-say.html?ref=wheresyoured.at\"><u>Vista Equity Partners tried to sell it in 2021 amid a surge of other M&amp;A transactions</u></a>, with the solution &#x2014; never change, private equity! &#x2014; <a href=\"https://www.tibco.com/press-releases/2022/citrix-to-be-acquired-by-vista-equity-partners-and-evergreen-coast-capital?ref=wheresyoured.at\"><u>being to buy Citrix for $16.5 billion (a 30%% premium on its stock price)</u></a> and merge it with Tibco, magically fixing the problem of &#x201C;what do we do with Tibco?&#x201D; by hiding it inside another transaction. Informatica eventually had a $10 billion IPO in 2021, <a href=\"https://www.bloomberg.com/news/articles/2021-10-27/software-maker-informatica-opens-below-ipo-price-in-debut?ref=wheresyoured.at\"><u>which was flat in its first day of trading</u></a>, never really did more than stay at its IPO price, <a href=\"https://www.cnbc.com/2025/05/27/salesforce-informatica-deal.html?ref=wheresyoured.at\"><u>then sold to Salesforce for $8 billion in 2025</u></a>, at <a href=\"https://www.permira.com/news-and-insights/announcements/permira-to-realise-investment-in-informatica-through-salesforce-transaction?ref=wheresyoured.at\"><u>an equity value of $8 billion</u></a>, which seems <em>fine</em> but not <em>great</em> until you realize that, with inflation, the $5.3 billion that Permira invested in 2015 was about $7.15 billion in 2025&#x2019;s money.</p><p>In every case, the assumption was very simple: these businesses would grow and own their entire industries, the PE firm would be the reason they did this (by taking them private and filling them full of debt while making egregious growth demands), and the meteoric growth of SaaS would continue in perpetuity.&#xA0;</p><p>Yet the real year that broke things was 2021. As everybody returned to the real world, consumer and business spending skyrocketed, leading (<a href=\"https://archive.is/hWcEY?ref=wheresyoured.at\"><u>per Bloomberg</u></a>) to a massive surge in revenues that convinced private equity to shove even more cash and debt up the ass of SaaS:</p><blockquote>The sector has been a hugely popular target for buyout firms and their private credit cousins. From 2015 to 2025, more than 1,900 software companies were taken over by private equity buyers in transactions valued at more than $440 billion, according to data compiled by Bloomberg.<br><br>Deals were easily waved through most investment committees because the model was simple. Revenues are &#x201C;sticky&#x201D; because the tech is embedded into businesses, helping with everything from payroll to HR, and the subscription fee model meant predictable cash flows.</blockquote><p>Bloomberg is a little nicer than I am, so they&#x2019;re not just writing &#x201C;deals were waved through because everybody assumed that software grows forever and nobody actually knew a thing about the technology or why it would grow so fast.&#x201D; Unsurprisingly, this didn&#x2019;t turn out to be true. <a href=\"https://www.theinformation.com/articles/ai-clogs-exits-pe-backed-software-firms?rc=kz8jh3&amp;ref=wheresyoured.at\"><u>Per The Information</u></a>, PE firms invested in or bought 1,167 U.S. software companies for $202 billion, and usually hold investments for three to five years. Thankfully, they also included a chart to show how badly this went:&#xA0;</p><figure class=\"kg-card kg-image-card\"><img src=\"https://www.wheresyoured.at/content/images/2026/02/data-src-image-41f1c6c8-8ee4-4518-9134-b5fccbaa73a3.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"787\" height=\"690\" srcset=\"https://www.wheresyoured.at/content/images/size/w600/2026/02/data-src-image-41f1c6c8-8ee4-4518-9134-b5fccbaa73a3.png 600w, https://www.wheresyoured.at/content/images/2026/02/data-src-image-41f1c6c8-8ee4-4518-9134-b5fccbaa73a3.png 787w\" sizes=\"(min-width: 720px) 720px\"></figure><p>2021 was the year of overvaluation, and (<a href=\"https://www.saastr.com/where-are-the-2021-unicorns-today-60-are-stuck-in-limbo-per-carta/?ref=wheresyoured.at\"><u>per Jason Lemkin of SaaStr</u></a>) 60% of unicorns (startups with $1bn+) valuations hadn&#x2019;t raised funds in years. The massive accumulated overinvestment, combined with no obvious pathway to an exit, led to people calling these companies &#x201C;<a href=\"https://archive.is/tZ2XS?ref=wheresyoured.at\"><u>Zombie Unicorns</u></a>&#x201D;:</p><blockquote>A reckoning that has been looming for years is becoming painfully tangible. In 2021 more than 354 companies received billion-dollar valuations, thus achieving unicorn status. Only six of them have since held IPOs, says Ilya Strebulaev, a professor at Stanford Graduate School of Business. Four others have gone public through SPACs, and another 10 have been acquired, several for less than $1 billion.<br><br>Welcome to the era of the zombie unicorn. There are a record 1,200 venture-backed unicorns that have yet to go public or get acquired, according to CB Insights, a researcher that tracks the venture capital industry. Startups that raised large sums of money are beginning to take desperate measures. Startups in later stages are in a particularly difficult position, because they generally need more money to operate&#x2014;and the investors who&#x2019;d write checks at billion-dollar-plus valuations have gotten more selective. For some, accepting unfavorable fundraising terms or selling at a steep discount are the only ways to avoid collapsing completely, leaving behind nothing but a unicorpse.</blockquote><p>The problem, to quote The Information, is that &#x201C;PE firms don&#x2019;t want to lock in returns that are lower than what they promised their backers, say some executives at these firms,&#x201D; and &#x201C;many enterprise software firms&#x2019; revenue growth has slowed.&#x201D;</p><h2 id=\"easy-money-and-easy-exits-caused-venture-capital-and-private-equity-to-over-extend-themselves-optimizing-for-growth-rather-than-investing-in-companies-that-were-actually-valuable\">Easy Money and Easy Exits Caused Venture Capital and Private Equity To Over-Extend Themselves, Optimizing For Growth Rather Than Investing In Companies That Were Actually Valuable</h2><p><a href=\"https://archive.is/f4TdH?ref=wheresyoured.at\"><u>Per CNBC in November 2025</u></a>, private equity firms were facing the same zombie problem:</p><blockquote>These so-called &#x201C;zombie companies&#x201D; refer to businesses that aren&#x2019;t growing, barely generate enough cash to service debt and are unable to attract buyers even at a discount. They are usually trapped on a fund&#x2019;s balance sheet beyond its expected holding period. &#x201C;Now, as interest rates were rising, people felt they were stuck with businesses that were slightly worthless, but they couldn&#x2019;t really sell them &#x2026; So you are in this awful situation where people throw around the word zombie companies,&#x201D; Oliver Haarmann, founding partner of private investment firm Searchlight Capital Partners, told CNBC&#x2019;s &#x201D; Squawk Box Europe &#x201D; on Tuesday.</blockquote><p><a href=\"https://cloud.substack.com/p/who-will-buy-the-saas-companies?ref=wheresyoured.at\"><u>Per Jason Lemkin</u></a>, private equity is sitting on its largest collection of companies held for longer than four years since 2012, with <a href=\"https://www.mckinsey.com/industries/private-capital/our-insights/global-private-markets-report?ref=wheresyoured.at\"><u>McKinsey estimating</u></a> that more than 16,000 companies (more than 52% of the total buyout-backed inventory) had been held by private equity for more than four years, the highest on record.</p><p>In very simple terms, there are hundreds of billions of tech companies sitting in the wings of private equity firms that they&#x2019;re desperate to sell, with the only customers being big tech firms, other private equity firms, and public offerings <a href=\"https://www.wheresyoured.at/the-enshittifinancial-crisis/#the-great-enshittification-of-the-stock-market:~:text=Per%20Nerdlawyer%2C%20IPOs%20have%20collapsed%20as%20an%20exit%20route%2C%20along%20with%20easy%2Dto%2Draise%20capital.%C2%A0\"><u>in one of the slowest IPO markets in history</u></a>.</p><p>Investing used to be easy. There were so many ideas for so many companies, companies that could be worth billions of dollars once they&#x2019;d been fattened up with venture capital and/or private equity. There were tons of acquirers, it was easy to take them public, and all you really had to do was <em>exist</em> and <em>provide capital.</em> Companies didn&#x2019;t have to be <em>good</em>, they just had to look good enough to sell.</p><p>This created a venture capital and private equity industry based on symbolic value, and chased out anyone who thought too hard about whether these companies could actually survive on their own merits.</p><p>Per PitchBook, since 2022, <a href=\"https://pitchbook.com/news/articles/startup-exit-loss-moic?ref=wheresyoured.at\"><u>70% of VC-backed exits were valued at less than the capital put in</u></a>, with <a href=\"https://pitchbook.com/news/articles/startups-were-buyers-in-more-than-one-third-of-us-startup-acquisitions-in-2024?ref=wheresyoured.at\"><u>more than a third of them being startups buying other startups</u></a> in 2024. <a href=\"https://pitchbook.com/news/articles/as-the-window-widens-pe-firms-rush-to-exit?ref=wheresyoured.at\"><u>Private equity firms are now holding assets for an average of 7 years</u></a>,</p><p>McKinsey also added one horrible detail for the overall private equity market, emphasis mine:&#xA0;</p><blockquote>PE returns have not only trended downward over time; they appear to be at a historic low. Buyout fund IRRs (internal rate of return) reached a post-2002 trough between 2022 and 2025, averaging 5.7 percent on a pooled basis and ranking as the second-lowest period on a median basis at 5.4 percent. This deterioration reflects a combination of <strong>paying more (entry valuations are higher)</strong>, macroeconomic uncertainty (inflation and higher interest rates especially hurt overall returns),<strong> and a persistently challenged realization environment (assets are harder to sell)</strong>.</blockquote><p>You see, private equity is fucking stupid, doesn&#x2019;t understand technology, doesn&#x2019;t understand<em> business, </em>and by setting up its holdings with debt based on the assumption of unrealistic growth, they&#x2019;ve created a crisis for both software companies and the greater tech industry.&#xA0;</p><p>On February 6, more than $17.7 billion of US tech company loans dropped to &#x201C;distressed&#x201D; trading levels (as in trading as if traders don&#x2019;t believe they&#x2019;ll get paid, <a href=\"https://archive.is/bwxIG?ref=wheresyoured.at\"><u>per Bloomberg</u></a>), growing the overall group of distressed tech loans to $46.9 billion, &#x201C;dominated by firms in SaaS.&#x201D; These firms included huge investments like Thoma Bravo&#x2019;s Dayforce (<a href=\"https://www.thomabravo.com/press-releases/thoma-bravo-completes-acquisition-of-dayforce?ref=wheresyoured.at\"><u>which it purchased <em>two days before this story ran</em> for $12.3 billion</u></a>) and Calabrio (<a href=\"https://www.bizjournals.com/nashville/inno/newsletter/23303549?limit=20&amp;skip=340&amp;ref=wheresyoured.at#:~:text=Terms%20of%20the%20deal%20weren,million%20for%20it%20in%202016.\"><u>which it acquired for &#x201C;over&#x201D; $1 billion in April 2021</u></a> and <a href=\"https://www.verint.com/press-room/2025/thoma-bravo-completes-acquisition-of-verint-a-leader-in-ai-driven-customer-experience-automation/?ref=wheresyoured.at\"><u>merged with Verint in November 2025</u></a>).&#xA0;</p><p>This isn&#x2019;t just about <em>the shit they&#x2019;ve bought</em>, but the destruction of the concept of &#x201C;value&#x201D; in the tech industry writ large. &#x201C;Value&#x201D; was not based on revenues, or your product, or anything other than your ability to grow and, ideally, <a href=\"https://www.wheresyoured.at/saaspocalypse-now/\"><u>trap as many customers as possible</u></a>, with the vague sense that there would always be infinitely more money every year to spend on software.&#xA0;</p><p>Revenue growth came from massive sales teams compensated with heavy commissions and yearly price increases, except things have begun to sour, <a href=\"https://www.wheresyoured.at/saaspocalypse-now/#:~:text=Want%20another%20sign,a%20necessary%20service.\"><u>with renewals now taking twice as long to complete</u></a>, and <a href=\"https://www.wheresyoured.at/saaspocalypse-now/#:~:text=According%20to%20research,million%20of%20ARR.\"><u>overall SaaS revenue growth slowing for years</u></a>.</p><p>To put it simply, much of the investment in software was based on the idea that software companies will always grow forever, and SaaS companies &#x2014; which have &#x201C;sticky&#x201D; recurring revenues &#x2014; would be the standard-bearer.</p><h1 id=\"private-equity-and-venture-capital-have-driven-a-valuation-crisis-in-the-tech-industry-based-on-hype-and-ignorance-%E2%80%94-and-ai-may-be-their-reckoning\">Private Equity And Venture Capital Have Driven A Valuation Crisis In The Tech Industry Based on Hype and Ignorance &#x2014; And AI May Be Their Reckoning</h1><p>When I got into the tech industry in 2008, I immediately became confused about the amount of unprofitable or unsustainable companies that were worth crazy amounts of money, and for the most part I&#x2019;d get laughed at by reporters for being too cynical.&#xA0;</p><p>For the best part of 20 years, software startups have been seen as eternal growth-engines. All you had to do was find a product-market fit, get a few hundred customers locked in, up-sell them on new features and grow in perpetuity as you conquered a market. The idea was that you could just keep pumping them with cash, hire as many pre-sales (technical person who makes the sale), sales and customer experience (read: helpful person who also loves to tell you more stuff) people as you need to both retain customers <em>and</em> sell them as much stuff as you need.&#xA0;</p><p>Innovation was, as you&#x2019;d expect, judged entirely by revenue growth and <a href=\"https://chartmogul.com/saas-metrics/nrr/?ref=wheresyoured.at\"><u>net revenue retention</u></a>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://www.wheresyoured.at/content/images/2026/02/data-src-image-ca09dfd6-d114-4a65-8e55-1028ba974abf.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"734\" height=\"102\" srcset=\"https://www.wheresyoured.at/content/images/size/w600/2026/02/data-src-image-ca09dfd6-d114-4a65-8e55-1028ba974abf.png 600w, https://www.wheresyoured.at/content/images/2026/02/data-src-image-ca09dfd6-d114-4a65-8e55-1028ba974abf.png 734w\" sizes=\"(min-width: 720px) 720px\"></figure><p>In practice, this sounds reasonable: what percentage of your revenue are you making year-over-year? The problem is that this is a <em>very</em> easy to game stat, especially if you&#x2019;re using it to raise money, because you can move customer billing periods around to make sure that things all continue to look good. Even then, <a href=\"https://winningbydesign.com/wp-content/uploads/2024/01/Research-Paper_Has-SaaS-Has-Lost-Go-to-Market-Fit.pdf?ref=wheresyoured.at\"><u>per research by Jacco van der Kooji and Dave Boyce</u></a>, net revenue retention is dropping quarter over quarter.</p><p>The other problem is that the entire process of selling software has separated from the end-user, which means that products (and sales processes) are oriented around selling that software to <em>the person responsible for buying it rather than those doomed to use it.&#xA0;</em></p><p>Per Nik Suresh&#x2019;s <a href=\"https://ludic.mataroa.blog/blog/brainwash-an-executive-today/?ref=wheresyoured.at\"><u>Brainwash An Executive Today</u></a>, in a conversation with the Chief Technology Officer of a company with over 10,000 people, who had asked if &#x201C;data observability,&#x201D; a thing that they did not (and would not need to, in their position) understand, was a problem, and whether Nik had heard of Monte Carlo. It turned out that the executive in question had no idea what Monte Carlo or data observability <em>was</em>, but because they&#x2019;d heard about it on LinkedIn, it was now all they could think about.&#xA0;</p><p>This is the environment that private equity bought into &#x2014; a seemingly-eternal growth engine with pliant customers <em>desperate</em> to spend money on a product that didn&#x2019;t have to be <em>good</em>, just <em>functional-enough.</em> These people do not know what they are talking about or why they are buying these companies other than being able to mumble out shit like &#x201C;ARR&#x201D; and &#x201C;NRR+&#x201D; and &#x201C;TAM&#x201D; and &#x201C;CAC&#x201D; and &#x201C;ARPA&#x201D; in the right order to convince themselves that something is a good idea without <em>ever thinking about what would happen if it wasn&#x2019;t. </em>This allowed them to stick to the &#x201C;big picture,&#x201D; meaning &#x201C;numbers that I can look at rather than any practical experience in software development.&#x201D;</p><p>While I guess the <em>concept</em> of private equity isn&#x2019;t morally repugnant, its current form &#x2014; which includes venture capital &#x2014; has led the modern state of technology into the fucking toilet, combining an initial flux of viable businesses, frothy markets <a href=\"https://en.wikipedia.org/wiki/Zero_interest-rate_policy?ref=wheresyoured.at\"><u>and</u></a> <a href=\"https://www.cnbc.com/2020/03/15/federal-reserve-cuts-rates-to-zero-and-launches-massive-700-billion-quantitative-easing-program.html?ref=wheresyoured.at\"><u>zero interest rates</u></a> making it deceptively easy to raise money to acquire and deploy capital, leading to brainless investing, the death of logical due diligence, and potentially ruinous consequences for everybody involved.</p><p>Private equity spent decades buying a little bit of just about everything, enriching the already-rich by engaging with the most vile elements of the <a href=\"https://www.wheresyoured.at/the-rot-economy/\"><u>Rot Economy&#x2019;s growth-at-all-costs mindset</u></a>. Its success is predicated on near-perpetual levels of liquidity and growth in both its holdings and the holdings of those who exist only to buy their stock, and on a tech and business media that doesn&#x2019;t think too hard about the reality of the problems their companies claim to solve.</p><p>The reckoning that&#x2019;s coming is one built specifically to target the ignorant hubris that made them rich.&#xA0;</p><p>Private equity has yet to be punished by its limited partners and banks for investing in zombie assets, allowing it to pile into the unprofitable data centers underpinning the AI bubble, meaning that companies like Apollo, Blue Owl and Blackstone &#x2014; <a href=\"https://techcrunch.com/2022/06/24/zendesk-drama-concludes-with-10-2-billion-private-equity-acquisition/?ref=wheresyoured.at\"><u>all of whom participated in the ugly $10.2 billion acquisition of Zendesk</u></a> in 2022 (<a href=\"https://techcrunch.com/2022/02/11/zendesk-spurns-17b-private-equity-takeover-offer/?ref=wheresyoured.at\"><u>after it rejected another PE offer of $17 billion in 2021</u></a>) that <a href=\"https://archive.is/KmohJ?ref=wheresyoured.at\"><u>included $5 billion in debt</u></a> &#x2014; have <a href=\"https://www.wheresyoured.at/data-center-crisis/\"><u>all become heavily-leveraged in giant, ugly debt deals covering assets that are obsolete to useless in a few years</u></a>.</p><p>Alongside the fumbling ignorance of private equity sits <a href=\"https://www.morganstanley.com/ideas/private-credit-outlook-considerations?ref=wheresyoured.at\"><u>the $3 trillion private credit industry</u></a>, an equally-putrid, growth-drunk, and poorly-informed industry run with the same lax attention to detail and Big Brain Number Models that can justify just about any investment they want. Their half-assed due diligence led to billions of dollars of loans being given to outright frauds like <a href=\"https://www.justice.gov/usao-sdny/pr/first-brands-executives-charged-multibillion-dollar-fraud?ref=wheresyoured.at\"><u>First Brands</u></a>, <a href=\"https://www.justice.gov/usao-sdny/pr/ceo-cfo-coo-charged-connection-billion-dollar-collapse-tricolor-auto?ref=wheresyoured.at\"><u>Tricolor</u></a> and <a href=\"https://www.law360.com/bankruptcy-authority/articles/2421569/lender-says-posigen-got-25m-loan-with-fraud?ref=wheresyoured.at\"><u>PosiGen</u></a>, and, to paraphrase JP Morgan&#x2019;s Jamie Dimon, <a href=\"https://www.theguardian.com/business/2025/oct/14/jp-morgan-jamie-dimon-losses-private-credit-sector?ref=wheresyoured.at\"><u>there are absolutely more fraudulent cockroaches waiting to emerge</u></a>.</p><p>You may wonder why this matters, as all of this is <em>private</em> credit.</p><p>Well, they get their money from banks. Big banks. In fact, <a href=\"https://www.bostonfed.org/news-and-events/news/2025/05/are-private-equity-lending-private-credit-funds-large-banks-loans-increasing.aspx?ref=wheresyoured.at#:~:text=Authors%20trace%20%E2%80%9Copaque%E2%80%9D%20bank%20connections,growing%20fraction%20of%20that%20business.\"><u>according to the Federal Reserve of Boston</u></a>, about 14% ($300 billion) of large banks&#x2019; total loan commitments to non-banking financial institutions in 2023 went to private equity and private credit, with Moody&#x2019;s pegging the number around $285 billion, <a href=\"https://www.moodys.com/web/en/us/insights/data-stories/breakdown-of-banks-annual-reporting-on-private-credit.html?ref=wheresyoured.at\"><u>with an additional $340 billion in unused-yet-committed cash waiting in the wings</u></a>.</p><p>Oh, and they get their money from <em>you</em>. Pension funds are <a href=\"https://gfmag.com/private-credit/who-provides-the-capital-behind-the-private-credit-boom/?ref=wheresyoured.at\"><u>among some of the biggest backers of private credit companies</u></a>, with the New York City Employees Retirement System and CalPERS increasing their investments.&#xA0;</p><p>Today, I&#x2019;m going to teach you all about private equity, private credit, and why years of reframing &#x201C;value&#x201D; to mean &#x201C;growth&#x201D; may genuinely threaten the global banking system, as well as how effectively every company raises money. An entirely-different system exists for the wealthy to raise and deploy capital, one with flimsy due diligence, a genuine lack of basic industrial knowledge, and hundreds of billions of dollars of crap it can&#x2019;t sell.&#xA0;</p><p>These people have been able to raise near-unlimited capital to do basically anything they want because there was always somebody stupid enough to buy whatever they were selling, and they have absolutely no plan for what happens when their system stops working.&#xA0;</p><p>They&#x2019;ll loan to anyone or invest in anything that confirms their biases, and those biases are equal parts moronic and malevolent. Now they&#x2019;re investing teachers&#x2019; pensions and insurance premiums in unprofitable and unsustainable data centers, all because they have no idea what a good investment actually looks like.&#xA0;</p><p>Welcome to the Hater&#x2019;s Guide To Private Equity, or &#x201C;The Stupidest Assholes In The Room.&#x201D;</p>",
    "description": "We have a global intelligence crisis, in that a lot of people are being really fucking stupid.As I discussed in this week&#x2019;s free piece, alleged financial analyst Citrini Research put out a truly awful screed called the &#x201C;2028 Global Intelligence Crisis&#x201D; &#x2014; a slop-filled scare-fiction",
    "is_fulltext": true,
    "source": "Ed Zitron's Where's Your Ed At",
    "pub_date": "Fri, 27 Feb 2026 17:07:32 GMT",
    "fetched_at": "2026-02-28T00:33:58.506351",
    "url_hash": "6c465cea8805fed6e00841f358fa467a"
  },
  {
    "title": "An AI agent coding skeptic tries AI agent coding, in excessive detail",
    "link": "https://minimaxir.com/2026/02/ai-agent-coding/",
    "content": "<p><span><style type=\"text/css\">\npre code.language-txt, pre code.language-md{\nwhite-space: pre-wrap !important;\nword-break: normal !important;\n}\n</style></span></p>\n<p>You&rsquo;ve likely seen many blog posts about AI agent coding/<a href=\"https://en.wikipedia.org/wiki/Vibe_coding\">vibecoding</a> where the author talks about all the wonderful things agents can now do supported by vague anecdata, how agents will lead to the atrophy of programming skills, how agents impugn the sovereignty of the human soul, etc etc. This is <strong>NOT</strong> one of those posts. You&rsquo;ve been warned.</p>\n<p>Last May, I wrote a blog post titled <a href=\"https://minimaxir.com/2025/05/llm-use/\">As an Experienced LLM User, I Actually Don&rsquo;t Use Generative LLMs Often</a> as a contrasting response to the hype around the rising popularity of agentic coding. In that post, I noted that while LLMs are most definitely not useless and they can answer simple coding questions faster than it would take for me to write it myself with sufficient accuracy, agents are a tougher sell: they are unpredictable, expensive, and the hype around it was wildly disproportionate given the results I had seen in personal usage. However, I concluded that I was open to agents if LLMs improved enough such that all my concerns were addressed and agents were more dependable.</p>\n<p>In the months since, I continued my real-life work as a Data Scientist while keeping up-to-date on the latest LLMs popping up on <a href=\"https://openrouter.ai\">OpenRouter</a>. In August, Google <a href=\"https://developers.googleblog.com/introducing-gemini-2-5-flash-image/\">announced</a> the release of their Nano Banana generative image AI with a <a href=\"https://ai.google.dev/gemini-api/docs/image-generation\">corresponding API</a> that&rsquo;s difficult to use, so I open-sourced the <a href=\"https://github.com/minimaxir/gemimg\">gemimg Python package</a> that serves as an API wrapper. It&rsquo;s not a thrilling project: there&rsquo;s little room or need for creative implementation and my satisfaction with it was the net present value with what it enabled rather than writing the tool itself. Therefore as an experiment, I plopped the feature-complete code into various up-and-coming LLMs on OpenRouter and prompted the models to identify and fix any issues with the Python code: if it failed, it&rsquo;s a good test for the current capabilities of LLMs, if it succeeded, then it&rsquo;s a software quality increase for potential users of the package and I have no moral objection to it. The LLMs actually were helpful: in addition to adding good function docstrings and type hints, it identified more Pythonic implementations of various code blocks.</p>\n<p>Around this time, my coworkers were pushing <a href=\"https://github.com/features/copilot\">GitHub Copilot</a> within <a href=\"https://code.visualstudio.com\">Visual Studio Code</a> as a coding aid, particularly around then-new <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>. For my data science work, Sonnet 4.5 in Copilot was not helpful and tended to create overly verbose Jupyter Notebooks so I was not impressed. However, in November, Google then <a href=\"https://blog.google/innovation-and-ai/products/nano-banana-pro/\">released</a> Nano Banana Pro which necessitated an immediate update to <code>gemimg</code> for compatibility with the model. After experimenting with Nano Banana Pro, I discovered that the model can <a href=\"https://minimaxir.com/2025/12/nano-banana-pro/#grid\">create images with arbitrary grids</a> (e.g. 2x2, 3x2) as an extremely practical workflow, so I quickly <a href=\"https://github.com/minimaxir/gemimg/issues/15\">wrote a spec</a> to implement support and also slice each subimage out of it to save individually. I knew this workflow is relatively simple-but-tedious to implement using <a href=\"https://pypi.org/project/pillow/\">Pillow</a> shenanigans, so I felt safe enough to ask Copilot to <code>Create a grid.py file that implements the Grid class as described in issue #15</code>, and it did just that although with some errors in areas not mentioned in the spec (e.g. mixing row/column order) but they were easily fixed with more specific prompting. Even accounting for handling errors, that&rsquo;s enough of a material productivity gain to be more <em>optimistic</em> of agent capabilities, but not nearly enough to become an AI hypester.</p>\n<p>In November, just a few days before Thanksgiving, Anthropic <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">released Claude Opus 4.5</a> and naturally my coworkers were curious if it was a significant improvement over Sonnet 4.5. It was very suspicious that Anthropic released Opus 4.5 right before a major holiday since companies typically do that in order to bury underwhelming announcements as your prospective users will be too busy gathering with family and friends to notice. Fortunately, I had no friends and no family in San Francisco so I had plenty of bandwidth to test the new Opus.</p>\n<h2 id=\"a-foreword-on-agentsmd\">A Foreword on AGENTS.md</h2>\n<p>One aspect of agents I hadn&rsquo;t researched but knew was necessary to getting good results from agents was the concept of the <a href=\"https://agents.md\">AGENTS.md</a> file: a file which can control specific behaviors of the agents such as code formatting. If the file is present in the project root, the agent will automatically read the file and in theory obey all the rules within. This is analogous to system prompts for normal LLM calls and if you&rsquo;ve been following my writing, I have an unhealthy addiction to highly nuanced system prompts with additional shenanigans such as ALL CAPS for increased adherence to more important rules (yes, that&rsquo;s still effective). I could not find a good starting point for a Python-oriented <code>AGENTS.md</code> I liked, so I asked Opus 4.5 to make one:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">Add an <span class=\"sb\">`AGENTS.md`</span> file oriented for good Python code quality. It should be intricately details. More important rules should use caps, e.g. <span class=\"sb\">`MUST`</span>\n</span></span></code></pre></div><p>I then added a few more personal preferences and suggested tools from my previous failures working with agents in Python: use <code>uv</code> and <code>.venv</code> instead of the base Python installation, use <code>polars</code> instead of <code>pandas</code> for data manipulation, only store secrets/API keys/passwords in <code>.env</code> while ensuring <code>.env</code> is in <code>.gitignore</code>, etc. Most of these constraints don&rsquo;t tell the agent what to do, but <em>how</em> to do it. In general, adding a rule to my <code>AGENTS.md</code> whenever I encounter a fundamental behavior I don&rsquo;t like has been very effective. For example, agents love using unnecessary emoji which I hate, so I added a rule:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">**NEVER** use emoji, or unicode that emulates emoji (e.g. ✓, ✗).\n</span></span></code></pre></div><p>Agents also tend to leave a lot of redundant code comments, so I added another rule to prevent that:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">**MUST** avoid including redundant comments which are tautological or self-demonstating (e.g. cases where it is easily parsable what the code does at a glance or its function name giving sufficient information as to what the code does, so the comment does nothing other than waste user time)\n</span></span></code></pre></div><p>My up-to-date <code>AGENTS.md</code> file for Python is available <a href=\"https://gist.github.com/minimaxir/10b780671ee5d695b4369b987413b38f\">here</a>, and throughout my time working with Opus, it adheres to every rule despite the file&rsquo;s length, and in the instances where I accidentally query an agent without having an <code>AGENTS.md</code>, it&rsquo;s <em>very</em> evident. It would not surprise me if the file is the main differentiator between those getting good and bad results with agents, although success is <a href=\"https://news.ycombinator.com/item?id=47034087\">often mixed</a>.</p>\n<p>As a side note if you are using <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a>, the file must be named <code>CLAUDE.md</code> instead because Anthropic is weird; this blog post will just use <code>AGENTS.md</code> for consistency.</p>\n<h2 id=\"opus-first-contact\">Opus First Contact</h2>\n<p>With my <code>AGENTS.md</code> file set up, I did more research into proper methods of prompting agents to see if I was missing something that led to the poor performance from working with Sonnet 4.5.</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/claude_docs_hu11332270489057178735.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/claude_docs_hu3030063716129854829.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/claude_docs_hu1659832108086122480.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/claude_docs.png 1378w\" src=\"claude_docs.png\"\n         alt=\"From the Claude Code quickstart.\"/> <figcaption>\n            <p>From the <a href=\"https://code.claude.com/docs/en/quickstart\">Claude Code quickstart</a>.</p>\n        </figcaption>\n</figure>\n\n<p>Anthropic&rsquo;s prompt suggestions are simple, but you can&rsquo;t give an LLM an open-ended question like that and expect the results <em>you</em> want! You, the user, are likely subconsciously picky, and there are always functional requirements that the agent won&rsquo;t magically apply because it cannot read minds and behaves as a <a href=\"https://tvtropes.org/pmwiki/pmwiki.php/Main/LiteralGenie\">literal genie</a>. My approach to prompting is to write the potentially-very-large individual prompt in its own Markdown file (which can be tracked in <code>git</code>), then tag the agent with that prompt and tell it to implement that Markdown file. Once the work is completed and manually reviewed, I manually commit the work to <code>git</code>, with the message referencing the specific prompt file so I have good internal tracking.</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/implement_hu15397510448559670285.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/implement.png 574w\" src=\"implement.png\"/> \n</figure>\n\n<p>I completely ignored Anthropic&rsquo;s advice and wrote a more elaborate test prompt based on a use case I&rsquo;m familiar with and therefore can audit the agent&rsquo;s code quality. In 2021, I wrote a script to <a href=\"https://github.com/minimaxir/youtube-video-scraper\">scrape YouTube video metadata</a> from videos on a given channel using <a href=\"https://developers.google.com/youtube/v3\">YouTube&rsquo;s Data API</a>, but the API is poorly and counterintuitively documented and my Python scripts aren&rsquo;t great. I subscribe to the <a href=\"https://www.youtube.com/channel/UC9ecwl3FTG66jIKA9JRDtmg\">SiIvagunner YouTube account</a> which, as a part of the channel&rsquo;s gimmick (<a href=\"https://www.youtube.com/watch?v=rEcOzjg7vBU\">musical swaps</a> with different melodies than the ones expected), posts hundreds of videos per month with nondescript thumbnails and titles, making it nonobvious which videos are the best other than the view counts. The video metadata could be used to surface good videos I missed, so I had a fun idea to test Opus 4.5:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">Create a robust Python script that, given a YouTube Channel ID, can scrape the YouTube Data API and store all video metadata in a SQLite database. The YOUTUBE_API_KEY is present in <span class=\"sb\">`.env`</span>.\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\">Documentation on the channel endpoint: https://developers.google.com/youtube/v3/guides/implementation/channels\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\">The test channel ID to scrape is: <span class=\"sb\">`UC9ecwl3FTG66jIKA9JRDtmg`</span>\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\">You MUST obey ALL the FOLLOWING rules in your implementation.\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Do not use the Google Client SDK. Use the REST API with <span class=\"sb\">`httpx`</span>.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Include sensible aggregate metrics, e.g. number of comments on the video.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Incude <span class=\"sb\">`channel_id`</span> and <span class=\"sb\">`retrieved_at`</span> in the database schema.\n</span></span></code></pre></div><p>The resulting script is available <a href=\"https://github.com/minimaxir/youtube_scraper_opus/blob/main/scrape_channel.py\">here</a>, and it worked first try to scrape up to 20,000 videos (the max limit). The resulting Python script has very Pythonic code quality following the copious rules provided by the <code>AGENTS.md</code>, and it&rsquo;s more robust than my old script from 2021. It is most definitely not the type of output I encountered with Sonnet 4.5. There was a minor issue however: the logging is implemented naively such that the API key is leaked in the console. I added a rule to <code>AGENTS.md</code> but really this is the YouTube API&rsquo;s fault for <a href=\"https://developers.google.com/youtube/v3/getting-started#example-1\">encouraging API keys as parameters in a GET request</a>.</p>\n<p>I asked a more data-science-oriented followup prompt to test Opus 4.5&rsquo;s skill at data-sciencing:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">Create a Jupyter Notebook that, using <span class=\"sb\">`polars`</span> to process the data, does a thorough exploratory data analysis of data saved in <span class=\"sb\">`youtube_videos.db`</span>, for all columns.\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\">This analysis should be able to be extended to any arbitrary input <span class=\"sb\">`channel_id`</span>.\n</span></span></code></pre></div><p>The <a href=\"https://github.com/minimaxir/youtube_scraper_opus/blob/main/eda_youtube.ipynb\">resulting Jupyter Notebook</a> is&hellip;indeed thorough. That&rsquo;s on me for specifying &ldquo;for all columns&rdquo;, although it was able to infer the need for temporal analysis (e.g. total monthly video uploads over time) despite not explicitly being mentioned in the prompt.</p>\n<p>The monthly analysis gave me an idea: could Opus 4.5 design a small webapp to view the top videos by month? That gives me the opportunity to try another test of how well Opus 4.5 works with less popular frameworks than React or other JavaScript component frameworks that LLMs push by default. Here, I&rsquo;ll try <a href=\"https://fastapi.tiangolo.com\">FastAPI</a>, <a href=\"https://picocss.com\">Pico CSS</a> for the front end (because we don&rsquo;t need a JavaScript framework for this), and <a href=\"https://htmx.org\">HTMX</a> for lightweight client/server interactivity:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">Create a Hacker News-worthy FastAPI application using HTMX for interactivity and PicoCSS for styling to build a YouTube-themed application that leverages <span class=\"sb\">`youtube_videos.db`</span> to create an interactive webpage that shows the top videos for each month, including embedded YouTube videos which can be clicked.\n</span></span></code></pre></div><figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/yt_web_app_hu14337359454475382611.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/yt_web_app_hu13631877744488862261.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/yt_web_app_hu5366479480531382495.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/yt_web_app.webp 1592w\" src=\"yt_web_app.webp\"/> \n</figure>\n\n<p>The FastAPI webapp <a href=\"https://github.com/minimaxir/youtube_scraper_opus/blob/main/app.py\">Python code</a> is good with logical integration of HTMX routes and partials, but Opus 4.5 had fun with the &ldquo;YouTube-themed&rdquo; aspect of the prompt: the video thumbnail simulates a YouTube thumbnail with video duration that loads an embedded video player when clicked! The full code is open-source <a href=\"https://github.com/minimaxir/youtube_scraper_opus/\">in this GitHub repository</a>.</p>\n<p>All of these tests performed far better than what I expected given my prior poor experiences with agents. Did I gaslight myself by being an agent skeptic? How did a LLM sent to die finally solve my agent problems? Despite the holiday, X and Hacker News were abuzz with similar stories about the massive difference between Sonnet 4.5 and Opus 4.5, so something <em>did</em> change.</p>\n<p>Obviously an API scraper and data viewer alone do not justify an <strong>OPUS 4.5 CHANGES EVERYTHING</strong> declaration on social media, but it&rsquo;s enough to be less cynical and more optimistic about agentic coding. It&rsquo;s an invitation to continue creating more difficult tasks for Opus 4.5 to solve. From this point going forward, I will also switch to the terminal Claude Code, since my pipeline is simple enough and doesn&rsquo;t warrant a UI or other shenanigans.</p>\n<h2 id=\"getting-rusty-at-coding\">Getting Rusty At Coding</h2>\n<p>If you&rsquo;ve spent enough time on programming forums such as Hacker News, you&rsquo;ve probably seen the name &ldquo;Rust&rdquo;, often in the context of snark. <a href=\"https://rust-lang.org\">Rust</a> is a relatively niche compiled programming language that touts two important features: speed, which is evident in <a href=\"https://www.techempower.com/benchmarks/#section=data-r23\">framework benchmarks</a> where it can perform 10x as fast as the fastest Python library, and memory safety enforced at compile time through its ownership and borrowing systems which mitigates many potential problems. For over a decade, the slogan &ldquo;Rewrite it in Rust&rdquo; <a href=\"https://transitiontech.ca/random/RIIR\">became a meme</a> where advocates argued that <em>everything</em> should be rewritten in Rust due to its benefits, including extremely mature software that&rsquo;s infeasible to actually rewrite in a different language. Even the major LLM companies are looking to Rust to eke out as much performance as possible: OpenAI President Greg Brockman <a href=\"https://x.com/gdb/status/2007228511363444905\">recently tweeted</a> &ldquo;rust is a perfect language for agents, given that if it compiles it&rsquo;s ~correct&rdquo; which — albeit that statement is silly at a technical level since code can still be <em>logically</em> incorrect — shows that OpenAI is very interested in Rust, and if they&rsquo;re interested in writing Rust code, they need their LLMs to be able to code well in Rust.</p>\n<p>I myself am not very proficient in Rust. Rust has a famously excellent <a href=\"https://rust-lang.org/learn/\">interactive tutorial</a>, but a persistent issue with Rust is that there are few resources for those with intermediate knowledge: there&rsquo;s little between the tutorial and &ldquo;write an operating system from scratch.&rdquo; That was around 2020 and I decided to wait and see if the ecosystem corrected this point (in 2026 it has not), but I&rsquo;ve kept an eye on Hacker News for all the new Rust blog posts and library crates so that one day I too will be able to write the absolutely highest performing code possible.</p>\n<p>Historically, LLMs have been poor at generating Rust code due to its nicheness relative to Python and JavaScript. Over the years, one of my test cases for evaluating new LLMs was to ask it to write a relatively simple application such as <code>Create a Rust app that can create &quot;word cloud&quot; data visualizations given a long input text.</code> but even without expert Rust knowledge I could tell the outputs were too simple and half-implemented to ever be functional even with additional prompting.</p>\n<p>However, due to modern LLM postraining paradigms, it&rsquo;s entirely possible that newer LLMs are specifically RLHF-trained to write better code in Rust despite its relative scarcity. I ran more experiments with Opus 4.5 and using LLMs in Rust on some fun pet projects, and my results were <em>far</em> better than I expected. Here are four such projects:</p>\n<h3 id=\"icon-to-image\">icon-to-image</h3>\n<p>As someone who primarily works in Python, what first caught my attention about Rust is the <a href=\"https://pyo3.rs/v0.28.2/\">PyO3</a> crate: a crate that allows accessing Rust code through Python with all the speed and memory benefits that entails while the Python end-user is none-the-wiser. My first exposure to <code>pyo3</code> was the fast tokenizers in <a href=\"https://huggingface.co\">Hugging Face</a> <a href=\"https://github.com/huggingface/tokenizers\">tokenizers</a>, but many popular Python libraries now also use this pattern for speed, including <a href=\"https://github.com/ijl/orjson\">orjson</a>, <a href=\"https://docs.pydantic.dev/latest/\">pydantic</a>, and my favorite <a href=\"https://pola.rs\">polars</a>. If agentic LLMs could now write both performant Rust code and leverage the <code>pyo3</code> bridge, that would be <em>extremely</em> useful for myself.</p>\n<p>I decided to start with a very simple project: a project that can take icons from an icon font file such as the ones provided by <a href=\"https://fontawesome.com\">Font Awesome</a> and render them into images at any arbitrary resolution.</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/icons_header_hu9523384845981914752.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/icons_header_hu2833346965406373643.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/icons_header_hu7299169397355823441.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/icons_header.webp 1536w\" src=\"icons_header.webp\"/> \n</figure>\n\n<p>I made <a href=\"https://github.com/minimaxir/icon-image\">this exact project</a> in Python in 2021, and it&rsquo;s very hacky by pulling together several packages and cannot easily be maintained. A better version in Rust with Python bindings is a good way to test Opus 4.5.</p>\n<p>The very first thing I did was create a <code>AGENTS.md</code> for Rust by telling Opus 4.5 to port over the Python rules to Rust semantic equivalents. This worked well enough and had the standard Rust idioms: no <code>.clone()</code> to handle lifetimes poorly, no unnecessary <code>.unwrap()</code>, no <code>unsafe</code> code, etc. Although I am not a Rust expert and cannot speak that the agent-generated code is idiomatic Rust, none of the Rust code demoed in this blog post has traces of bad Rust code smell. Most importantly, the agent is instructed to call <a href=\"https://doc.rust-lang.org/stable/clippy/\">clippy</a> after each major change, which is Rust&rsquo;s famous linter that helps keep the code clean, and Opus is good about implementing suggestions from its warnings. My up-to-date Rust <code>AGENTS.md</code> is available <a href=\"https://gist.github.com/minimaxir/068ef4137a1b6c1dcefa785349c91728\">here</a>.</p>\n<p>With that, I built a gigaprompt to ensure Opus 4.5 accounted for both the original Python implementation and a few new ideas I had, such as <a href=\"https://en.wikipedia.org/wiki/Supersampling\">supersampling</a> to antialias the output.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">Create a Rust/Python package (through <span class=\"sb\">`pyo3`</span> and <span class=\"sb\">`maturin`</span>) that efficiently and super-quickly takes an Icon Font and renders an image based on the specified icon. The icon fonts are present in <span class=\"sb\">`assets`</span>, and the CSS file which maps the icon name to the corresponding reference in the icon font is in <span class=\"sb\">`fontawesome.css`</span>.\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\">You MUST obey ALL the FOLLOWING implementation notes:\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> If the icon name has <span class=\"sb\">`solid`</span> in it, it is referencing <span class=\"sb\">`fa-solid.otf`</span>.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> <span class=\"sb\">`fa-brands.otf`</span> and <span class=\"sb\">`fa-regular.otf`</span> can be combined.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> The package MUST also support Python (via <span class=\"sb\">`pyo3`</span> and <span class=\"sb\">`maturin`</span>).\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> The package MUST be able to output the image rendered as an optimized PNG and WEBP. with a default output resolution of 1024 x 1024.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> The image rendering MUST support supersampling for antialiased text and points (2x by default)\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> The package MUST implement <span class=\"sb\">`fontdue`</span> as its text rendering method.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Allow the user to specify the color of the icon and the color of the background (both hex and RGB)\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Allow transparent backgrounds.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Allow user to specify the icon size and canvas size separately.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Allow user to specify the anchor positions (horizontal and vertical) for the icon relative to the canvas (default: center and center)\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Allow users to specify a horizontal and vertical pixel offset for the icon relative to the canvas.\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\">After your base implementation is complete, you MUST:\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Write a comprehensive Python test suite using <span class=\"sb\">`pytest`</span>.\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Write a Python Jupyter Notebook\n</span></span><span class=\"line\"><span class=\"cl\"><span class=\"k\">-</span> Optimize the Rust binary file size and the Python package file size.\n</span></span></code></pre></div><p>It completed the assignment in one-shot, accounting for all of the many feature constraints specified. The &ldquo;Python Jupyter Notebook&rdquo; notebook command at the end is how I manually tested whether the <code>pyo3</code> bridge worked, and it indeed worked like a charm. There was one mistake that&rsquo;s my fault however: I naively chose the <a href=\"https://github.com/mooman219/fontdue\">fontdue</a> Rust crate as the renderer because I remember <a href=\"https://github.com/mooman219/fontdue?tab=readme-ov-file#performance\">seeing a benchmark</a> showing it was the fastest at text rendering. However, testing large icon generation exposed a flaw: <code>fontdue</code> achieves its speed by only partially rendering curves, which is a very big problem for icons, so I followed up:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" class=\"chroma\"><code class=\"language-md\" data-lang=\"md\"><span class=\"line\"><span class=\"cl\">The generated icons, at a high resolution, show signs of not having curves and instead showing discrete edges (image attached). Investigate the <span class=\"sb\">`fontdue`</span> font renderer to see if there&#39;s an issue there.\n</span></span><span class=\"line\"><span class=\"cl\">\n</span></span><span class=\"line\"><span class=\"cl\">In the event that it&#39;s not possible to fix this in <span class=\"sb\">`fontdue`</span>, investigate using <span class=\"sb\">`ab_glyph`</span> instead.\n</span></span></code></pre></div><p>Opus 4.5 used its Web Search tool to confirm the issue is expected with <code>fontdue</code> and implemented <a href=\"https://crates.io/crates/ab_glyph\">ab_glyph</a> instead which did fix the curves.</p>\n<p>icon-to-image is available <a href=\"https://github.com/minimaxir/icon-to-image\">open-source on GitHub</a>. There were around 10 prompts total adding tweaks and polish, but through all of them Opus 4.5 never failed the assignment as written. Of course, generating icon images in Rust-with-Python-bindings is an order of magnitude faster than my old hacky method, and thanks to the better text rendering and supersampling it also looks much better than the Python equivalent.</p>\n<p>There&rsquo;s a secondary pro and con to this pipeline: since the code is compiled, it avoids having to specify as many dependencies in Python itself; in this package&rsquo;s case, Pillow for image manipulation in Python is optional and the Python package won&rsquo;t break if Pillow changes its API. The con is that compiling the Rust code into Python wheels is difficult to automate especially for multiple OS targets: fortunately, GitHub provides <a href=\"https://docs.github.com/en/actions/concepts/runners/github-hosted-runners\">runner VMs</a> for this pipeline and a little bit of back-and-forth with Opus 4.5 created <a href=\"https://github.com/minimaxir/icon-to-image/blob/main/.github/workflows/release.yml\">a GitHub Workflow</a> which runs the build for all target OSes on publish, so there&rsquo;s no extra effort needed on my end.</p>\n<h3 id=\"word-clouds-in-the-browser\">Word Clouds In The Browser</h3>\n<p>When I used word clouds in Rust as my test case for LLM Rust knowledge, I had an ulterior motive: I <em>love</em> word clouds. Back in 2019, I open-sourced a Python package titled <a href=\"https://github.com/minimaxir/stylecloud\">stylecloud</a>: a package built on top of Python&rsquo;s word cloud, but with the added ability to add more color gradients and masks based on icons to easily conform it into shapes (sound familiar?)</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/stylecloud_banner_hu11915381348910189533.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/stylecloud_banner_hu10339034291971611939.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/stylecloud_banner.png 768w\" src=\"stylecloud_banner.png\"/> \n</figure>\n\n<p>However, stylecloud was hacky and fragile, and a number of features I wanted to add such as non-90-degree word rotation, transparent backgrounds, and SVG output flat-out were not possible to add due to its dependency on Python&rsquo;s <a href=\"https://github.com/amueller/word_cloud\">wordcloud</a>/<a href=\"https://matplotlib.org\">matplotlib</a>, and also the package was really slow. The only way to add the features I wanted was to build something from scratch: Rust fit the bill.</p>\n<p>The pipeline was very similar to <code>icon-to-image</code> above: ask Opus 4.5 to fulfill a long list of constraints with the addition of Python bindings. But there&rsquo;s another thing that I wanted to test that would be extremely useful if it worked: WebAssembly (WASM) output with <a href=\"https://crates.io/crates/wasm-bindgen\">wasm-bindgen</a>. Rust code compiled to WASM allows it to be run in any modern web browser with the speed benefits intact: no dependencies needed, and therefore should be future-proof. However, there&rsquo;s a problem: I would have to design an interface and I am not a front end person, and I say without hyperbole that for me, designing even a simple HTML/CSS/JS front end for a project is more stressful than training an AI. However, Opus 4.5 is able to take general guidelines and get it into something workable: I first told it to use Pico CSS and vanilla JavaScript and that was enough, but then I had an idea to tell it to use <a href=\"https://ui.shadcn.com\">shadcn/ui</a> — a minimalistic design framework normally reserved for Web Components — along with screenshots from that website as examples. That also worked.</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/wordcloud_rust_ui_hu5225407277958092339.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/wordcloud_rust_ui_hu11592722749763023066.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/wordcloud_rust_ui_hu10255586485709241455.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/wordcloud_rust_ui.webp 1251w\" src=\"wordcloud_rust_ui.webp\"/> \n</figure>\n\n<p>After more back-and-forth with design nitpicks and more features to add, the package is feature complete. However, it needs some more polish and a more unique design before I can release it, and I got sidetracked by <em>something</em> more impactful&hellip;</p>\n<h3 id=\"miditui\">miditui</h3>\n<p><code>Create a music player in the terminal using Rust</code> was another Rust stress test I gave to LLMs: command line terminals can&rsquo;t play audio, right? Turns out, it can with the <a href=\"https://crates.io/crates/rodio\">rodio</a> crate. Given the success so far with Opus 4.5 I decided to make the tasks more difficult: terminals can play sound, but can it <em>compose</em> sound? So I asked Opus 4.5 to create a MIDI composer and playback DAW within a terminal, which worked. Adding features forced me to learn more about how MIDIs and <a href=\"https://en.wikipedia.org/wiki/SoundFont\">SoundFonts</a> actually work, so it was also educational!</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/miditui_hu15914726632886928414.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/miditui_hu10232551516988147501.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/miditui_hu13226160204484135869.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/miditui.webp 1582w\" src=\"miditui.webp\"/> \n</figure>\n\n<p>miditui is available <a href=\"https://github.com/minimaxir/miditui\">open-sourced on GitHub</a>, and the prompts used to build it are <a href=\"https://github.com/minimaxir/miditui/blob/main/agent_notes/PROMPTS.md\">here</a>.</p>\n<p>During development I encountered a caveat: Opus 4.5 can&rsquo;t test or view a terminal output, especially one with unusual functional requirements. But despite being blind, it knew enough about the <a href=\"https://ratatui.rs\">ratatui</a> terminal framework to implement whatever UI changes I asked. There were a large number of UI bugs that likely were caused by Opus&rsquo;s inability to create test cases, namely failures to account for scroll offsets resulting in incorrect click locations. As someone who spent 5 years as a <a href=\"https://en.wikipedia.org/wiki/Black_box\">black box</a> Software QA Engineer who was unable to review the underlying code, this situation was my specialty. I put my QA skills to work by messing around with <code>miditui</code>, told Opus any errors with occasionally a screenshot, and it was able to fix them easily. I do not believe that these bugs are inherently due to LLM agents being better or worse than humans as humans are most definitely capable of making the same mistakes. Even though I myself am adept at finding the bugs and offering solutions, I don&rsquo;t believe that I would inherently avoid causing similar bugs were I to code such an interactive app without AI assistance: QA brain is different from software engineering brain.</p>\n<h3 id=\"ballin\">ballin</h3>\n<p>One night — after a glass of wine — I had another idea: one modern trick with <a href=\"https://en.wikipedia.org/wiki/ASCII_art\">ASCII art</a> is the use of <a href=\"https://www.unicode.org/charts/nameslist/c_2800.html\">Braille unicode characters</a> to allow for <a href=\"https://steamcommunity.com/sharedfiles/filedetails/?id=2807089604\">very high detail</a>. That reminded me of ball physics simulations, so what about building a full physics simulator also in the terminal? So I asked Opus 4.5 to create a terminal physics simulator with the <a href=\"https://rapier.rs\">rapier</a> 2D physics engine and a detailed explanation of the Braille character trick: this time Opus did better and completed it in one-shot, so I spent more time making it colorful and <em>fun</em>. I pessimistically thought the engine would only be able to handle a few hundred balls: instead, the Rust codebase can handle over 10,000 logical balls!</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/ballin_hu6527272623856741407.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/ballin_hu4879560967875871347.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/ballin_hu13153143417674011956.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/ballin.webp 1909w\" src=\"ballin.webp\"\n         alt=\"I explicitly prompted Opus to make the Colors button have a different color for each letter.\"/> <figcaption>\n            <p>I explicitly prompted Opus to make the Colors button have a different color for each letter.</p>\n        </figcaption>\n</figure>\n\n<p>ballin is available <a href=\"https://github.com/minimaxir/ballin\">open-sourced on GitHub</a>, and the prompts used to build it are <a href=\"https://github.com/minimaxir/ballin/blob/main/PROMPTS.md\">here</a>.</p>\n<p>The <code>rapier</code> crate also published a blog post highlighting a <a href=\"https://dimforge.com/blog/2026/01/09/the-year-2025-in-dimforge\">major change to its underlying math engine</a>, in its 0.32.0 version so I asked Opus 4.5 to upgrade to that version&hellip;and it caused crashes, yet tracing the errors showed it originated with <code>rapier</code> itself. Upgrading to 0.31.0 was fine with no issues: a consequence of only using agentic coding for this workflow is that I cannot construct a minimal reproducible test case to file as a regression bug report or be able to isolate it as a side effect of a new API not well-known by Opus 4.5.</p>\n<p>The main lesson I learnt from working on these projects is that agents work best when you have <a href=\"https://www.youtube.com/watch?v=W9_iQ1FSnp8\">approximate knowledge of many things</a> with enough domain expertise to know what should and should not work. Opus 4.5 is good enough to let me finally do side projects where I know precisely what I want but not necessarily how to implement it. These specific projects aren&rsquo;t the Next Big Thing™ that justifies the existence of an industry taking billions of dollars in venture capital, but they make my life better and since they are open-sourced, hopefully they make someone else&rsquo;s life better. However, I still wanted to push agents to do more impactful things in an area that might be more worth it.</p>\n<h2 id=\"its-not-ai-psychosis-if-it-works\">It&rsquo;s Not AI Psychosis If It Works</h2>\n<p>Before I wrote my blog post about how I use LLMs, I wrote a tongue-in-cheek blog post titled <a href=\"https://minimaxir.com/2025/01/write-better-code/\">Can LLMs write better code if you keep asking them to “write better code”?</a> which is exactly as the name suggests. It was an experiment to determine how LLMs interpret the ambiguous command &ldquo;write better code&rdquo;: in this case, it was to prioritize making the code more convoluted with more helpful features, but if instead given commands to optimize the code, it did make the code faster successfully albeit at the cost of significant readability. In software engineering, one of the greatest sins is <a href=\"https://stackify.com/premature-optimization-evil/\">premature optimization</a>, where you sacrifice code readability and thus maintainability to chase performance gains that slow down development time and may not be worth it. Buuuuuuut with agentic coding, we implicitly accept that our interpretation of the code is fuzzy: could agents iteratively applying optimizations for the sole purpose of minimizing benchmark runtime — and therefore faster code in typical use cases if said benchmarks are representative — now actually be a good idea? People complain about how AI-generated code is slow, but if AI can now reliably generate <em>fast</em> code, that changes the debate.</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/div255_hu11595908880257789077.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/div255_hu11983769508646333070.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/div255_hu1675902341658744238.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/div255.png 1104w\" src=\"div255.png\"\n         alt=\"Multiplication and division are too slow for Opus 4.6.\"/> <figcaption>\n            <p>Multiplication and division are too slow for Opus 4.6.</p>\n        </figcaption>\n</figure>\n\n<p>As a data scientist, I&rsquo;ve been frustrated that there haven&rsquo;t been any impactful new Python data science tools released in the past few years other than <code>polars</code>. Unsurprisingly, research into AI and LLMs has subsumed traditional DS research, where developments such as text embeddings have had <a href=\"https://minimaxir.com/2025/02/embeddings-parquet/\">extremely valuable gains</a> for typical data science natural language processing tasks. The traditional machine learning algorithms are still valuable, but no one has invented <a href=\"https://developers.google.com/machine-learning/decision-forests/intro-to-gbdt\">Gradient Boosted Decision Trees</a> 2: Electric Boogaloo. Additionally, as a data scientist in San Francisco I am legally required to use a MacBook, but there haven&rsquo;t been data science utilities that actually use the GPU in an Apple Silicon MacBook as they don&rsquo;t support its Metal API; data science tooling is exclusively in CUDA for NVIDIA GPUs. What if agents could now port these algorithms to a) run on Rust with Python bindings for its speed benefits and b) run on GPUs without complex dependencies?</p>\n<p>This month, OpenAI announced their <a href=\"https://openai.com/index/introducing-the-codex-app/\">Codex app</a> and my coworkers were asking questions. So I downloaded it, and as a test case for the GPT-5.2-Codex (high) model, I asked it to reimplement the <a href=\"https://umap-learn.readthedocs.io/en/latest/\">UMAP algorithm</a> in Rust. UMAP is a dimensionality reduction technique that can take in a high-dimensional matrix of data and simultaneously cluster and visualize data in lower dimensions. However, it is a very computationally-intensive algorithm and the only tool that can do it quickly is NVIDIA&rsquo;s <a href=\"https://github.com/rapidsai/cuml\">cuML</a> which requires CUDA dependency hell. If I can create a UMAP package in Rust that&rsquo;s superfast with minimal dependencies, that is an <em>massive</em> productivity gain for the type of work I do and can enable fun applications if fast enough.</p>\n<p>After OpenAI <a href=\"https://openai.com/index/introducing-gpt-5-3-codex/\">released</a> GPT-5.3-Codex (high) which performed substantially better and faster at these types of tasks than GPT-5.2-Codex, I asked Codex to write a UMAP implementation from scratch in Rust, which at a glance seemed to work and gave reasonable results. I also instructed it to create benchmarks that test a wide variety of representative input matrix sizes. Rust has a popular benchmarking crate in <a href=\"https://crates.io/crates/criterion\">criterion</a>, which outputs the benchmark results in an easy-to-read format, which, most importantly, agents can easily parse.</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/criterion_hu12126640346462378747.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/criterion_hu13136779370143842008.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/criterion_hu12098075617543775482.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/criterion.png 1300w\" src=\"criterion.png\"\n         alt=\"Example output from criterion.\"/> <figcaption>\n            <p>Example output from <code>criterion</code>.</p>\n        </figcaption>\n</figure>\n\n<p>At first glance, the benchmarks and their construction looked good (i.e. no cheating) and are much faster than working with UMAP in Python. To further test, I asked the agents to implement additional different useful machine learning algorithms such as HDBSCAN as individual projects, with each repo starting with this 8 prompt plan in sequence:</p>\n<ol>\n<li>Implement the package with the specific functional requirements and design goals; afterwards, create benchmarks with specific matrix sizes that are representative of typical use cases</li>\n<li>Do a second pass to clean up the code/comments and make further optimizations</li>\n<li>Scan the crate to find areas of algorithmic weaknesses in extreme cases, and write a sentence for each describing the problem, the potential solution, and quantifying the impact of the solution</li>\n<li>Leveraging the findings found, optimize the crate such that ALL benchmarks run 60% or quicker (1.4x faster). Use any techniques to do so, and repeat until benchmark performance converges, but don&rsquo;t game the benchmarks by overfitting on the benchmark inputs alone <sup id=\"fnref:1\"><a href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\">1</a></sup></li>\n<li>Create custom tuning profiles that take advantage of the inherent quantities of the input data and CPU thread saturation/scheduling/parallelization to optimize the crate such that ALL benchmarks run 60% or quicker (1.4x faster). You can use the <a href=\"https://crates.io/crates/flamegraph\">flamegraph</a> crate to help with the profiling</li>\n<li>Add Python bindings using <code>pyo3</code> 0.27.2 and <code>maturin</code>, with relevant package-specific constraints (specifying the <code>pyo3</code> version is necessary to ensure compatability with Python 3.10+)</li>\n<li>Create corresponding benchmarks in Python, and write a comparison script between the Python bindings and an existing Python package</li>\n<li>Accuse the agent of potentially cheating its algorithm implementation while pursuing its optimizations, so tell it to optimize for the similarity of outputs against a known good implementation (e.g. for a regression task, minimize the <a href=\"https://en.wikipedia.org/wiki/Mean_absolute_error\">mean absolute error</a> in predictions between the two approaches)</li>\n</ol>\n<p>The simultaneous constraints of code quality requirements via <code>AGENTS.md</code>, speed requirements with a quantifiable target objective, and an output accuracy/quality requirement, all do succeed at finding meaningful speedups consistently (atleast 2x-3x)</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/pca_benchmark_codex_hu9123443470676813514.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/pca_benchmark_codex_hu1618257782133371141.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/pca_benchmark_codex_hu9032841352375549643.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/pca_benchmark_codex.png 1366w\" src=\"pca_benchmark_codex.png\"\n         alt=\"Codex 5.3 after optimizing a principal component analysis implementation.\"/> <figcaption>\n            <p>Codex 5.3 after optimizing a <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\">principal component analysis</a> implementation.</p>\n        </figcaption>\n</figure>\n\n<p>I&rsquo;m not content with only 2-3x speedups: nowadays in order for this agentic code to be meaningful and not just another repo on GitHub, it has to be the <em>fastest implementation possible</em>. In a moment of sarcastic curiosity, I tried to see if Codex and Opus had different approaches to optimizing Rust code by chaining them:</p>\n<ol>\n<li>Instruct Codex to optimize benchmarks to 60% of runtime</li>\n<li>Instruct Opus to optimize benchmarks to 60% of runtime</li>\n<li>Instruct Opus to minimize differences between agentic implementation and known good implementation without causing more than a 5% speed regression on any benchmarks</li>\n</ol>\n<p><em>This works</em>. From my tests with the algorithms, Codex can often speed up the algorithm by 1.5x-2x, then Opus somehow speeds up that optimized code <em>again</em> to a greater degree. This has been the case of all the Rust code I&rsquo;ve tested: I also ran the <code>icon-to-image</code> and the word cloud crates through this pipeline and gained 6x cumulative speed increases in both libraries.</p>\n<p>Can these agent-benchmaxxed implementations actually beat the existing machine learning algorithm libraries, despite those libraries already being written in a low-level language such as C/C++/Fortran? Here are the results on my personal MacBook Pro comparing the CPU benchmarks of the Rust implementations of various computationally intensive ML algorithms to their respective popular implementations, where the agentic Rust results are within similarity tolerance with the battle-tested implementations and Python packages are compared against the Python bindings of the agent-coded Rust packages:</p>\n<ul>\n<li>UMAP: 2-10x faster than Rust&rsquo;s <a href=\"https://crates.io/crates/fast-umap\">fast-umap</a>, 9-30x faster than Python&rsquo;s <a href=\"https://umap-learn.readthedocs.io/en/latest/\">umap</a></li>\n<li>HDBSCAN (clustering algorithm): 23-100x faster than the <a href=\"https://crates.io/crates/hdbscan\">hdbscan</a> Rust crate, 3x-10x faster than Python&rsquo;s <a href=\"https://pypi.org/project/hdbscan/\">hdbscan</a></li>\n<li>GBDT (tree-boosting algorithm): 1.1x-1.5x faster fit/predict than the <a href=\"https://crates.io/crates/treeboost\">treeboost</a> Rust crate<sup id=\"fnref:2\"><a href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\">2</a></sup>, 24-42x faster fit/1-5x faster predict than Python&rsquo;s <a href=\"https://xgboost.readthedocs.io/en/stable/index.html\">xgboost</a></li>\n</ul>\n<p>I&rsquo;ll definitely take those results with this unoptimized prompting pipeline! In all cases, the GPU benchmarks are unsurprisingly even better and with <a href=\"https://crates.io/crates/wgpu\">wgpu</a> and added WGSL shaders the code runs on Metal without any additional dependencies, however further testing is needed so I can&rsquo;t report numbers just yet.</p>\n<p>Although I could push these new libraries to GitHub now, machine learning algorithms are understandably a domain which requires extra care and testing. It would be arrogant to port Python&rsquo;s <a href=\"https://scikit-learn.org/stable/\">scikit-learn</a> — the gold standard of data science and machine learning libraries — to Rust with all the features that implies.</p>\n<p>But that&rsquo;s unironically a good idea so I decided to try and do it anyways. With the use of agents, I am now developing <code>rustlearn</code> (extreme placeholder name), a Rust crate that implements not only the fast implementations of the standard machine learning algorithms such as <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">logistic regression</a> and <a href=\"https://en.wikipedia.org/wiki/K-means_clustering\">k-means clustering</a>, but also includes the fast implementations of the algorithms above: the same three step pipeline I describe above still works even with the more simple algorithms to beat scikit-learn&rsquo;s implementations. This crate can therefore receive Python bindings and even expand to the Web/JavaScript and beyond. This also gives me the oppertunity to add quality-of-life features to resolve grievances I&rsquo;ve had to work around as a data scientist, such as model serialization and native integration with pandas/polars DataFrames. I hope this use case is considered to be more practical and complex than making a ball physics terminal app.</p>\n<p>Many people reading this will call bullshit on the performance improvement metrics, and honestly, fair. I too thought the agents would stumble in hilarious ways trying, but they did not. To demonstrate that I am not bullshitting, I also decided to release a more simple Rust-with-Python-bindings project today: nndex, an in-memory vector &ldquo;store&rdquo; that is designed to retrieve the exact nearest neighbors as fast as possible (and has fast approximate NN too), and is now available <a href=\"https://github.com/minimaxir/nndex\">open-sourced on GitHub</a>. This leverages the <a href=\"https://en.wikipedia.org/wiki/Dot_product\">dot product</a> which is one of the simplest matrix ops and is therefore heavily optimized by existing libraries such as Python&rsquo;s <a href=\"https://numpy.org\">numpy</a>&hellip;and yet after a few optimization passes, it tied <code>numpy</code> even though <code>numpy</code> leverages <a href=\"https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms\">BLAS</a> libraries for maximum mathematical performance. Naturally, I instructed Opus to also add support for BLAS with more optimization passes and it now is 1-5x numpy&rsquo;s speed in the single-query case and much faster with batch prediction. <sup id=\"fnref:3\"><a href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\">3</a></sup> It&rsquo;s so fast that even though I also added GPU support for testing, it&rsquo;s mostly ineffective below 100k rows due to the GPU dispatch overhead being greater than the actual retrieval speed.</p>\n<figure>\n\n    \n\n    <img loading=\"lazy\" srcset=\"https://minimaxir.com/2026/02/ai-agent-coding/nndex_hu9515467843186677676.webp 320w,https://minimaxir.com/2026/02/ai-agent-coding/nndex_hu925894612593947548.webp 768w,https://minimaxir.com/2026/02/ai-agent-coding/nndex_hu10646951113229378552.webp 1024w,https://minimaxir.com/2026/02/ai-agent-coding/nndex.png 1564w\" src=\"nndex.png\"\n         alt=\"Comparison of Python nndex to numpy on test workloads.topk_overlap measures result matches (perfect match) and max_similarity_abs_delta measure the largest difference between calculated cosine similarities (effectively zero).\"/> <figcaption>\n            <p>Comparison of Python <code>nndex</code> to numpy on test workloads.<code>topk_overlap</code> measures result matches (perfect match) and <code>max_similarity_abs_delta</code> measure the largest difference between calculated cosine similarities (effectively zero).</p>\n        </figcaption>\n</figure>\n\n<p>One of the criticisms about AI generated code is that it &ldquo;just regurgitates everything on GitHub&rdquo; but by construction, if the code is faster than what currently exists, then it can&rsquo;t have been stolen and must be an original approach. Even if the explicit agentic nature of <code>rustlearn</code> makes it risky to adopt downstream, the learnings from how it accomplishes its extreme speed are still valuable.</p>\n<h2 id=\"the-implications-of-my-agentic-successes\">The Implications of My Agentic Successes</h2>\n<p>Like many who have hopped onto the agent train post-Opus 4.5, I&rsquo;ve become nihilistic over the past few months, but not for the typical reasons. I actually am not hitting burnout and I am not worried that my programming skills are decaying due to agents: on the contrary, the session limits intended to stagger server usage have unintentionally caused me to form a habit of coding for fun an hour every day incorporating and implementing new ideas. However, is there a <em>point</em> to me writing this blog post and working on these libraries if people will likely just reply &ldquo;tl;dr AI slop&rdquo; and &ldquo;it&rsquo;s vibecoded so it&rsquo;s automatically bad&rdquo;?</p>\n<p>The real annoying thing about Opus 4.6/Codex 5.3 is that it&rsquo;s impossible to publicly say &ldquo;Opus 4.5 (and the models that came after it) are an order of magnitude better than coding LLMs released just months before it&rdquo; without sounding like an AI hype booster clickbaiting, but it&rsquo;s the counterintuitive truth to my personal frustration. I have been trying to break this damn model by giving it complex tasks that would take me months to do by myself despite my coding pedigree but Opus and Codex keep doing them correctly. On Hacker News I was <a href=\"https://news.ycombinator.com/item?id=46979055\">accused of said clickbaiting</a> when making a similar statement with accusations of &ldquo;I haven&rsquo;t had success with Opus 4.5 so you must be lying.&rdquo; The remedy to this skepticism is to provide more evidence in addition to greater checks and balances, but what can you do if people refuse to believe your evidence?</p>\n<p>A year ago, I was one of those skeptics who was very suspicious of the agentic hype, but I was willing to change my priors in light of new evidence and experiences, which apparently is rare. Generative AI discourse has become too toxic and its discussions always end the same way, so I have been experimenting with touching grass instead, and it is nice. At this point, if I&rsquo;m not confident that I can please anyone with my use of AI, then I&rsquo;ll take solace in just pleasing myself. Continue open sourcing my projects, writing blog posts, and let the pieces fall as they may. If you want to follow along or learn when <code>rustlearn</code> releases, you can follow me <a href=\"https://bsky.app/profile/minimaxir.bsky.social\">on Bluesky</a>.</p>\n<p>Moment of introspection aside, I&rsquo;m not sure what the future holds for agents and generative AI. My use of agents has proven to have significant utility (for myself at the least) and I have more-than-enough high-impact projects in the pipeline to occupy me for a few months. Although certainly I will use LLMs more for coding apps which benefit from this optimization, that doesn&rsquo;t imply I will use LLMs more elsewhere: I still don&rsquo;t use LLMs for writing — in fact I have intentionally made my writing voice more sardonic to specifically fend off AI accusations.</p>\n<p>With respect to Rust, working with agents and seeing how the agents make decisions/diffs has actually helped me break out of the intermediate Rust slog and taught me a lot about the ecosystem by taking on more ambitious projects that required me to research and identify effective tools for modern Rust development. Even though I have <em>technically</em> released Rust packages with many stars on GitHub, I have no intention of putting Rust as a professional skill on my LinkedIn or my résumé. As an aside, how exactly do résumés work in an agentic coding world? Would &ldquo;wrote many open-source libraries through the use of agentic LLMs which increased the throughput of popular data science/machine learning algorithms by an order of magnitude&rdquo; be disqualifying to a prospective employer as they may think I&rsquo;m cheating and faking my expertise?</p>\n<p>My obligation as a professional coder is to do what works best, especially for open source code that other people will use. Agents are another tool in that toolbox with their own pros and cons. If you&rsquo;ve had poor experiences with agents before last November, I strongly urge you to give modern agents another shot, especially with an <code>AGENTS.md</code> tailored to your specific coding domain and nuances (again here are my <a href=\"https://gist.githubusercontent.com/minimaxir/10b780671ee5d695b4369b987413b38f/raw/f06ad4f1430a8d9f268b160a755dab817384c93c/AGENTS.md\">Python</a> and <a href=\"https://gist.githubusercontent.com/minimaxir/068ef4137a1b6c1dcefa785349c91728/raw/0fa5d1b505338b3a2c6834cc41e728cefe57511b/AGENTS.md\">Rust</a> files, in conveient copy/paste format).</p>\n<p>Overall, I&rsquo;m very sad at the state of agentic discourse but also very excited at its promise: it&rsquo;s currently unclear which one is the stronger emotion.</p>\n<div class=\"footnotes\" role=\"doc-endnotes\">\n<hr>\n<ol>\n<li id=\"fn:1\">\n<p>Two subtle ways agents can implicitly negatively affect the benchmark results but wouldn&rsquo;t be considered cheating/gaming it are a) implementing a form of caching so the benchmark tests are not independent and b) launching benchmarks in parallel on the same system. I eventually added <code>AGENTS.md</code> rules to ideally prevent both.&#160;<a href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\">&#x21a9;&#xfe0e;</a></p>\n</li>\n<li id=\"fn:2\">\n<p>The <code>treeboost</code> crate beat the agent-optimized GBT crate by 4x on my first comparison test, which naturally I took offense: I asked Opus 4.6 to &ldquo;Optimize the crate such that <code>rust_gbt</code> wins in ALL benchmarks against <code>treeboost</code>.&rdquo; and it did just that.&#160;<a href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\">&#x21a9;&#xfe0e;</a></p>\n</li>\n<li id=\"fn:3\">\n<p>Currently, only the macOS build has BLAS support as Win/Linux BLAS support is a rabbit hole that needs more time to investigate. On those platforms, numpy does win, but that won&rsquo;t be the case for long!&#160;<a href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\">&#x21a9;&#xfe0e;</a></p>\n</li>\n</ol>\n</div>\n",
    "description": "No vagueposting here, just look at the Estimated Read Time.",
    "is_fulltext": true,
    "source": "Max Woolf's Blog",
    "pub_date": "Fri, 27 Feb 2026 10:00:00 -0800",
    "fetched_at": "2026-02-28T00:33:59.357751",
    "url_hash": "1e287d7aaa3721effeca618a8b4fd5fb"
  },
  {
    "title": "Computers and the Internet: A Two-Edged Sword",
    "link": "https://blog.jim-nielsen.com/2026/two-edged-sword-of-computers-and-internet/",
    "content": "<p>Dave Rupert articulated something in <a href=\"https://daverupert.com/2026/02/computers-were-a-mistake-for-me/\" >“Priority of idle hands”</a> that’s been growing in my subconscious for years:</p>\n<blockquote>\n<p>I had a small, intrusive realization the other day that computers and the internet are probably bad for me […] This is hard to accept because a lot of my work, hobbies, education, entertainment, news, communities, and curiosities are all on the internet. I love the internet, it’s a big part of who I am today</p>\n</blockquote>\n<p>Hard same. I love computers and the internet. Always have. I feel lucky to have grown up in the late 90’s / early 00’s where I was exposed to the fascination, excitement, and imagination of  PCs, the internet, and then “mobile”. What a time to make websites!</p>\n<p>Simultaneously, I’ve seen how computers and the internet are a two-edged sword for me: I’ve cut out many great opportunities with them, but I’ve also cut myself a lot (and continue to).</p>\n<p>Per Dave’s comments, I have this feeling somewhere inside of me that the internet and computers don’t necessarily align in support my own, personal perspective of what a life well lived is <em>for me</em>. My excitement and draw to them also often leave me with a feeling of “I took that too far.” I still haven’t figured out a completely healthy balance (but I’m also doing ok).</p>\n<p>Dave comes up with a priority of constituencies to deal with his own realization. I like his. Might steal it. But I also think I need to adapt it, make it my own — but I don’t know what that looks like yet.</p>\n<p>To be honest, I don&#39;t think I was ready to confront any of this but reading Dave’s blog forced it out of my subconscious and into the open, so now I gotta deal.</p>\n<p>Thanks Dave.</p>\n\n    <hr />\n    \n\n    <p>\n      Reply via:\n      \n\n      <a\n        href=\"mailto:jimniels%2Bblog@gmail.com?subject=Re:%20blog.jim-nielsen.com/2026/two-edged-sword-of-computers-and-internet/\"\n        >Email</a\n      >\n      · <a href=\"https://mastodon.social/@jimniels\">Mastodon</a> ·\n\n      <a href=\"https://bsky.app/profile/jim-nielsen.com\">Bluesky</a>\n    </p>\n\n    \n  ",
    "description": "Dave Rupert articulated something in “Priority of idle hands” that’s been growing in my subconscious for years: I had a small, intrusive realization the other day that computers and the internet are probably bad for me […] This is hard to accept because a lot of my work, hobbies, education, entertainment, news, communities, and curiosities are all on the internet. I love the internet, it’s a big part of who I am today Hard same. I love computers and the internet. Always have. I feel lucky to hav",
    "is_fulltext": true,
    "source": "Jim Nielsen’s Blog",
    "pub_date": "Fri, 27 Feb 2026 19:00:00 GMT",
    "fetched_at": "2026-02-28T00:34:02.157373",
    "url_hash": "be13b04f4c018f5204c1cd50e39e49be"
  },
  {
    "title": "Wikipedia at 25: What the web can be",
    "link": "https://anildash.com/2026/01/15/wikipedia-at-25/",
    "content": "\n        \n      <p>When Wikipedia <a href=\"https://wikipedia25.org/en/\">launched 25 years ago today</a>, I heard about it almost immediately, because the Internet was small back then, and I thought “Well… good luck to those guys.” Because there had been online encyclopedias before Wikipedia, and anybody who really <em>cared</em> about this stuff would, of course, buy Microsoft Encarta on CD-ROM, right? I’d been fascinated by the technology of wikis for a good while at that point, but was still not convinced about whether they could be deployed at such a large scale.</p>\n<p>So, once Wikipedia got a little bit of traction, and I met Jimmy Wales the next year, I remember telling him (with all the arrogance that only a dude that age can bring to such an obvious point) “well, the <em>hard part</em> is going to be getting all the people to contribute”. As you may be aware, Jimmy, and a broad worldwide community of volunteers, did pretty well with the hard part.</p>\n<p>Wikipedia has, of course, become vital to the world’s information ecosystem. Which is why everyone needs to be aware of the fact that it is currently under <a href=\"https://www.theverge.com/cs/features/717322/wikipedia-attacks-neutrality-history-jimmy-wales\">existential threat</a> from those who see any reliable source of truth as an attack on their power. The same authoritarians in power who are trying to purchase every media outlet and social network where ordinary people might have a chance to share accurate information about their crimes or human rights violations are deeply threatened about a platform that they can’t control and can’t own.</p>\n<p>Perhaps the greatest compliment to Wikipedia at 25 years old is the fact that, if the fascists can’t buy it, then they’re going to try to kill it.</p>\n<h2>The Building Block</h2>\n<p>What I couldn’t foresee in the early days, when so many were desperate to make sure that Wikipedia wasn’t treated as a credible source — there were <em>so many</em> panicked conversations about how to keep kids from citing the site in their school papers — was how the site would become infrastructure for so much of the commercial internet.</p>\n<p>The first hint was when Google introduced their “Knowledge Panel”, the little box of info next to their search results that tried to explain what you were looking for, without you even having to click through to a website. For Google, this had a huge economic value, because it kept you on their search results page where all their ad links lived. The vast majority of the Knowledge Panel content for many major topics was basically just Wikipedia content, summarized and wrapped up in a nice little box. Here was the most valuable company of the new era of the Internet, and one of their signature experiences relied on the strength of the Wikipedia community’s work.</p>\n<p>This was, of course, complemented by the fact that Wikipedia would also organically show up right near the top of so many search results just based on the strength of the content that the community was cranking out at a remarkable pace. Though it probably made Google bristle a little bit that those damn Wikipedia pages didn’t have any Google ads on them, and didn’t have any of Google’s tracking code on them, so they couldn’t surveil what you do when you were clicking around on the site, making it impossible for them to spy on you and improve the targeting of their advertising to you.</p>\n<p>The same pattern played out later for the other major platforms; Apple’s Siri and Amazon’s Alexa both default to using Wikipedia data to answer common questions. During the few years when Facebook pretended to care about misinformation, they would show summaries of Wikipedia information in the news feed to help users fact-check misinformation that was being shared.</p>\n<p>Unsurprisingly, a lot of the time when the big companies would try to use Wikipedia as the water to put out the fires that they’d started, they <a href=\"https://www.wired.com/story/youtube-wikipedia-content-moderation-internet/\">didn’t even bother to let the organization know</a> before they started doing so, burdening the non-profit with the cost and complexity of handling their millions of users and billions of requests, without sharing any of their trillions of dollars. (At least until there was public uproar over the practice.) Eventually, Wikimedia Foundation (the organization that runs Wikipedia) made a way for <a href=\"https://enterprise.wikimedia.com\">companies to make deals with them</a> and actually support the community instead of just extracting from the community without compensation.</p>\n<h2>The culture war comes for Wikipedia</h2>\n<p>Things had reached a bit of equilibrium for a few years, even as the larger media ecosystem started to crumble, because the world could see after a few decades that Wikipedia had become a vital and valuable foundation to the global knowledge ecology. It’s almost impossible to imagine how the modern internet would function without it.</p>\n<p>But as the global fascist movement has risen in recent years, one of their first priorities, as in all previous such movements, has been undermining any sources of truth that can challenge their control over information and public sentiment. In the U.S., this has manifested from the top-down with the richest tycoons in the country, including Elon Musk, stoking sentiment against Wikipedia with vague innuendo and baseless attacks against the site. This is also why Musk has funded the creation of alternatives like Grokipedia, designed to undermine the centrality and success of Wikipedia. From the bottom-up, there have been individual bad actors who have attempted to infiltrate the ranks of editors on the site, or worked to deface articles, often working slowly or across broad swaths of content in order to attempt to avoid detection.</p>\n<p>All of this has been carefully coordinated; as noted in <a href=\"https://www.theverge.com/cs/features/717322/wikipedia-attacks-neutrality-history-jimmy-wales\">well-documented pieces like the Verge’s excellent coverage</a> of the story, the attack on Wikipedia is a campaign that has been led by voices like Christopher Rufo, who helped devise campaigns like the concerted effort to demonize trans kids as a cultural scapegoat, and the intentional targeting of Ivy League presidents as part of the war on DEI. The undermining of Wikipedia hasn’t yet gotten the same traction, but they also haven’t yet put the same time and resources into the fight.</p>\n<p>There’s been such a constant stream of vitriol directed at Wikipedia and its editors and leadership that, when I heard about a <a href=\"https://gothamist.com/news/gunman-storms-stage-at-wikipedia-conference-in-manhattan-no-injuries-reported\">gunman storming the stage</a> at the recent gathering of Wikipedia editors, I had <em>assumed</em> it was someone who had been incited by the baseless attacks from the extremists. (It turned out to have been someone who was disturbed on his own, which he said was tied to the editorial policies of the site.) But I would expect it’s only a matter of time until the attacks on Wikipedia’s staff and volunteers take on a far more serious tone much of the time — and it’s not as if this is an organization that has a massive security budget like the trillion-dollar tech companies.</p>\n<p>The temperature keeps rising, and there isn’t yet sufficient awareness amongst good actors to protect the Wikipedia community and to guard its larger place in society.</p>\n<h2>Enter the AI era</h2>\n<p>Against this constant backdrop of increasing political escalation, there’s also been the astronomical ramp-up in demand for Wikipedia content from AI platforms. The very first source of data for many teams when training a new LLM system is Wikipedia, and the vast majority of the time, they gather that data not by paying to license the content, but by “scraping” it from the site — which uses both more technical resources and precludes the possibility of establishing any consensual paid relationship with the site.</p>\n<p>A way to think about it is that, for the AI world, they’re music fans trading Wikipedia like it’s MP3s on Napster, and conveniently ignoring the fact there’s an Apple Music or Spotify offering a legitimate way to get that same data while supporting the artist. Hopefully the <a href=\"https://www.anildash.com/2025/09/18/the-taylors-version-generation/\">“Taylor’s Version” generation</a> can see Wikipedia as being at least as worthy of supporting as a billionaire like Taylor Swift is.</p>\n<p>But as people start going to their AI apps first, or chatting with bots instead of doing Google searches, they don’t <em>see</em> those Knowledge Panels anymore, and they don’t click through to Wikipedia anymore. At a surface level, this hurts traffic to the site, but at a deeper level, this hurts the flow of new contributors to the site. Interestingly, though I’ve been linking to <a href=\"https://www.anildash.com/2006/07/31/quitting-wikipe/\">critiques of Wikipedia</a> on my site for at least twenty years, for most of the last few decades, my biggest criticism of Wikipedia has long been the lack of inclusion amongst its base of editorial volunteers. But this is, at least, a shortcoming that both the Wikimedia Foundation and the community itself readily acknowledge and have been working diligently on.</p>\n<p>That lack of diversity in editors as a problem will pale in comparison to the challenge presented if people stop coming to the front door entirely because they’re too busy talking to their AI bots. They may not even <em>know</em> what parts of the answers they’re getting from AI are due to the bot having slurped up the content from Wikipedia. Worse, they’ll have been so used to constantly encountering hallucinations that the idea of joining a community that’s constantly trying to improve the accuracy of information will seem quaint, or even <em>absurd</em>, in a world where everything is wrong and made up all the time.</p>\n<p>This means that it’s in the best interests of the AI platforms to not only pay to sustain Wikipedia and its community so that there’s a continuous source of new, accurate information over time, but that it’s also in their interest to keep teaching their community about the value of such a resource. The very fact that people are so desperate to chat with a bot shows how hungry they are for connection, and just imagine how excited they’d be to connect with the <em>actual humans</em> of the Wikipedia community!</p>\n<h2>We can still build</h2>\n<p>It’s easy to forget how radical Wikipedia was at its start. For the majority of people on the Internet, Wikipedia is just something that’s been omnipresent right from the start. But, as someone who got to watch it rise, take it from me: this was a thing that lots of regular people <em>built together</em>. And it was explicitly done as a collaboration meant to show the spirit of what the Internet is really about.</p>\n<p><a href=\"https://wikimediafoundation.org/wikipedia25/\">Take a look at its history</a>. Think about what it means that there is no advertising, and there never has been. It doesn’t track your activity. You can edit the site <em>without even logging in</em>. If you make an account, you don’t have to use your real name if you’d like to stay anonymous. When I wrote about <a href=\"https://www.anildash.com/2008/09/22/alan-leeds-and-who-writes-the-web/\">being the creator</a> of an entirely <em>new</em> page on Wikipedia, it felt like magic, and it still does! You can be the person that births something onto the Internet that feels like it becomes a permanent part of the historical record, and then others around the world will help make it better, forever.</p>\n<p>The site is still amongst the most popular sites on the web, bigger than almost every commercial website or app that has ever existed. There’s never been a single ad promoting it. It has unlocked <em>trillions</em> of dollars in value for the business world, and unmeasurable educational value for multiple generations of children. Did you know that for many, many topics, you can change your language from English to <em>Simple English</em> and get an <a href=\"https://simple.wikipedia.org/wiki/Quadratic_equation\">easier-to-understand</a> version of an article that can often help explain a concept in much more approachable terms? Wikipedia has a <a href=\"https://www.wikivoyage.org\">travel guide</a>! A <a href=\"https://www.wiktionary.org\">dictionary</a>! A <a href=\"https://www.wikibooks.org\">collection of textbooks and cookbooks</a>! Here are <a href=\"https://species.wikimedia.org/\">all the species</a>! It’s unimaginably deep.</p>\n<p>Whenever I worry about where the Internet is headed, I remember that this example of the collective generosity and goodness of people still exists. There are so many folks just working away, every day, to make something good and valuable for strangers out there, simply from the goodness of their hearts. They have no way of ever knowing who they’ve helped. But they believe in the simple power of doing a little bit of good using some of the most basic technologies of the internet. Twenty-five years later, all of the evidence has shown that they really have changed the world.</p>\n<hr>\n<p>If you are able, today is a very good day to <a href=\"https://donate.wikimedia.org/\">support the Wikimedia Foundation</a>.</p>\n\n    \n      ",
    "description": "",
    "is_fulltext": true,
    "source": "Anil Dash",
    "pub_date": "2026-01-15T00:00:00Z",
    "fetched_at": "2026-02-28T00:34:23.439737",
    "url_hash": "d23d1407fed1ad329b50b4d62b9c1b92"
  },
  {
    "title": "cash issuing terminals",
    "link": "https://computer.rip/2026-02-27-ibm-atm.html",
    "content": "  <p>In the United States, we are losing our fondness for cash. As in many other\ncountries, cards and other types of electronic payments now dominate everyday\ncommerce. To some, this is a loss. Cash represented a certain freedom from\nintermediation, a comforting simplicity, that you just don't get from Visa.\nIt's funny to consider, then, how cash is in fact quite amenable to automation.\nEven Benjamin Franklin's face on a piece of paper can feel like a mere proxy\nfor a database transaction. How different from &quot;e-cash&quot; is cash itself, when\nit starts and ends its lifecycle through automation?</p>\n<p>Increasing automation of cash reflects the changing nature of banking: decades\nago, a consumer might have interacted with banking primarily through a &quot;passbook&quot;\nsavings account, where transactions were so infrequent that the bank recorded\nthem directly in the patron's copy of the passbook. Over the years, nationwide\ntravel and nationwide communications led to the ubiquitous use of inter-bank\nmoney transfers, mostly in the form of the check. The accounts that checks\ntypically drew on—checking accounts—were made for convenience and ease of\naccess. You might deposit your entire paycheck into an account, it might even\nbe sent there automatically... and then when you needed a little walking around\nmoney, you would withdraw cash by the assistance of a teller. By the time I was\na banked consumer, even the teller was mostly gone. Today, we get our cash from\nmachines so that it can be deposited into other machines.</p>\n<p><img src=\"https://computer.rip/static/img/ibm_atm/1.jpg\" alt=\"IBM 2984 ATM\" /></p>\n<p>Cash handling is fraught with peril. Bills are fairly small and easy to hide,\nand yet quite valuable. Automation in the banking world first focused on solving\nthis problem, of reliable and secure cash handling within the bank branch. The\nprimary measure against theft by insiders was that the theft would be discovered,\nas a result of the careful bookkeeping that typifies banks. But, well, that\nbookkeeping was surprisingly labor-intensive in even the bank of the 1950s.</p>\n<p>Histories of the ATM usually focus on just that: the ATM. It's an interesting\nstory, but one that I haven't been particularly inclined to cover due to the\nlack of a compelling angle. Let's try IBM. IBM is such an important, famous\nplayer in business automation that it forms something of a synecdoche for the\nlarger industry. Even so, in the world of bank cash handling, IBM's efforts\nultimately failed... a surprising outcome, given their dominance in the machines\nthat actually did the accounting.</p>\n<p>In this article, we'll examine the history of ATMs—by IBM. IBM was just one of\nthe players in the ATM industry and, by its maturity, not even one of the more\nimportant ones. But the company has a legacy of banking products that put the\nATM in a more interesting context, and despite lackluster adoption of later IBM\nmodels, their efforts were still influential enough that later ATMs inherited\nsome of IBM's signature design concepts. I mean that more literally than you\nmight think. But first, we have to understand where ATMs came from. We'll start\nwith branch banking.</p>\n<p>When you open a bank account, you typically do so at a &quot;branch,&quot; one of many\nphysical locations that a national bank maintains. Let us imagine that you are\nopening an account at your local branch of a major bank sometime around 1930;\nwhether before or after that year's bank run is up to you. Regardless of the\nturbulent economic times, the branch became responsible for tracking the balance\nof your account. When you deposit money, a teller writes up a slip. When you\ncome back and withdraw money, a different teller writes up a different slip. At\nthe end of each business day, all of these slips (which basically constitute\na journal in accounting terminology) have to be rounded up by the back office\nand posted to the ledger for your account, which was naturally kept as a card in\na big binder.</p>\n<p>A perfectly practicable 1930s technology, but you can already see the downsides.\nImagine that you appear at a <em>different</em> branch to withdraw money from your\naccount. Fortunately this was not very common at the time, and you would be more\nlikely to use other means of moving money in most scenarios. Still, the bank\ntries to accommodate. The branch at which you have appeared can dispense cash,\nwrite a slip, and then send it to the correct branch for posting... but they\nalso need to post it to their own ledger that tracks transactions for foreign\naccounts, since they need to be able to reconcile where their cash went. And\nthat ignores the whole issue of who you are, whether or not you even have an\naccount at another branch, and whether or not you have enough money to cover the\nwithdrawal. Those are problems that, mercifully, could mostly be sorted out with\na phone call to your home branch.</p>\n<p>Bank branches, being branches, do not exist in isolation. The bank also has a\nheadquarters, which tracks the finances of its various branches—both to know the\nbank's overall financial posture (critical considering how banks fail), and to\nprovide controls against insider theft. Yes, that means that each of the branch\nbanks had to produce various reports and ledger copies and then send them by\ncourier to the bank headquarters, where an army of clerks in yet another back\noffice did yet another round of arithmetic to produce the bank's overall\nledgers.</p>\n<p>As the United States entered World War II, an expanding economy, rapid\nindustrial buildup, and a huge increase in national mobility (brought on by\nthings like the railroads and highways) caused all of these tasks to occur on\nlarger and larger scales. Major banks expanded into a tiered system, in which\nbranches reported their transactions to &quot;regional centers&quot; for reconciliation\nand further reporting up to headquarters. The largest banks turned to unit\nrecord equipment or &quot;business machines,&quot; arguably the first form of business\ncomputing: punched card machines that did not evaluate programs, but sorted and\nsummed.</p>\n<p>Simple punched card equipment gave way to advanced punched card equipment,\ninnovations like the &quot;posting machine.&quot; These did exactly what they promised:\ngiven a stack of punched cards encoding transactions, they produced a ledger\nwith accurately computed sums. Specialized posting machines were made for\nindustries ranging from hospitality (posting room service and dining charges\nto room folios) to every part of finance, and might be built custom to the\nbusiness process of a large customer.</p>\n<p>If tellers punched transactions into cards, the bank could come much\ncloser to automation by shipping the cards around for processing at each office.\nBut then, if transactions are logged in a machine readable format, and then\nprocessed by machines, do we really need to courier them to rooms full of\nclerks?</p>\n<p>Well, yes, because that was the state of technology in the 1930s. But it would\nnot stay that way for long.</p>\n<p>In 1950, Bank of America approached SRI about the feasibility of an automated\ncheck processing system. Use of checks was rapidly increasing, as were total\naccount holders, and the resulting increase in inter-branch transactions was\nclearly overextending BoA's workforce—to such an extent that some branches were\ncurtailing their business hours to make more time for daily closing. By 1950,\ncomputer technology had advanced to such a state that it was obviously possible\nto automate this activity, but it still represented one of the most ambitious\nefforts in business computing to date.</p>\n<p>BoA wanted a system that would not only automate the posting of transactions\nprepared by tellers, but actually automate the handling of the checks\nthemselves. SRI and, later, their chosen manufacturing partner General Electric\nran a multi-year R&amp;D campaign on automated check handling that ultimately lead\nto the design of the checks that we use today: preprinted slips with account\nholder information, and account number, already in place. And, most importantly,\ncertain key fields (like account number and check number) represented in a newly\ndeveloped machine-readable format called &quot;MICR&quot; for magnetic ink character\nrecognition. This format remains in use today, to the extent that checks remain\nin use, although as a practical matter MICR has given way to the more familiar\nOCR (aided greatly by the constrained and standardized MICR character set).</p>\n<p>The machine that came out of this initiative was called ERMA, the Electronic\nRecording Machine, Accounting. I will no doubt one day devote a full article\nto ERMA, as it holds a key position in the history of business computing while\nalso managing to not have much of a progeny due to General Electric's failure to\nbecome a serious contender in the computer industry. ERMA did not lead to a\nwhole line of large-scale &quot;ERM&quot; business systems as GE had hoped, but it did\nfirmly establish the role of the computer in accounting, automate parts of the\nbookkeeping through almost the entirety of what would become the nation's\nlargest bank, and inspire generations of products from other computer\nmanufacturers.</p>\n<p>The first ERMA system went into use in 1959. While IBM was the leader in unit\nrecord equipment and very familiar to the banking industry, it took a few years\nfor Big Blue to bring their own version. Still, IBM had their own legacy to\nbuild on, including complex electromechanical machines that performed some of\nthe tasks that ERMA was taking over. Since the 1930s, IBM had produced a line of\ncheck processing or &quot;proofing&quot; machines. These didn't exactly &quot;automate&quot; check\nhandling, but they did allow a single operator to handle a <em>lot</em> of documents.</p>\n<p>The IBM 801, 802, and 803 line of check proofers used what were fundamentally\nunit record techniques—keypunch, sorting bins, mechanical totalizers—to present\nchecks one at a time in front of the operator, who read information like the\namount, account number, and check number off of the paper slip and entered it\non a keypad. The machine then whisked the check away, printing the keyed data\n(and reference numbers for auditing) on the back of the check, stamped an\nendorsement, added the check's amounts to the branch's daily totals (including\nsubtotals by document type), and deposited the check in an appropriate sorter\nbin to be couriered to the drawer's bank. While all this happened, the machines\nalso printed the keyed check information and totals onto paper tapes.</p>\n<p>By the early 1960s, with ERMA on the scene, IBM's started to catch up.\nSubsequent check processing systems gained support for MICR, eliminating much\n(sometimes all!) of the operator's keying. Since the check proofing machines\ncould also handle deposit slips, a branch that generated MICR-marked deposit\nslips could eliminate most of the human touchpoints involved in routine banking.\nA typical branch bank setup might involve an IBM 1210 document\nreader/sorter machine connected by serial channel to an IBM 1401 computer.\nThis system behaved much like the older check proofers, reading documents,\nlogging them, and calculating totals. But it was now all under computer control,\nwith the flexibility and complexity that entails.</p>\n<p>One of these setups could process almost a thousand checks a minute with a\nlittle help from an operator, and adoption of electronic technology at other\nstages made clerk's lives easier. For example, IBM's mid-1960s equipment\nintroduced solid-state memory. The IBM 1260 was used for adding machine-readable\nMICR data to documents that didn't already have it. Through an innovation that\nwe would now call a trivial buffer, the 1260's operator could key in the numbers\nfrom the next document while the printer was still working on the previous.</p>\n<p>Along with improvements in branch bank equipment came a new line of &quot;high-speed&quot;\nsystems. In a previous career, I worked at a Federal Reserve bank, where\n&quot;high-speed&quot; was used as the name of a department in the basement vault. There,\nhuge machines processed currency to pick out bad bills. This use of &quot;high-speed&quot;\nseems to date to an IBM collaboration with the Federal Reserve to build machines\nfor central clearinghouses, handling checks by the tens of thousands. By the\ntime I found myself in central banking, the use of &quot;high-speed&quot; machinery for\nchecks was a thing of the past—&quot;digital substitute&quot; documents or image-based\nclearing having completely replaced physical handling of paper checks. Still,\nthe &quot;high-speed&quot; staff labored on in their ballistic glass cages, tending to the\ngreen paper slips that the institution still dispenses by the millions.</p>\n<p><img src=\"https://computer.rip/static/img/ibm_atm/2.png\" alt=\"IBM service documentation\" /></p>\n<p>One of the interesting things about the ATM is when, exactly, it pops up in the\nhistory of computers. We are, right now, in the 1960s. The credit card is in its\nnascent stages, MasterCard's predecessor pops up in 1966 to compete with Bank of\nAmerica's own partially ERMA-powered charge card offering. With computer systems\nmaintaining account sums, and document processing machines communicating with\nbookkeeping computers in real-time, it would seem that we are on the very cusp\nof online transaction authorization, which must be the fundamental key to the\nATM. ATMs hand out cash, and one thing we all know about cash is that once you\ngive yours to someone else you are very unlikely to get it back. ATMs, therefore,\nmust not dispense cash unless they can confirm that the account holder is &quot;good\nfor it.&quot; Otherwise the obvious fraud opportunity would easily wipe out the\nbenefits.</p>\n<p>So, what do you do? It seems obvious, right? You connect the ATM to the\nbookkeeping computer so it can check account balances before dispensing cash.\nSimple enough.</p>\n<p>But that's not actually how the ATM evolved, not at all. There are plenty of\nreasons. Computers were very expensive so banks centralized functions and not\nall branches had one. Long-distance computer communication links were very\nexpensive as well, and still, in general, an unproven technology. Besides, the\ncomputer systems used by banks were fundamentally batch-mode machines, and it\nwas difficult to see how you would shove an ATM's random interruptions into the\nprogramming model.</p>\n<p>Instead, the first ATMs were token-based. Much like an NYC commuter of the era\ncould convert cash into a subway token, the first ATMs were machines that\nconverted tokens into cash. You had to have a token—and to get one, you appeared\nat a teller during business hours, who essentially dispensed the token as if it\nwere a routine cash withdrawal.</p>\n<p>It seems a little wacky to modern sensibilities, but keep in mind that this was\nthe era of the traveler's check. A lot of consumers didn't want to carry a lot\nof cash around with them, but they did want to be able to get cash after hours.\nBy seeing a teller to get a few ATM tokens (usually worth $10 or £10 and\nsometimes available only in that denomination), you had the ability to retrieve\ncash, but only carried a bank document that was thought (due to features like\nrevocability and the presence of ATMs under bank surveillance) to be relatively\nsecure against theft. Since the tokens were later &quot;cleared&quot; against accounts\nmuch like checks, losing them wasn't necessarily a big deal, as something\nanalogous to a &quot;stop payment&quot; was usually possible.</p>\n<p>Unlike subway tokens, these were not coin-shaped. The most common scheme was a\npaper card, often the same dimensions as a modern credit card, but with punched\nholes that encoded the denomination and account holder information. The punched\nholes were also viewed as an anti-counterfeiting measure, probably not one that\nwould hold up today, but still a roadblock to fraudsters who would have a hard\ntime locating a keypunch and a valid account number. Manufacturers also\nexplored some other intriguing opportunities, like the very first production\ncash dispenser, 1967's Barclaycash machine. This proto-ATM used punched paper\ntokens that were also printed in part with a Carbon-14 ink. Carbon-14 is\nunstable and emits beta radiation, which the ATM detected with a simple\nelectrostatic sensor. For some reason difficult to divine the radioactive\nATM card did not catch on.</p>\n<p>For roughly the first decade of the &quot;cash machine,&quot; they were offline devices\nthat issued cash based on validating a token. The actual decision making, on\nthe worthiness of a bank customer to withdraw cash, was still deferred to the\nteller who issued the tokens. Whether or not you would even consider this an ATM\nis debatable, although historical accounts generally do. They are certainly of a\ndifferent breed than the modern online ATM, but they also set some of the\npatterns we still follow. Consider, for example, the ATMs within my lifespan\nthat accepted deposits in an envelope. These ATMs did nothing with the envelopes\nother than accumulate them into a bin to go to a central processing center later\non—the same way that early token-based ATMs introduced deposit boxes.</p>\n<p>In this theory of ATM evolution, the missing link that made\n1960s-1970s ATMs so primitive was the lack of computer systems that were\namenable to real-time data processing using networked peripherals. The '60s and\n'70s were a remarkable era in computer history, though, seeing the introduction\nof IBM's System/360 and System/370 line. These machines were more powerful,\nmore flexible, and more interoperable than any before them. I think it's fair to\nsay that, despite earlier dabbling, it was the 360/370 that truly ushered in the\nera of business computing. Banks didn't miss out.</p>\n<p>One of the innovations of the System/360 was an improved and standardized\narchitecture for the connection of peripherals to the machine. While earlier\nIBM models had supported all kinds of external devices, there was a lot of\ncustom integration to make that happen. With the System/360, this took the form\nof &quot;Bisync,&quot; which I might grandly call a far ancestor of USB. Bisync allowed a\n360 computer to communicate with multiple peripherals connected to a common\nmulti-drop bus, even using different logical communications protocols. While the\nfirst Bisync peripherals were &quot;remote job entry&quot; terminals for interacting\nwith the machine via punched cards and teletype, IBM and other manufacturers\nfound more and more applications in the following years.</p>\n<p><img src=\"https://computer.rip/static/img/ibm_atm/3.png\" alt=\"IBM 3214 ATM\" /></p>\n<p>IBM had already built document processing machines that interacted with their\ncomputers. In 1971, IBM joined the credit card fray with the 2730, a\n&quot;transaction&quot; terminal that we would now recognize as a credit card reader. It\nused a Bisync connection to a System/360-class machine to authorize a credit\ntransaction in real time. The very next year, IBM took the logical next step:\nthe IBM 2984 Cash Issuing Terminal. Like many other early ATMs, the 2984 had its\ndebut in the UK as Lloyds Bank's &quot;Cashpoint.&quot;</p>\n<p>The 2984 similarly used Bisync communications with a System/360. While not the\nvery first implementation of the concept, the 2984 was an important step in ATM\nsecurity and the progenitor of an important line of cryptographic algorithms.\nTo withdraw cash, a user inserted a magnetic card that contained an account\nnumber, and then keyed in a PIN. The 2984 sent this information, over the Bisync\nconnection, to the computer, which then responded with a command such as\n&quot;dispense cash.&quot; In some cases the computer was immediately on the other side of\nthe wall, but it was already apparent that banks would install ATMs in remote\nlocations controlled via leased telephone lines—and those telephone lines were\nnot well-secured. A motivated attacker (and with cash involved, it's easy to be\nmotivated!) could probably &quot;tap&quot; the ATM's network connection and issue it\nspurious &quot;dispense cash&quot; commands. To prevent this problem, and assuage the\nconcerns of bankers who were nervous about dispensing cash so far from the\nbranch's many controls, IBM decided to <em>encrypt</em> the network connection.</p>\n<p>The concept of an encrypted network connection was not at all new; encrypted\ncommunications were widely used in the military during the second World War and\nthe concept was well-known in the computer industry. As IBM designed the 2984,\nin the late '60s, encrypted computer links were nonetheless very rare. There\nwere not yet generally accepted standards, and cryptography as an academic\ndiscipline was immature.</p>\n<p>IBM, to secure the 2984's network connection, turned to an algorithm recently\ndeveloped by an IBM researcher named Horst Feistel. Feistel, for silly reasons,\nhad named his family of experimental block ciphers LUCIFER. For the 2984, a\nmodified version of one of the LUCIFER implementations called DSD-1<sup class=\"footnote-ref\" id=\"fnref-1\"><a href=\"#fn-1\">1</a></sup>. Through\na Bureau of Standards design competition and the twists and turns of industry\npolitics, DSD-1 later reemerged (with just slight changes) as the Data Encryption\nStandard, or DES. We owe the humble ATM honors for its key role in computer\ncryptography.</p>\n<p>The 2984 was a huge step forward. Unlike the token-based machines of the 1960s,\nit was pretty much the same as the ATMs we use today. To use a 2984, you\ninserted your ATM card and entered a PIN. You could then choose to check your\nbalance, and then enter how much cash you wanted. The machine checked your\nbalance in real time and, if it was high enough, debited your account\nimmediately before coughing up money.</p>\n<p>The 2984 was not as successful as you might expect. The Lloyd's Bank rollout was\nbig, but very few were installed by other banks. Collective memory of the 2984\nis vague enough that I cannot give a definitive reason for its limited success,\nbut I think it likely comes down to a common tale about IBM: price and\nflexibility. The 2984 was essentially a semi-custom peripheral, designed for\nLloyd's Bank and the specific System/360 environment already in place there.\nAdoption for other banks was quite costly. Besides, despite the ATM's lead in\nthe UK, the US industry had quickly caught up. By the time the 2984 would be\nconsidered by other banks, there were several different ATMs available in the US from\nother manufacturers (some of them the same names you see on ATMs today). The\n2984 is probably the first &quot;modern&quot; ATM, but since IBM spent 4-5 years\ndeveloping it, it was not as far ahead of the curve on launch day as you might\nexpect. Just a year or two later, a now-forgotten company called Docutel was\ndominating the US market, leaving IBM little room to fit in.</p>\n<p>Because most other ATMs were offered by companies that didn't control the entire\nsoftware stack, they were more flexible, designed to work with simpler host\nsupport. There is something of an inverse vertical integration penalty here:\nwhen introducing a new product, close integration with an existing product\nfamily makes it difficult to sell! Still, it's interesting that the 2984 used\npretty much the same basic architecture as the many ATMs that followed. It's\nworth reflecting on the 2984's relationship with its host, a close dependency\nthat generally holds true for modern ATMs as well.</p>\n<p>The 2984 connected to its host via a Bisync channel (possibly over various\ncarrier or modem systems to accommodate remote ATMs), a communications facility\noriginally provided for remote job entry, the conceptual ancestor of IBM's later\nblock-oriented terminals. That means that the host computer expected the\nperipheral to provide some input for a job and then wait to be sent the results.\nRemote job entry devices, and block terminals later, can be confusing when\ncompared to more familiar, Unix-family terminals. In some ways, they were quite\nsophisticated, with the host computer able to send configuration information\nlike validation rules for input. In other ways, they were very primitive,\ncapable of no real logic other than receiving computer output (which was dumped\nto cards, TTY, or screen) and then sending computer input (from much the same\ndevices). So, the ATM behaved the same way.</p>\n<p>In simple terms, the ATM's small display (called a VDU or Video Display Unit in\ntypical IBM terminology) showed whatever the computer sent as the body of a\n&quot;display&quot; command. It dispensed whatever cash the computer indicated with a\n&quot;dispense cash&quot; command. Any user input, such as reading a card or entry of a\nPIN number, was sent directly to the computer. The host was responsible for all\nof the actual logic, and the ATM was a dumb terminal, just doing exactly what\nthe computer said. You can think of the Cash Issuing Terminal as, well, just\nthat: a mainframe terminal with a weird physical interface.</p>\n<p><img src=\"https://computer.rip/static/img/ibm_atm/4.png\" alt=\"IBM 4700 series documentation\" /></p>\n<p>Most modern ATMs follow this same model, although the actual protocol has\nbecome more sophisticated and involves a great deal more XML. You can be\nreassured that when the ATM takes a frustratingly long time to advance to the\nnext screen, it is at least waiting to receive the contents of that screen from\na host computer that is some distance away or, even worse, in The Cloud.</p>\n<p>Incidentally, you might wonder about the software that ran on the host computer.\nI believe that the IBM 2984 was designed for use with CICS, the Customer\nInformation Control System. CICS will one day get its own article, but it\nlaunched in 1966, built specifically for the Michigan Bell to manage customer\nand billing data. Over the following years, CICS was extensively expanded for\nuse in the utility and later finance industries. I don't think it's inaccurate\nto call CICS the first &quot;enterprise customer relationship management system,&quot;\nthe first voyage in an adventure that took us through Siebel before grounding\non the rocks of Salesforce. Today we wouldn't think of a CRM as the system of\nrecord for depository finance institutions like banks, but CICS itself was\nvery finance-oriented from the start (telephone companies sometimes felt like\naccounting firms that ran phones on the side) and took naturally to gathering\ntransactions and posting them against customer accounts. Since CICS was designed\nas an online system to serve telephone and in-person customer service reps (in\nfact making CICS a very notable early real-time computing system), it was also a\ngood fit for handling ATM requests throughout the day.</p>\n<div class=\"beg\">\n<hr />\n<p>I put a lot of time into writing this, and I hope that you enjoy reading\nit. If you can spare a few dollars, consider <a href=\"https://ko-fi.com/jbcrawford\">supporting me on\nko-fi</a>. You'll receive an occasional extra,\nsubscribers-only post, and defray the costs of providing artisanal, hand-built\nworld wide web directly from Albuquerque, New Mexico.</p>\n<hr />\n</div>\n<p>Despite the 2984's lackluster success, IBM moved on. I don't think IBM was\nparticularly surprised by the outcome, the 2984 was always a &quot;request quotation&quot;\n(e.g. custom) product. IBM probably regarded it as a prototype or pilot with\ntheir friendly customer Lloyds Bank. More than actual deployment, the 2984's\nachievement was paving the way for the IBM 3614 Consumer Transaction Facility.</p>\n<p>In 1970, IBM had replaced the System/360 line with the System/370. The 370 is\ndirectly based on the 360 and uses the same instruction set, but it came with\nnumerous improvements. Among them was a new approach to peripheral connectivity\nthat developed into the IBM Systems Network Architecture, or SNA, basically\nIBM's entry into the computer networking wars of the 1970s and 1980s. While SNA\nwould ultimately cede to IP (with, naturally, an interregnum of SNA-over-IP),\nit gave IBM the foundations for networked systems that are <em>almost</em> modern in\ntheir look and feel.</p>\n<p>I say <em>almost</em> because SNA was still very much a mainframe-oriented design. An\nexample SNA network might look like this: An S/370 computer running CICS (or\none of several other IBM software packages with SNA support) is connected via\nchannel (the high-speed peripheral bus on mainframe computers, analogous to PCI)\nto an IBM 3705 Communications Controller running the Network Control Program\n(analogous to a network interface controller). The 3705 had one or more\n&quot;scanners&quot; installed, which supported simple low-speed serial lines or fast,\nhigh-level protocols like SDLC (synchronous data link control) used by SNA. The\n3705 fills a role sometimes called a &quot;front-end processor,&quot; doing the grunt work\nof polling (scanning) communications lines and implementing the SDLC protocol\nso that the &quot;actual computer&quot; was relieved of these menial tasks.</p>\n<p>At the other end of one of the SDLC links might be an IBM 3770 Data\nCommunications System, which was superficially a large terminal that, depending\non options ordered, could include a teletypewriter, card reader and punch,\ndiskette drives, and a high speed printer. Yes, the 3770 is basically a grown-up\nremote job entry terminal, and the SNA/SDLC stack was a direct evolution from\nthe Bisync stack used by the 2984. The 3770 had a bit more to offer, though:\nin order to handle its multiple devices, like the printer and card punch, it\nacted as a sort of network switch—the host computer identified the 3770's\ndevices as separate endpoints, and the 3770 interleaved their respective\ntraffic. It could also perform that interleaving function for additional\nperipherals connected to it by serial  lines, which depending on customer\nrequirements often included additional card punches and readers for data entry,\nor line printers for things like warehouse picking slips.</p>\n<p>In 1973, IBM gave banks the SNA treatment with the 3600 Finance Communication\nSystem <sup class=\"footnote-ref\" id=\"fnref-2\"><a href=\"#fn-2\">2</a></sup>. A beautifully orange brochure tells us:</p>\n<blockquote>\n<p>The IBM 3600 Finance Communication System is a family of products designed to\nprovide the Finance Industry with remote on-line teller station operation.</p>\n</blockquote>\n<p>System/370 computers represented an enormous investment, generally around a\nmillion dollars and more often above that point than below. They were also large\nand required both infrastructure and staff to support them. Banks were already\nnot inclined to install an S/370 in each branch, so it became a common pattern\nto place a &quot;full-size&quot; computer like an S/370 in a central processing center to\nsupport remote peripherals (over leased telephone line) in branches. The 3600\nwas a turn-key product line for exactly this use.</p>\n<p>An S/370 computer with a 3704 or 3705 running the NCP would connect (usually\nover a leased line) to a 3601 System, which IBM describes as a\n&quot;programmable communications controller&quot; although they do not seem to have\nelevated that phrase to a product name. The 3601 is basically a minicomputer of\nits own, with up to 20KB of user-available memory and diskette drive. A 3601\nincludes, as standard, a 9600 bps SDLC modem for connection to the host, and a\n9600 bps &quot;loop&quot; interface for a local multidrop serial bus. For larger\ninstallations, you could expand a 3601 with additional local loop interfaces or\n4800 or 9600 bps modems to extend the local loop interface to a remote location\nvia telephone line.</p>\n<p>In total, a 3601 could interface up to five peripheral loops with the host\ncomputer over a single interleaved SDLC link. But what would you put on those\nperipheral loops? Well, the 3604 Keyboard Display Unit was the mainstay, with\na vacuum fluorescent display and choice of &quot;numeric&quot; (accounting, similar to a\ndesk calculator) or &quot;data entry&quot; (alphabetic) keyboard. A bank would put one of\nthese 3604s in front of each teller, where they could inquire into customer\naccounts and enter transactions. In the meantime, 3610 printers provided\ngeneral-purpose document printing capability, including back-office journals\n(logging all transactions) or filling in pre-printed forms such as receipts\nand bank checks. Since the 3610 was often used as a journal printer, it was\navailable with a take-up roller that stored the printed output under a locked\ncover. In fact, basically every part of the 3600 system was available with a\nkey switch or locking cover, a charming reminder of the state of computer\nsecurity at the time.</p>\n<p>The 3612 is a similar printer, but with the addition of a\ndedicated passbook feature. Remember passbook savings accounts, where the bank\nwrites every transaction in a little booklet that the customer keeps? They were\nstill around, although declining in use, in the 1970s. The 3612 had a slot on\nthe front where an appropriately formatted passbook could be inserted, and like\na check validator or slip printer, it printed the latest transaction onto the\nnext empty line. Finally, the 3618 was a &quot;medium-speed&quot; printer, meaning 155 lines per minute.\nA branch bank would probably have one, in the back office, used for printing\ndaily closing reports and other longer &quot;administrative&quot; output.</p>\n<p><img src=\"https://computer.rip/static/img/ibm_atm/5.png\" alt=\"IBM 4700 series documentation\" /></p>\n<p>A branch bank could carry out all of its routine business through the 3600\nsystem, including cash withdrawals. In fact, since a customer withdrawing cash\nwould end up talking to a teller who simply keyed the transaction into a 3604,\nit seems like a little more automation could make an ATM part of the system.</p>\n<p>Enter the 3614 Consumer Transaction Facility, the first IBM ATM available as a\nregular catalog item. The 3614 is actually fairly obscure, and doesn't seem to\nhave sold in large numbers. Some sources suggest that it was basically the same\nas the 2984, but with a general facelift and adaptations to connect to a 3601 Finance Communication\nController instead of directly to a front-end processor. Some features which\nwere optional on the 2984, like a deposit slot, were apparently standard on 3614.\nI'm not even quite sure when the 3614 was introduced, but based on manual\ncopyright dates they must have been around by 1977.</p>\n<p>One of the reasons the 3614 is obscure is that its replacement, the IBM 3624\nConsumer Transaction Facility, hit the market in 1978—probably very shortly\nafter the 3614. The 3624 was functionally very similar to the 3614, but with\nmaintainability improvements like convenient portable cartridges for storing\ncash. It also brought a completely redesigned front panel that is more similar\nto modern ATMs. I should talk about the front panels—the IBM ATMs won a few\ndesign awards over their years, and they were really very handsome machines.\nThe backlit logo panel and function-specific keys of the 3624 look more pleasant\nto use than most modern ATMs, although they would of course render translation\ndifficult.</p>\n<p>The 3614/3624 series established a number of conventions that are still in use\ntoday. For example, they added an envelope deposit system in which the machine\naccepted an envelope (with cash or checks) and printed a transaction identifier\non the outside of the envelope for lookup at the processing center. This\nrelieved the user of writing up a deposit slip when using the ATM. It was also\ncapable of not only reading but, optionally, writing to the magnetic strips on\nATM cards. To the modern reader that sounds strange, but we have to discuss one\nof the most enduring properties of the 3614/3624: their handling of PIN numbers.</p>\n<p>I believe the 2984 did something fairly similar, but the details are now obscure\n(and seem to get mixed up with its use of LUCIFER/DSD-1/DES for communications).\nThe 3614/3624, though, so firmly established a particular approach to PIN\nnumbers that it is now known as the 3624 algorithm. Here's how it works: the\nATM reads the card number (called Primary Account Number or PAN) off of the\nATM card, reads a key from memory, and then applies a convoluted cryptographic\nalgorithm to calculate an &quot;intermediate PIN&quot; from it. The &quot;intermediate pin&quot;\nis then summed with a &quot;PIN offset&quot; stored on the card itself, modulo 10, to\nproduce the PIN that the user is actually expected to enter. This means that\nyour &quot;true&quot; PIN is a static value calculated from your card number and a key,\nbut as a matter of convenience, you can &quot;set&quot; a PIN of your choice by using an\nATM that is equipped to rewrite the PIN offset on your card. This same system,\nwith some tweaks and a lot of terminological drift, is still in use today. You\nwill sometimes hear IBM's intermediate PIN called the &quot;natural PIN,&quot; the one\nyou get with an offset of 0, which is a use of language that I find charming.</p>\n<p>Another interesting feature of the 3624 was a receipt printer—I'm not sure if it\nwas the first ATM to offer a receipt, but it was definitely an early one. The\nexact mechanics of the 3624 receipt printer are amusing and the result of some\nhappenstance at IBM. Besides its mainframes and their peripherals, IBM in the\n1970s was was increasingly invested in &quot;midrange computers&quot; or &quot;midcomputers&quot;\nthat would fill in a space between the mainframe and minicomputer—and, most\nimportantly, make IBM more competitive with the smaller businesses that could\nnot afford IBM's mainframe systems and were starting to turn to competitors like\nDEC as a result. These would eventually blossom into the extremely successful\nAS/400 and System i, but not easily, and the first few models all suffered from\ndecidedly soft sales.</p>\n<p>For these smaller computers, IBM reasoned that they needed to offer peripherals\nlike card punches and readers that were also smaller. Apparently following that\nline of thought to a misguided extent, IBM also designed a smaller punch card:\nthe 96-column three-row card, which was nearly square. The only computer ever\nto support these cards was the very first of the midrange line, the 1969\nSystem/3. One wonders if the System/3's limited success lead to excess stock of\n96-column card equipment, or perhaps they just wanted to reuse tooling. In any\ncase, the oddball System/3 card had a second life as the &quot;Transaction Statement\nPrinter&quot; on the 3614 and 3624. The ATM could print four lines of text, 34\ncharacters each, onto the middle of the card. The machines didn't actually punch\nthem, and the printed text ended up over the original punch fields. You could,\nif you wanted, actually order a 3624 with two printers: one that presented the\nslip to the customer, and another that retained it internally for bank auditing.\nA curious detail that would so soon be replaced by thermal receipt printers.</p>\n<p>Unlike IBM's ATMs before it, and, as we will see, unlike those after it as well,\nthe 3624 was a hit. While IBM never enjoyed the dominance in ATMs that they did\nin computers, and companies like NCR and Diebold had substantial market\nshare, the 3624 was widely installed in the late 1970s and would probably be\nrecognized by anyone who was withdrawing cash in that era. The machine had\ntechnical leadership as well: NCR built their successful ATM line in part by\nduplicating aspects of the 3624 design, allowing interoperability with IBM\nbackend systems. Ultimately, as so often happens, it may have been IBM's success\nthat became its undoing.</p>\n<p>In 1983, IBM completely refreshed their branch banking solution with the 4700\nFinance Communication System. While architecturally similar, the 4700 was a big\nupgrade. For one, the CRT had landed: the 4700 peripherals replaced several-line\nVFDs with full-size CRTs typical of other computer terminals, and conventional\ncomputer keyboards to boot. Most radically, though, the 4700 line introduced\n<em>distributed communications</em> to IBM's banking offerings. The 4701 Communications\nController was optionally available with a hard disk, and could be programmed\nin COBOL. Disk-equipped 4701s could operate offline, without a connection to the\nhost, or in a hybrid mode in which they performed some transactions locally and\nonly contacted the host system when necessary. Local records kept by the 4701\ncould be automatically sent to the host computer on a scheduled basis for\nreconciliation.</p>\n<p>Along with the 4700 series came a new ATM: the IBM 473x Personal Banking\nMachines. And with that, IBM's glory days in ATMs came crashing to the ground.\nThe 473x series was such a flop that it is hard to even figure out the model\nnumbers, the 4732 is most often referenced but others clearly existed, including\nthe 4730, 4731, 4736, 4737, and 4738. These various models were introduced from\n1983 to 1988, making up almost a decade of IBM's efforts and very few sales.\nThe 4732 had a generally upgraded interface, including a CRT, but a similar\nfeature set—unsurprising, given that the 3724 had already introduced most of the\nfeatures ATMs have today. It also didn't sell. I haven't been able to find any\nnumbers, but the trade press referred to the 4732 with terms like\n&quot;debacle,&quot; so they couldn't have been great.</p>\n<p>There were a few faults in the 4732's stars. First, IBM had made the decision to\nhandle the 4700 Finance Communication System as a complete rework of the 3600.\nThe 4700 controllers could support some 3600 peripherals, but 4700 peripherals\ncould <em>not</em> be used with 3600 controllers. Since 3600 systems were widely\ninstalled in banks, the compatibility choice created a situation where many of\nthe 4732's prospective buyers would end up having to replace a significant\namount of their other equipment, and then likely make software changes, in order\nto support the new machine. That might not have been so bad on its own had IBM's\ncompetitors not provided another way out.</p>\n<p>NCR made their fame in ATMs in part by equipping their contemporary models with\n3624 software emulation, making them a drop-in modernization option for existing\n3600 systems. In general, other ATM manufacturers had pursued a path of\ninteroperability, with multiprotocol ATMs that supported multiple hosts, and\nstandalone ATM host products that could interoperate with multiple backend\naccounting systems. For customers, buying an NCR or Diebold product that would\nwork with whatever they already used was a more appealing option than buying the\nentire IBM suite in one go. It also matched the development cycle of ATMs\nbetter: as a consumer-facing device, ATMs became part of the brand image of the\nbank, and were likely to see replacement more often than back-office devices\nlike teller terminals. NCR offered something like a regular refresh, while IBM\nwas still in a mode of generational releases that would completely replace the\nbank's computer systems.</p>\n<p><img src=\"https://computer.rip/static/img/ibm_atm/6.jpg\" alt=\"IBM 3614 promo photo\" /></p>\n<p>The 4732 and its 473x compatriots became the last real IBM ATMs. After a hiatus\nof roughly a decade, IBM reentered the ATM market by forming a joint venture\nwith Diebold called InterBold. The basic terms were that Diebold would sell its\nATMs in the US, and IBM would sell them overseas, where IBM had generally been\nthe more successful of the two brands. The IBM 478x series ATMs, which you might\nencounter in the UK for example, are the same as the Diebold 1000 series in the\nUS. InterBold was quite successful, becoming the dominant ATM manufacturer in\nthe US, and in 1998 Diebold bought out IBM's share.</p>\n<p>IBM had won the ATM market, and then lost it. Along the way, they left us with\nso much texture: DES's origins in the ATM, the 3624 PIN format, the dumb\nterminal or thin client model... even InterBold, IBM's protracted exit, gave us\nquite a legacy: now you know the reason that so many later ATMs ran OS/2. IBM,\na once great company, provided Diebold with their once great operating system.\nUnlike IBM, Diebold made it successful.</p>\n<div class=\"footnotes\">\n<ol>\n<li id=\"fn-1\">\n<p>Wikipedia calls it DTD-1 for some reason, but IBM sources consistently\nsay DSD-1. I'm not sure if the name changed, if DSD-1 and DTD-1 were slightly\ndifferent things, or if Wikipedia is simply wrong. One of the little mysteries\nof the universe.<a href=\"#fnref-1\" class=\"footnote\">&#8617;</a></p></li>\n<li id=\"fn-2\">\n<p>I probably need to explain that I am pointedly <em>not</em> explaining IBM model\nnumbers, which do follow various schemes but are nonetheless confusing. Bigger\nnumbers are sometimes later products but not always; some prefixes mean specific\nthings, other prefixes just identify product lines.<a href=\"#fnref-2\" class=\"footnote\">&#8617;</a></p></li>\n</ol>\n</div>\n  ",
    "description": "In the United States, we are losing our fondness for cash. As in many other countries, cards and other types of electronic payments now dominate everyday commerce. To some, this is a loss. Cash represented a certain freedom from intermediation, a comforting simplicity, that you just don't get from Visa. It's funny to consider, then, how cash is in fact quite amenable to automation. Even Benjamin Franklin's face on a piece of paper can feel like a mere proxy for a database transaction. How differ",
    "is_fulltext": true,
    "source": "computers are bad",
    "pub_date": "27 Feb 2026 00:00:00 UT",
    "fetched_at": "2026-02-28T00:34:39.085994",
    "url_hash": "f5c926035383d81867ee2b517870ea71"
  }
]